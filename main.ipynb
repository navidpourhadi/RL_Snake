{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T21:49:54.740569Z",
     "start_time": "2024-01-05T21:49:54.724713Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import environments_fully_observable \n",
    "import environments_partially_observable\n",
    "import numpy as np\n",
    "from  tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "import DQN\n",
    "import AStar_Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_boards(env, n=5):\n",
    "    \n",
    "    fig,axs=plt.subplots(1,min(len(env.boards), n), figsize=(10,2))\n",
    "    for ax, board in zip(axs, env.boards):\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.imshow(board, origin=\"lower\")\n",
    "\n",
    "def to_channels(state):    \n",
    "    num_boards = state.shape[0]\n",
    "    board_dim = state.shape[1]\n",
    "    return np.transpose(state, (0,3,1,2)).reshape(num_boards, 4, board_dim, board_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T21:51:24.586654Z",
     "start_time": "2024-01-05T21:51:24.492663Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# function to standardize getting an env for the whole notebook\n",
    "def get_env(n=100, size = 15):\n",
    "    # n is the number of boards that you want to simulate parallely\n",
    "    # size is the size of each board, also considering the borders\n",
    "    # mask for the partially observable, is the size of the local neighborhood\n",
    "    e = environments_fully_observable.OriginalSnakeEnvironment(n, size)\n",
    "    # e = environments_partially_observable.OriginalSnakeEnvironment(n, size, 2)\n",
    "    return e\n",
    "env_ = get_env(n=100, size=10)\n",
    "GAMMA = .9\n",
    "ITERATIONS = 2000\n",
    "\n",
    "display_boards(env_, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "GPU is not available. Switching to CPU.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAABVCAYAAADOppJ2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEjklEQVR4nO3cMW4bVxAG4FlCbgwQ6lnrAOnSJG4DpMspUqTKYVLkFOx8gMRFfA4CvMACaSTwpVCcuNBCT7PD1Yr8PoAwYNPi+seIqx/PnKG11gIAAKDQ5rUvAAAAuDyKBgAAUE7RAAAAyikaAABAOUUDAAAop2gAAADlFA0AAKDcTc+TTqdTHI/H2G63MQzDua9ptVprMY5j7Ha72Gz6OprscrlFyC7CzM0huzzZ5ckuT3Y57rF5Zi6vO7vW4XA4tIjw+PdxOBx6YpPdjNxkl89ObrKT3es/ZCe7Necmu3x2cntZdl0nGtvtNiIivosf4ybe9fyVi/QQ9/EpPv6XRw/Z5XKLkF2EmZtDdnmyy5Ndnuxy3GPzzFxeb3ZdRePL0dBNvIub4XpDjfb4y0uOymQXqdy+fr7szFyK7PJklye7PNnluMfmmbm8zux8GBwAACinaAAAAOUUDQAAoJyiAQAAlOv6MPhz/v7p24ovsxrv958Xey3Z5S2V3fHD9Aeddn+0stdZKjszlye7PNnlyS5Pdnmyy8nk9udvvz/5+9//8vPcy5ltbm5ONAAAgHKKBgAAUE7RAAAAyikaAABAOUUDAAAoV7J1amorT+VGHs5nzdsO1sAcw7ostQkOYAmX/POWEw0AAKCcogEAAJRTNAAAgHKKBgAAUE7RAAAAyikaAABAuZL1tkutE5xawxpx2avBzk1218U6at46swrwNjjRAAAAyikaAABAOUUDAAAop2gAAADlFA0AAKBcydappdiOBPPZ2AM8xWZHoJoTDQAAoJyiAQAAlFM0AACAcooGAABQTtEAAADKKRoAAEC5N7XeFgA4j2taYXv8MEz+mRXgj6bWHV/TnDCfEw0AAKCcogEAAJRTNAAAgHKKBgAAUE7RAAAAyikaAABAOettAVbG6s3zsK5zWVNzfLdf+EKe4Pvoeb4vqOBEAwAAKKdoAAAA5RQNAACgnKIBAACUUzQAAIBytk4BzDS1zSgit7nFRpzzsEVnWeaYHrbsXTYnGgAAQDlFAwAAKKdoAAAA5RQNAACgnKIBAACUUzQAAIBy1tu+sqm1bla6Lat6Pem1kNuja/q3AjW8fz66lp93rnWNrxMNAACgnKIBAACUUzQAAIByigYAAFBO0QAAAMqVbJ16v/9c8WWu0t2vf732JbxZlXP3w/6b6deJy5pvueV5r8uTXZ7s8tac3drfP9ec3ZpN5Xa3X/hCVsKJBgAAUE7RAAAAyikaAABAOUUDAAAop2gAAADlurZOtdYiIuIh7iPaWa9n1R7iPiL+z6OH7HK5ff182Zm5DNnlyS5Pdnmyy3GPzTNzeb3ZdRWNcRwjIuJTfJx5WZdhHMe4vb3tfm6E7CJeltuX50fILsLMzSG7PNnlyS5PdjnusXlmLu+57IbWUeNOp1Mcj8fYbrcxDEPpBb4lrbUYxzF2u11sNn3/60x2udwiZBdh5uaQXZ7s8mSXJ7sc99g8M5fXm11X0QAAAHgJHwYHAADKKRoAAEA5RQMAACinaAAAAOUUDQAAoJyiAQAAlFM0AACAcv8Aa4f9SPO/AlMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = to_channels(env_.to_state()).shape[1:]\n",
    "\n",
    "DQN_agent = DQN.DQNAgent(input_shape= input_shape, num_actions= 4, gamma= GAMMA)\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print('GPU is available.')\n",
    "else:\n",
    "    print('GPU is not available. Switching to CPU.')\n",
    "\n",
    "display_boards(env_, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/2000 => loss: 0.06959887593984604, Reward Mean: -0.006000000052154064\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Epoch 2/2000 => loss: 0.018707793205976486, Reward Mean: -0.01400000136345625\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 3/2000 => loss: 0.0031325609888881445, Reward Mean: -0.01400000136345625\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Epoch 4/2000 => loss: 0.010056755505502224, Reward Mean: -0.009999999776482582\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Epoch 5/2000 => loss: 0.003462338587269187, Reward Mean: -0.007000000681728125\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Epoch 6/2000 => loss: 0.009196983650326729, Reward Mean: -0.007000000681728125\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "Epoch 7/2000 => loss: 0.003963438328355551, Reward Mean: -0.014999999664723873\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "Epoch 8/2000 => loss: 0.008900913409888744, Reward Mean: -0.011000001803040504\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "Epoch 9/2000 => loss: 0.004181320779025555, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 10/2000 => loss: 0.008576608262956142, Reward Mean: -0.023999998345971107\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 11/2000 => loss: 0.004031913820654154, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 12/2000 => loss: 0.008057897910475731, Reward Mean: -0.0019999996293336153\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 13/2000 => loss: 0.004449088126420975, Reward Mean: -0.02199999988079071\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 14/2000 => loss: 0.00801425613462925, Reward Mean: -0.020999999716877937\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 15/2000 => loss: 0.0040376437827944756, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 16/2000 => loss: 0.0076088672503829, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 17/2000 => loss: 0.00430250121280551, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 18/2000 => loss: 0.007503671105951071, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 19/2000 => loss: 0.004448033403605223, Reward Mean: -0.02199999801814556\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 20/2000 => loss: 0.007261244580149651, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 21/2000 => loss: 0.004293342120945454, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 22/2000 => loss: 0.0069236960262060165, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 23/2000 => loss: 0.004051311407238245, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 24/2000 => loss: 0.006557949353009462, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 25/2000 => loss: 0.004086384084075689, Reward Mean: -0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 26/2000 => loss: 0.0065572550520300865, Reward Mean: -0.001999999862164259\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 27/2000 => loss: 0.004138827323913574, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 28/2000 => loss: 0.00666767219081521, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 29/2000 => loss: 0.004003998823463917, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 30/2000 => loss: 0.006376906763762236, Reward Mean: -0.001999999862164259\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 31/2000 => loss: 0.004557181615382433, Reward Mean: -0.0010000001639127731\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 32/2000 => loss: 0.006882862187922001, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 33/2000 => loss: 0.0042663803324103355, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 34/2000 => loss: 0.006478849332779646, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 35/2000 => loss: 0.004224829375743866, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 36/2000 => loss: 0.005694500636309385, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 37/2000 => loss: 0.004216567613184452, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 38/2000 => loss: 0.006685248110443354, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 39/2000 => loss: 0.00457491772249341, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 40/2000 => loss: 0.006413219962269068, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 41/2000 => loss: 0.00457061966881156, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 42/2000 => loss: 0.005916908383369446, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 43/2000 => loss: 0.0043153660371899605, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 44/2000 => loss: 0.006671960465610027, Reward Mean: -0.0029999997932463884\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 45/2000 => loss: 0.004133038688451052, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 46/2000 => loss: 0.006453108508139849, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 47/2000 => loss: 0.004492277279496193, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 48/2000 => loss: 0.005875966511666775, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 49/2000 => loss: 0.004162118304520845, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 50/2000 => loss: 0.005527755245566368, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 51/2000 => loss: 0.003942178562283516, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 52/2000 => loss: 0.004807683639228344, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 53/2000 => loss: 0.0030329683795571327, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 54/2000 => loss: 0.0038598920218646526, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 55/2000 => loss: 0.002596612088382244, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 56/2000 => loss: 0.0028277502860873938, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 57/2000 => loss: 0.002081141574308276, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 58/2000 => loss: 0.002925314474850893, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 59/2000 => loss: 0.00266864150762558, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 60/2000 => loss: 0.0023647742345929146, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 61/2000 => loss: 0.0016443559434264898, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 62/2000 => loss: 0.001870601437985897, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 63/2000 => loss: 0.002130728680640459, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 64/2000 => loss: 0.002419483382254839, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 65/2000 => loss: 0.0018308113794773817, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 66/2000 => loss: 0.0016904398798942566, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 67/2000 => loss: 0.002018966479226947, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 68/2000 => loss: 0.0017368776025250554, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 69/2000 => loss: 0.0019863201305270195, Reward Mean: 0.0010000000474974513\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 70/2000 => loss: 0.0018172746058553457, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 71/2000 => loss: 0.0019418627489358187, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 72/2000 => loss: 0.00150175835005939, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 73/2000 => loss: 0.0018962160684168339, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 74/2000 => loss: 0.0015701318625360727, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 75/2000 => loss: 0.0017050086753442883, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 76/2000 => loss: 0.0019948030821979046, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 77/2000 => loss: 0.0013730016071349382, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 78/2000 => loss: 0.0014886370627209544, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 79/2000 => loss: 0.0011851023882627487, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 80/2000 => loss: 0.0016382684698328376, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 81/2000 => loss: 0.001968439668416977, Reward Mean: -0.020999999716877937\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 82/2000 => loss: 0.0017258271109312773, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 83/2000 => loss: 0.001604641554877162, Reward Mean: -0.0029999997932463884\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 84/2000 => loss: 0.0015897606499493122, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 85/2000 => loss: 0.002139369025826454, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 86/2000 => loss: 0.0015083069447427988, Reward Mean: -0.024000000208616257\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 87/2000 => loss: 0.0021590357646346092, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 88/2000 => loss: 0.0018074859399348497, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 89/2000 => loss: 0.001668664743192494, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 90/2000 => loss: 0.0014986027963459492, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 91/2000 => loss: 0.0018694900209084153, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 92/2000 => loss: 0.0017501621041446924, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 93/2000 => loss: 0.0015528283547610044, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 94/2000 => loss: 0.0019529054407030344, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 95/2000 => loss: 0.0019847643561661243, Reward Mean: -0.0010000000474974513\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 96/2000 => loss: 0.0018933005630970001, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 97/2000 => loss: 0.0018642130307853222, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 98/2000 => loss: 0.0020825425162911415, Reward Mean: 0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 99/2000 => loss: 0.001950658275745809, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 100/2000 => loss: 0.0015730184968560934, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 101/2000 => loss: 0.001913634710945189, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 102/2000 => loss: 0.0018583473283797503, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 103/2000 => loss: 0.001977673266083002, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 104/2000 => loss: 0.0021237675100564957, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 105/2000 => loss: 0.001914402935653925, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 106/2000 => loss: 0.0017738607712090015, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 107/2000 => loss: 0.0019838816951960325, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 108/2000 => loss: 0.0015111940447241068, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 109/2000 => loss: 0.0017745407531037927, Reward Mean: -0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 110/2000 => loss: 0.002163892611861229, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 111/2000 => loss: 0.0017948811873793602, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 112/2000 => loss: 0.0018589887768030167, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 113/2000 => loss: 0.0019586877897381783, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 114/2000 => loss: 0.0018826033920049667, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 115/2000 => loss: 0.0020929034799337387, Reward Mean: -0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 116/2000 => loss: 0.0018002244178205729, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 117/2000 => loss: 0.001726319082081318, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 118/2000 => loss: 0.0022522499784827232, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 119/2000 => loss: 0.0018919502617791295, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 120/2000 => loss: 0.0015827647875994444, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 121/2000 => loss: 0.002304977038875222, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 122/2000 => loss: 0.0016396275022998452, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 123/2000 => loss: 0.0022164832334965467, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 124/2000 => loss: 0.001830743858590722, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 125/2000 => loss: 0.001585664926096797, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 126/2000 => loss: 0.0019403058104217052, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 127/2000 => loss: 0.0018543683690950274, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 128/2000 => loss: 0.0024275798350572586, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 129/2000 => loss: 0.0020727624651044607, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 130/2000 => loss: 0.0020317386370152235, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 131/2000 => loss: 0.0018838965333998203, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 132/2000 => loss: 0.0020048203878104687, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 133/2000 => loss: 0.0019736597314476967, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 134/2000 => loss: 0.0020702865440398455, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 135/2000 => loss: 0.001618949230760336, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 136/2000 => loss: 0.001909372629597783, Reward Mean: 2.2351741291171123e-10\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 137/2000 => loss: 0.0018664977978914976, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 138/2000 => loss: 0.002048949245363474, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 139/2000 => loss: 0.0018457910045981407, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 140/2000 => loss: 0.0017815682804211974, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 141/2000 => loss: 0.001991845201700926, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 142/2000 => loss: 0.002494953805580735, Reward Mean: 2.2351741291171123e-10\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 143/2000 => loss: 0.0013999922666698694, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 144/2000 => loss: 0.0016318419948220253, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 145/2000 => loss: 0.002136160619556904, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 146/2000 => loss: 0.002032777527347207, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 147/2000 => loss: 0.001956661231815815, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 148/2000 => loss: 0.0020425538532435894, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 149/2000 => loss: 0.0023731060791760683, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 150/2000 => loss: 0.002070731483399868, Reward Mean: 0.0010000001639127731\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 151/2000 => loss: 0.0021385117433965206, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 152/2000 => loss: 0.002370415488258004, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 153/2000 => loss: 0.0021548294462263584, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 154/2000 => loss: 0.0025454519782215357, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 155/2000 => loss: 0.0020992073696106672, Reward Mean: -0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 156/2000 => loss: 0.002322392538189888, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 157/2000 => loss: 0.0021832240745425224, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 158/2000 => loss: 0.0017581538995727897, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 159/2000 => loss: 0.0020746251102536917, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 160/2000 => loss: 0.0022558486089110374, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 161/2000 => loss: 0.0024083321914076805, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 162/2000 => loss: 0.0017612744122743607, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 163/2000 => loss: 0.001775004668161273, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 164/2000 => loss: 0.0022528599947690964, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 165/2000 => loss: 0.002296817023307085, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 166/2000 => loss: 0.002018080558627844, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 167/2000 => loss: 0.0019370889058336616, Reward Mean: 0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 168/2000 => loss: 0.0022018023300915956, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 169/2000 => loss: 0.0016316755209118128, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 170/2000 => loss: 0.0023197068367153406, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 171/2000 => loss: 0.001711888937279582, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 172/2000 => loss: 0.001984512899070978, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 173/2000 => loss: 0.0024300776422023773, Reward Mean: 0.0009999992325901985\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 174/2000 => loss: 0.0016212166519835591, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 175/2000 => loss: 0.0016851366963237524, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 176/2000 => loss: 0.0022984915412962437, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 177/2000 => loss: 0.0020554931834340096, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 178/2000 => loss: 0.0018663456430658698, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 179/2000 => loss: 0.002096485812216997, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 180/2000 => loss: 0.0020989584736526012, Reward Mean: 0.001000000280328095\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 181/2000 => loss: 0.0021042809821665287, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 182/2000 => loss: 0.0015518650179728866, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 183/2000 => loss: 0.0021575121209025383, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 184/2000 => loss: 0.0019192069303244352, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 185/2000 => loss: 0.0020636662375181913, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 186/2000 => loss: 0.0025557377375662327, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 187/2000 => loss: 0.0019405705388635397, Reward Mean: -0.023000001907348633\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 188/2000 => loss: 0.0023394266609102488, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 189/2000 => loss: 0.002338285557925701, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 190/2000 => loss: 0.0024586310610175133, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 191/2000 => loss: 0.002188463695347309, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 192/2000 => loss: 0.0017301796469837427, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 193/2000 => loss: 0.0017752557760104537, Reward Mean: 0.0\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 194/2000 => loss: 0.0030498881824314594, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 195/2000 => loss: 0.0022208839654922485, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 196/2000 => loss: 0.002108892658725381, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 197/2000 => loss: 0.001618044450879097, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 198/2000 => loss: 0.002113626804202795, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 199/2000 => loss: 0.0019918072503060102, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 200/2000 => loss: 0.0015273303724825382, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 201/2000 => loss: 0.001846563769504428, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 202/2000 => loss: 0.0020537814125418663, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 203/2000 => loss: 0.002084834035485983, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 204/2000 => loss: 0.0018296733032912016, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 205/2000 => loss: 0.0015892393421381712, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 206/2000 => loss: 0.001962357433512807, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 207/2000 => loss: 0.0019518493209034204, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 208/2000 => loss: 0.0020024930126965046, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 209/2000 => loss: 0.0018930218648165464, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 210/2000 => loss: 0.002382026519626379, Reward Mean: -0.02199999988079071\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 211/2000 => loss: 0.002126567531377077, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 212/2000 => loss: 0.0021074635442346334, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 213/2000 => loss: 0.0019629402086138725, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 214/2000 => loss: 0.002192038344219327, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 215/2000 => loss: 0.0022506932727992535, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 216/2000 => loss: 0.0018500863807275891, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 217/2000 => loss: 0.001875558402389288, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 218/2000 => loss: 0.0018740282393991947, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 219/2000 => loss: 0.0019246030133217573, Reward Mean: -0.005999999586492777\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 220/2000 => loss: 0.002170721534639597, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 221/2000 => loss: 0.002035620389506221, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 222/2000 => loss: 0.0022585054393857718, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 223/2000 => loss: 0.0020347784738987684, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 224/2000 => loss: 0.0025127544067800045, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 225/2000 => loss: 0.0017617435660213232, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 226/2000 => loss: 0.0018438291735947132, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 227/2000 => loss: 0.002111460780724883, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 228/2000 => loss: 0.002097778022289276, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 229/2000 => loss: 0.0017257053405046463, Reward Mean: -0.020999999716877937\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 230/2000 => loss: 0.0017812552396208048, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 231/2000 => loss: 0.0021239686757326126, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 232/2000 => loss: 0.002191926119849086, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 233/2000 => loss: 0.0023849881254136562, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 234/2000 => loss: 0.0022246045991778374, Reward Mean: 0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 235/2000 => loss: 0.0017978240502998233, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 236/2000 => loss: 0.0016071680001914501, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 237/2000 => loss: 0.001630978542380035, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 238/2000 => loss: 0.001733735203742981, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 239/2000 => loss: 0.002374395029619336, Reward Mean: -0.02199999988079071\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 240/2000 => loss: 0.001963426126167178, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 241/2000 => loss: 0.0019789927173405886, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 242/2000 => loss: 0.002191915875300765, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 243/2000 => loss: 0.0020064208656549454, Reward Mean: 0.0\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 244/2000 => loss: 0.0020085207652300596, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 245/2000 => loss: 0.0022441577166318893, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 246/2000 => loss: 0.002133814850822091, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 247/2000 => loss: 0.0018221675418317318, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 248/2000 => loss: 0.002050071721896529, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 249/2000 => loss: 0.0017672243993729353, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 250/2000 => loss: 0.0024348455481231213, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 251/2000 => loss: 0.0016755040269345045, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 252/2000 => loss: 0.002456406829878688, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 253/2000 => loss: 0.002039289567619562, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 254/2000 => loss: 0.0020165371242910624, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 255/2000 => loss: 0.0015525131020694971, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 256/2000 => loss: 0.0018191265407949686, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 257/2000 => loss: 0.001967853168025613, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 258/2000 => loss: 0.0018461192958056927, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 259/2000 => loss: 0.002110715489834547, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 260/2000 => loss: 0.0022375918924808502, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 261/2000 => loss: 0.0020255153067409992, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 262/2000 => loss: 0.0018946642521768808, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 263/2000 => loss: 0.002163015305995941, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 264/2000 => loss: 0.001867357175797224, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 265/2000 => loss: 0.001897494657896459, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 266/2000 => loss: 0.002114738803356886, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 267/2000 => loss: 0.0018382545094937086, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 268/2000 => loss: 0.002246952848508954, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 269/2000 => loss: 0.002015302423387766, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 270/2000 => loss: 0.00193980080075562, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 271/2000 => loss: 0.0018000167328864336, Reward Mean: -0.001999999862164259\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 272/2000 => loss: 0.00198035454377532, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 273/2000 => loss: 0.0022490639239549637, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 274/2000 => loss: 0.0017938843229785562, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 275/2000 => loss: 0.002333013340830803, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 276/2000 => loss: 0.0021039636339992285, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 277/2000 => loss: 0.0022148226853460073, Reward Mean: -0.0029999997932463884\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 278/2000 => loss: 0.002125122118741274, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 279/2000 => loss: 0.002448695246130228, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 280/2000 => loss: 0.0020598447881639004, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 281/2000 => loss: 0.0020187818445265293, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 282/2000 => loss: 0.002309406641870737, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 283/2000 => loss: 0.0021392800845205784, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 284/2000 => loss: 0.001818503369577229, Reward Mean: -0.010000001639127731\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 285/2000 => loss: 0.002321186475455761, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 286/2000 => loss: 0.0017711682012304664, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 287/2000 => loss: 0.001971652265638113, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 288/2000 => loss: 0.0023225576151162386, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 289/2000 => loss: 0.002506343647837639, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 290/2000 => loss: 0.002813044935464859, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 291/2000 => loss: 0.0020538053940981627, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 292/2000 => loss: 0.0017998924013227224, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 293/2000 => loss: 0.0017316725570708513, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 294/2000 => loss: 0.0022087148390710354, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 295/2000 => loss: 0.002596670761704445, Reward Mean: -0.001000000280328095\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 296/2000 => loss: 0.002071527997031808, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 297/2000 => loss: 0.0021192068234086037, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 298/2000 => loss: 0.002000836655497551, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 299/2000 => loss: 0.0026087185833603144, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 300/2000 => loss: 0.002079737139865756, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 301/2000 => loss: 0.00209595775231719, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 302/2000 => loss: 0.001915425295010209, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 303/2000 => loss: 0.001640442293137312, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 304/2000 => loss: 0.0018721275264397264, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 305/2000 => loss: 0.0015106461942195892, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 306/2000 => loss: 0.00214931252412498, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 307/2000 => loss: 0.0018645974341779947, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 308/2000 => loss: 0.0019886703230440617, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 309/2000 => loss: 0.0018195528537034988, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 310/2000 => loss: 0.002085916232317686, Reward Mean: -0.007999999448657036\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 311/2000 => loss: 0.001704278402030468, Reward Mean: 0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 312/2000 => loss: 0.0019073905423283577, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 313/2000 => loss: 0.002144410740584135, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 314/2000 => loss: 0.0017898286459967494, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 315/2000 => loss: 0.0023199189454317093, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 316/2000 => loss: 0.002049562521278858, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 317/2000 => loss: 0.00164674106054008, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 318/2000 => loss: 0.0019487967947497964, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 319/2000 => loss: 0.0026035173796117306, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 320/2000 => loss: 0.0018994552083313465, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 321/2000 => loss: 0.0021940728183835745, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 322/2000 => loss: 0.002047038171440363, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 323/2000 => loss: 0.0019523629453033209, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 324/2000 => loss: 0.002002359600737691, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 325/2000 => loss: 0.0019077430479228497, Reward Mean: -0.010000001639127731\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 326/2000 => loss: 0.0018756925128400326, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 327/2000 => loss: 0.001629380974918604, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 328/2000 => loss: 0.0019160652300342917, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 329/2000 => loss: 0.0015285804402083158, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 330/2000 => loss: 0.00204847427085042, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 331/2000 => loss: 0.0019639944657683372, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 332/2000 => loss: 0.0023817624896764755, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 333/2000 => loss: 0.002407244173809886, Reward Mean: 0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 334/2000 => loss: 0.0022499822080135345, Reward Mean: 0.0010000000474974513\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 335/2000 => loss: 0.0020469194278120995, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 336/2000 => loss: 0.0022784657776355743, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 337/2000 => loss: 0.0021403981372714043, Reward Mean: 0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 338/2000 => loss: 0.0020585721358656883, Reward Mean: -0.0029999997932463884\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 339/2000 => loss: 0.0019155479967594147, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 340/2000 => loss: 0.0020849413704127073, Reward Mean: -0.021000001579523087\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 341/2000 => loss: 0.0014189386274665594, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 342/2000 => loss: 0.0021179369650781155, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 343/2000 => loss: 0.0024438381660729647, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 344/2000 => loss: 0.0024816570803523064, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 345/2000 => loss: 0.0024621400516480207, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 346/2000 => loss: 0.0027958531863987446, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 347/2000 => loss: 0.0019829696975648403, Reward Mean: 0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 348/2000 => loss: 0.0025164117105305195, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 349/2000 => loss: 0.002547942567616701, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 350/2000 => loss: 0.0020855162292718887, Reward Mean: -0.02199999988079071\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 351/2000 => loss: 0.0019155882764607668, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 352/2000 => loss: 0.0016057008178904653, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 353/2000 => loss: 0.002391277579590678, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 354/2000 => loss: 0.002295315731316805, Reward Mean: 2.98023217215615e-10\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 355/2000 => loss: 0.0018335205968469381, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 356/2000 => loss: 0.0019301369320601225, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 357/2000 => loss: 0.0025476841256022453, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 358/2000 => loss: 0.002589254640042782, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 359/2000 => loss: 0.001821337267756462, Reward Mean: -0.020999999716877937\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 360/2000 => loss: 0.0023546800948679447, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 361/2000 => loss: 0.001932953717187047, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 362/2000 => loss: 0.0017758700996637344, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 363/2000 => loss: 0.002468295395374298, Reward Mean: 0.0009999999310821295\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 364/2000 => loss: 0.0018427602481096983, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 365/2000 => loss: 0.0021874867379665375, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 366/2000 => loss: 0.002430276945233345, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 367/2000 => loss: 0.0019032780546694994, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 368/2000 => loss: 0.0022211147006601095, Reward Mean: 0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 369/2000 => loss: 0.0021514147520065308, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 370/2000 => loss: 0.0025265219155699015, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 371/2000 => loss: 0.001766715431585908, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 372/2000 => loss: 0.002113024704158306, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 373/2000 => loss: 0.0017832379089668393, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 374/2000 => loss: 0.002097944263368845, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 375/2000 => loss: 0.0016893692081794143, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 376/2000 => loss: 0.0022383052855730057, Reward Mean: -0.0010000000474974513\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 377/2000 => loss: 0.002633216092363, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 378/2000 => loss: 0.0021703557576984167, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 379/2000 => loss: 0.0016782657476142049, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 380/2000 => loss: 0.001855421345680952, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 381/2000 => loss: 0.0020820507779717445, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 382/2000 => loss: 0.0019403875339776278, Reward Mean: 0.001999999862164259\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 383/2000 => loss: 0.002204912481829524, Reward Mean: -0.011000001803040504\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 384/2000 => loss: 0.001640441594645381, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 385/2000 => loss: 0.0018122715409845114, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 386/2000 => loss: 0.0019385966006666422, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 387/2000 => loss: 0.0020304243080317974, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 388/2000 => loss: 0.002332022413611412, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 389/2000 => loss: 0.0018686596304178238, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 390/2000 => loss: 0.00243273819796741, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 391/2000 => loss: 0.0017557968385517597, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 392/2000 => loss: 0.0022497556637972593, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 393/2000 => loss: 0.0019884712528437376, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 394/2000 => loss: 0.001391841098666191, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 395/2000 => loss: 0.002722848206758499, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 396/2000 => loss: 0.0022173235192894936, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 397/2000 => loss: 0.002468796679750085, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 398/2000 => loss: 0.0016576293855905533, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 399/2000 => loss: 0.002119573298841715, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 400/2000 => loss: 0.0019279851112514734, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 401/2000 => loss: 0.0026109390892088413, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 402/2000 => loss: 0.0016044938238337636, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 403/2000 => loss: 0.002181408228352666, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 404/2000 => loss: 0.002258423250168562, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 405/2000 => loss: 0.0024481243453919888, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 406/2000 => loss: 0.002083428669720888, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 407/2000 => loss: 0.002449107589200139, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 408/2000 => loss: 0.002085492480546236, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 409/2000 => loss: 0.0021875544916838408, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 410/2000 => loss: 0.0021882527507841587, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 411/2000 => loss: 0.0021834182552993298, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 412/2000 => loss: 0.0018183307256549597, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 413/2000 => loss: 0.0021895975805819035, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 414/2000 => loss: 0.0025049918331205845, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 415/2000 => loss: 0.0019899001345038414, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 416/2000 => loss: 0.0025214734487235546, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 417/2000 => loss: 0.001845641527324915, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 418/2000 => loss: 0.0023360634222626686, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 419/2000 => loss: 0.0024176989682018757, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 420/2000 => loss: 0.0020039209630340338, Reward Mean: -0.0030000004917383194\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 421/2000 => loss: 0.0022285631857812405, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 422/2000 => loss: 0.0018203196814283729, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 423/2000 => loss: 0.002070026472210884, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 424/2000 => loss: 0.0020057985093444586, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 425/2000 => loss: 0.002334131859242916, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 426/2000 => loss: 0.00216430751606822, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 427/2000 => loss: 0.0016305256867781281, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 428/2000 => loss: 0.0020359805785119534, Reward Mean: 0.0009999999310821295\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 429/2000 => loss: 0.002096332609653473, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 430/2000 => loss: 0.0016112702433019876, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 431/2000 => loss: 0.00227023521438241, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 432/2000 => loss: 0.001950940233655274, Reward Mean: 0.0\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 433/2000 => loss: 0.0017529125325381756, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 434/2000 => loss: 0.0021759294904768467, Reward Mean: -0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 435/2000 => loss: 0.0016337938141077757, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 436/2000 => loss: 0.0017767379758879542, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 437/2000 => loss: 0.0017605831380933523, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 438/2000 => loss: 0.0017118518007919192, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 439/2000 => loss: 0.0021159229800105095, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 440/2000 => loss: 0.0021384344436228275, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 441/2000 => loss: 0.0018928874051198363, Reward Mean: 0.001000000280328095\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 442/2000 => loss: 0.0019140213262289762, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 443/2000 => loss: 0.0023413565941154957, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 444/2000 => loss: 0.001784246414899826, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 445/2000 => loss: 0.0014450588496401906, Reward Mean: -0.02500000037252903\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 446/2000 => loss: 0.0023003879468888044, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 447/2000 => loss: 0.001752948621287942, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 448/2000 => loss: 0.0023088911548256874, Reward Mean: 0.003000000026077032\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 449/2000 => loss: 0.0018279338255524635, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 450/2000 => loss: 0.0018628907855600119, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 451/2000 => loss: 0.0023885508999228477, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 452/2000 => loss: 0.0013526063412427902, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 453/2000 => loss: 0.0024500410072505474, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 454/2000 => loss: 0.0020720071624964476, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 455/2000 => loss: 0.001353819970972836, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 456/2000 => loss: 0.0025140484794974327, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 457/2000 => loss: 0.0025189053267240524, Reward Mean: -0.003999999724328518\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 458/2000 => loss: 0.0018294028704985976, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 459/2000 => loss: 0.002077808603644371, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 460/2000 => loss: 0.002267646137624979, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 461/2000 => loss: 0.002042624168097973, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 462/2000 => loss: 0.001966191455721855, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 463/2000 => loss: 0.0015506220515817404, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 464/2000 => loss: 0.002187680685892701, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 465/2000 => loss: 0.0020694956183433533, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 466/2000 => loss: 0.0018094817642122507, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 467/2000 => loss: 0.0024980311281979084, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 468/2000 => loss: 0.002212807536125183, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 469/2000 => loss: 0.0018734927289187908, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 470/2000 => loss: 0.0019894978031516075, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 471/2000 => loss: 0.0019248508615419269, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 472/2000 => loss: 0.0021017175167798996, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 473/2000 => loss: 0.0019051112467423081, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 474/2000 => loss: 0.0017726689111441374, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 475/2000 => loss: 0.0022173793986439705, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 476/2000 => loss: 0.002275383798405528, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 477/2000 => loss: 0.0023607881739735603, Reward Mean: 0.0019999993965029716\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 478/2000 => loss: 0.002090573078021407, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 479/2000 => loss: 0.0019551957957446575, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 480/2000 => loss: 0.0024967228528112173, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 481/2000 => loss: 0.002458019182085991, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 482/2000 => loss: 0.0020796661265194416, Reward Mean: 0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 483/2000 => loss: 0.0018650011625140905, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 484/2000 => loss: 0.002502948511391878, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 485/2000 => loss: 0.0023390022106468678, Reward Mean: -0.0029999995604157448\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 486/2000 => loss: 0.0020256727002561092, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 487/2000 => loss: 0.0020008061546832323, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 488/2000 => loss: 0.0023447172716259956, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 489/2000 => loss: 0.002403132850304246, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 490/2000 => loss: 0.0017476167995482683, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 491/2000 => loss: 0.0022197789512574673, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 492/2000 => loss: 0.0018578716553747654, Reward Mean: -0.005000000819563866\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 493/2000 => loss: 0.0018289476865902543, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 494/2000 => loss: 0.002038168255239725, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 495/2000 => loss: 0.0020428223069757223, Reward Mean: -0.001000000280328095\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 496/2000 => loss: 0.0017059736419469118, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 497/2000 => loss: 0.0018942664610221982, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 498/2000 => loss: 0.001863942015916109, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 499/2000 => loss: 0.002472414169460535, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 500/2000 => loss: 0.0022876551374793053, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 501/2000 => loss: 0.002037410857155919, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 502/2000 => loss: 0.00174884800799191, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 503/2000 => loss: 0.00188265775796026, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 504/2000 => loss: 0.002459498355165124, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 505/2000 => loss: 0.002241727663204074, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 506/2000 => loss: 0.002349032089114189, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 507/2000 => loss: 0.0017909342423081398, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 508/2000 => loss: 0.0019969623535871506, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 509/2000 => loss: 0.0017634837422519922, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 510/2000 => loss: 0.00174023921135813, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 511/2000 => loss: 0.002617286052554846, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 512/2000 => loss: 0.0023681840393692255, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 513/2000 => loss: 0.0023617015685886145, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 514/2000 => loss: 0.0021974542178213596, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 515/2000 => loss: 0.00187340856064111, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 516/2000 => loss: 0.0020920266397297382, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 517/2000 => loss: 0.0026782911736518145, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 518/2000 => loss: 0.002542044036090374, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 519/2000 => loss: 0.0020831660367548466, Reward Mean: -0.0030000004917383194\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 520/2000 => loss: 0.002267905045300722, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 521/2000 => loss: 0.0023012945894151926, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 522/2000 => loss: 0.0021304218098521233, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 523/2000 => loss: 0.002389314351603389, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 524/2000 => loss: 0.0019866377115249634, Reward Mean: -0.020999999716877937\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 525/2000 => loss: 0.0021785530261695385, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 526/2000 => loss: 0.0018961767200380564, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 527/2000 => loss: 0.0021390444599092007, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 528/2000 => loss: 0.0022567319683730602, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 529/2000 => loss: 0.0018804019782692194, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 530/2000 => loss: 0.0022112708538770676, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 531/2000 => loss: 0.0015984915662556887, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 532/2000 => loss: 0.0019670347683131695, Reward Mean: -0.0010000005131587386\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 533/2000 => loss: 0.0023988441098481417, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 534/2000 => loss: 0.0016442857449874282, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 535/2000 => loss: 0.0020982930436730385, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 536/2000 => loss: 0.0016777159180492163, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 537/2000 => loss: 0.002350092399865389, Reward Mean: -0.001999999862164259\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 538/2000 => loss: 0.0022064840886741877, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 539/2000 => loss: 0.002415011404082179, Reward Mean: 0.0\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 540/2000 => loss: 0.001848442479968071, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 541/2000 => loss: 0.002984090941026807, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 542/2000 => loss: 0.0022387064527720213, Reward Mean: -0.020999999716877937\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 543/2000 => loss: 0.0023665635380893946, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 544/2000 => loss: 0.001733250916004181, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 545/2000 => loss: 0.0022623250260949135, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 546/2000 => loss: 0.0022635147906839848, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 547/2000 => loss: 0.0019900230690836906, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 548/2000 => loss: 0.002077719196677208, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 549/2000 => loss: 0.002024252898991108, Reward Mean: -0.007999999448657036\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 550/2000 => loss: 0.0022036724258214235, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 551/2000 => loss: 0.002364324638620019, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 552/2000 => loss: 0.0015215130988508463, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 553/2000 => loss: 0.0019122186349704862, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 554/2000 => loss: 0.00257975235581398, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 555/2000 => loss: 0.002277965657413006, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 556/2000 => loss: 0.002189233899116516, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 557/2000 => loss: 0.0018503034953027964, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 558/2000 => loss: 0.001799627672880888, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 559/2000 => loss: 0.001985454000532627, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 560/2000 => loss: 0.0021432344801723957, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 561/2000 => loss: 0.0024519406724721193, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 562/2000 => loss: 0.0016870544059202075, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 563/2000 => loss: 0.0021990290842950344, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 564/2000 => loss: 0.002004394307732582, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 565/2000 => loss: 0.0026954340282827616, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 566/2000 => loss: 0.0020453501492738724, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 567/2000 => loss: 0.0020369666162878275, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 568/2000 => loss: 0.0018587589729577303, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 569/2000 => loss: 0.0022023541387170553, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 570/2000 => loss: 0.002133312402293086, Reward Mean: -0.022999996319413185\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 571/2000 => loss: 0.0019784942269325256, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 572/2000 => loss: 0.002212743740528822, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 573/2000 => loss: 0.0023743000347167253, Reward Mean: -0.007000001147389412\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 574/2000 => loss: 0.0020902734249830246, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 575/2000 => loss: 0.0020608636550605297, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 576/2000 => loss: 0.002147783525288105, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 577/2000 => loss: 0.0022120573557913303, Reward Mean: 0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 578/2000 => loss: 0.001882507698610425, Reward Mean: 0.0009999999310821295\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 579/2000 => loss: 0.0015559224411845207, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 580/2000 => loss: 0.00217942101880908, Reward Mean: -0.0029999995604157448\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 581/2000 => loss: 0.0018284190446138382, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 582/2000 => loss: 0.002091213595122099, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 583/2000 => loss: 0.002709552412852645, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 584/2000 => loss: 0.0019863410852849483, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 585/2000 => loss: 0.0022805011831223965, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 586/2000 => loss: 0.0017832259181886911, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 587/2000 => loss: 0.0017760589253157377, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 588/2000 => loss: 0.0018015193054452538, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 589/2000 => loss: 0.0017862273380160332, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 590/2000 => loss: 0.0026202360168099403, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 591/2000 => loss: 0.002114838920533657, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 592/2000 => loss: 0.0020595386158674955, Reward Mean: -0.020999999716877937\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 593/2000 => loss: 0.0022971751168370247, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 594/2000 => loss: 0.0015903916209936142, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 595/2000 => loss: 0.0021626492962241173, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 596/2000 => loss: 0.0019739801064133644, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 597/2000 => loss: 0.0017905667191371322, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 598/2000 => loss: 0.002053037052974105, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 599/2000 => loss: 0.0021023305598646402, Reward Mean: -0.02199999801814556\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 600/2000 => loss: 0.0017849705182015896, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 601/2000 => loss: 0.0019697844982147217, Reward Mean: -0.0029999997932463884\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 602/2000 => loss: 0.001798312645405531, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 603/2000 => loss: 0.0021601004991680384, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 604/2000 => loss: 0.001826040679588914, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 605/2000 => loss: 0.002023640787228942, Reward Mean: 0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 606/2000 => loss: 0.0018627657555043697, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 607/2000 => loss: 0.0017574243247509003, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 608/2000 => loss: 0.002135378075763583, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 609/2000 => loss: 0.002272295765578747, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 610/2000 => loss: 0.002234562998637557, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 611/2000 => loss: 0.0016064296942204237, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 612/2000 => loss: 0.001680454588495195, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 613/2000 => loss: 0.0021007899194955826, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 614/2000 => loss: 0.002257927320897579, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 615/2000 => loss: 0.0016702936263754964, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 616/2000 => loss: 0.0020049642771482468, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 617/2000 => loss: 0.002002870198339224, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 618/2000 => loss: 0.0024835041258484125, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 619/2000 => loss: 0.0020317460875958204, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 620/2000 => loss: 0.002282844390720129, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 621/2000 => loss: 0.0024752733297646046, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 622/2000 => loss: 0.0018351732287555933, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 623/2000 => loss: 0.0022401725873351097, Reward Mean: 0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 624/2000 => loss: 0.001919479575008154, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 625/2000 => loss: 0.002259056083858013, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 626/2000 => loss: 0.0028282329440116882, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 627/2000 => loss: 0.0018506445921957493, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 628/2000 => loss: 0.002003937028348446, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 629/2000 => loss: 0.0023058238439261913, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 630/2000 => loss: 0.0022101690992712975, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 631/2000 => loss: 0.0022332787048071623, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 632/2000 => loss: 0.0018658081535249949, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 633/2000 => loss: 0.0018804334104061127, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 634/2000 => loss: 0.001915573957376182, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 635/2000 => loss: 0.00172024080529809, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 636/2000 => loss: 0.0020828633569180965, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 637/2000 => loss: 0.0020824712701141834, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 638/2000 => loss: 0.001927063800394535, Reward Mean: 0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 639/2000 => loss: 0.0026900391094386578, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 640/2000 => loss: 0.0020826472900807858, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 641/2000 => loss: 0.0018658828921616077, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 642/2000 => loss: 0.0019490559352561831, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 643/2000 => loss: 0.002790327649563551, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 644/2000 => loss: 0.0014635351253673434, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 645/2000 => loss: 0.0017999124247580767, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 646/2000 => loss: 0.0024546345230191946, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 647/2000 => loss: 0.00219636014662683, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 648/2000 => loss: 0.002179493196308613, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 649/2000 => loss: 0.002228008583188057, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 650/2000 => loss: 0.0017610001377761364, Reward Mean: 0.0009999999310821295\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 651/2000 => loss: 0.0017437689239159226, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 652/2000 => loss: 0.001796784228645265, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 653/2000 => loss: 0.0017871176823973656, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 654/2000 => loss: 0.002002946101129055, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 655/2000 => loss: 0.0018514111870899796, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 656/2000 => loss: 0.00263440259732306, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 657/2000 => loss: 0.0015160080511122942, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 658/2000 => loss: 0.002001214772462845, Reward Mean: -0.0029999997932463884\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 659/2000 => loss: 0.0018847142346203327, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 660/2000 => loss: 0.001741353189572692, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 661/2000 => loss: 0.002251294907182455, Reward Mean: -0.001999999862164259\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 662/2000 => loss: 0.0019395096460357308, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 663/2000 => loss: 0.0020286967046558857, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 664/2000 => loss: 0.001892100553959608, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 665/2000 => loss: 0.001768435351550579, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 666/2000 => loss: 0.002369347959756851, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 667/2000 => loss: 0.0018891097279265523, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 668/2000 => loss: 0.002065404085442424, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 669/2000 => loss: 0.0018222269136458635, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 670/2000 => loss: 0.0023578323889523745, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 671/2000 => loss: 0.002047155983746052, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 672/2000 => loss: 0.0018318952061235905, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 673/2000 => loss: 0.0017927923472598195, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 674/2000 => loss: 0.002058986574411392, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 675/2000 => loss: 0.0019113649614155293, Reward Mean: -0.00400000112131238\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 676/2000 => loss: 0.00235088262706995, Reward Mean: 2.2351741291171123e-10\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 677/2000 => loss: 0.002625218126922846, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 678/2000 => loss: 0.0021986712235957384, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 679/2000 => loss: 0.0019201359245926142, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 680/2000 => loss: 0.0018766637658700347, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 681/2000 => loss: 0.0019064084626734257, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 682/2000 => loss: 0.0023127365857362747, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 683/2000 => loss: 0.002011468168348074, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 684/2000 => loss: 0.001973652746528387, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 685/2000 => loss: 0.0016718744300305843, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 686/2000 => loss: 0.002132132649421692, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 687/2000 => loss: 0.0019004702335223556, Reward Mean: -0.005000000819563866\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 688/2000 => loss: 0.00180156622081995, Reward Mean: -0.001999999862164259\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 689/2000 => loss: 0.0022615818306803703, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 690/2000 => loss: 0.0017874417826533318, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 691/2000 => loss: 0.0024126237258315086, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 692/2000 => loss: 0.001713430043309927, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 693/2000 => loss: 0.002396560739725828, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 694/2000 => loss: 0.002141219098120928, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 695/2000 => loss: 0.0019311245996505022, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 696/2000 => loss: 0.001644855597987771, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 697/2000 => loss: 0.002370678586885333, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 698/2000 => loss: 0.0021884203888475895, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 699/2000 => loss: 0.00192640395835042, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 700/2000 => loss: 0.002029922790825367, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 701/2000 => loss: 0.001641141134314239, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 702/2000 => loss: 0.0017541126580908895, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 703/2000 => loss: 0.0015995834255591035, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 704/2000 => loss: 0.00223321421071887, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 705/2000 => loss: 0.002186499536037445, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 706/2000 => loss: 0.001913257408887148, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 707/2000 => loss: 0.002024636138230562, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 708/2000 => loss: 0.0020149946212768555, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 709/2000 => loss: 0.001814478193409741, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 710/2000 => loss: 0.0018815179355442524, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 711/2000 => loss: 0.001831626403145492, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 712/2000 => loss: 0.001584016252309084, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 713/2000 => loss: 0.002277230843901634, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 714/2000 => loss: 0.0016276000533252954, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 715/2000 => loss: 0.0017877453938126564, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 716/2000 => loss: 0.002266973489895463, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 717/2000 => loss: 0.001692808698862791, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 718/2000 => loss: 0.0017667976208031178, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 719/2000 => loss: 0.0020990276243537664, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 720/2000 => loss: 0.0017516894731670618, Reward Mean: 2.2351741291171123e-10\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 721/2000 => loss: 0.002545434283092618, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 722/2000 => loss: 0.0021322863176465034, Reward Mean: -0.003999999724328518\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 723/2000 => loss: 0.0019284408772364259, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 724/2000 => loss: 0.0024754400365054607, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 725/2000 => loss: 0.0021248357370495796, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 726/2000 => loss: 0.0017610773211345077, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 727/2000 => loss: 0.0025850762613117695, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 728/2000 => loss: 0.002274715341627598, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 729/2000 => loss: 0.0019332817755639553, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 730/2000 => loss: 0.0019922510255128145, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 731/2000 => loss: 0.0020874186884611845, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 732/2000 => loss: 0.0022673062048852444, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 733/2000 => loss: 0.0020558470860123634, Reward Mean: -0.02500000037252903\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 734/2000 => loss: 0.0016785002080723643, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 735/2000 => loss: 0.0017333189025521278, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 736/2000 => loss: 0.0022338794078677893, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 737/2000 => loss: 0.002474496839568019, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 738/2000 => loss: 0.0021905191242694855, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 739/2000 => loss: 0.002007649280130863, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "Epoch 740/2000 => loss: 0.0021669368725270033, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 741/2000 => loss: 0.001855229726061225, Reward Mean: -0.007999999448657036\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 742/2000 => loss: 0.0023179175332188606, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 743/2000 => loss: 0.0018385624280199409, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 744/2000 => loss: 0.002081680577248335, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 745/2000 => loss: 0.0021810431499034166, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 746/2000 => loss: 0.0015346017898991704, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 747/2000 => loss: 0.0017247542273253202, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 748/2000 => loss: 0.0023712357506155968, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 749/2000 => loss: 0.0019233431667089462, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 750/2000 => loss: 0.0022213610354810953, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 751/2000 => loss: 0.0023440392687916756, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 752/2000 => loss: 0.00193271494936198, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 753/2000 => loss: 0.002222725423052907, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 754/2000 => loss: 0.002134989481419325, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 755/2000 => loss: 0.0018102761823683977, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 756/2000 => loss: 0.0020063305273652077, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 757/2000 => loss: 0.0021847959142178297, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 758/2000 => loss: 0.002089942805469036, Reward Mean: -0.0019999996293336153\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 759/2000 => loss: 0.0018031129147857428, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 760/2000 => loss: 0.0020520908292382956, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 761/2000 => loss: 0.0018997103907167912, Reward Mean: 0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 762/2000 => loss: 0.002142419805750251, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 763/2000 => loss: 0.0019828786607831717, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 764/2000 => loss: 0.0017422244418412447, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 765/2000 => loss: 0.0018512823153287172, Reward Mean: -0.0009999999310821295\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 766/2000 => loss: 0.0017551546916365623, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 767/2000 => loss: 0.002021264284849167, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 768/2000 => loss: 0.0023321048356592655, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 769/2000 => loss: 0.0025110957212746143, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 770/2000 => loss: 0.0024219811893999577, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 771/2000 => loss: 0.002145554404705763, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 772/2000 => loss: 0.0017151429783552885, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 773/2000 => loss: 0.0019135393667966127, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 774/2000 => loss: 0.0019174384651705623, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 775/2000 => loss: 0.002029093448072672, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 776/2000 => loss: 0.0013950287830084562, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 777/2000 => loss: 0.001678501139394939, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 778/2000 => loss: 0.0027717615012079477, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 779/2000 => loss: 0.002266457537189126, Reward Mean: -0.001999999862164259\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 780/2000 => loss: 0.002033356809988618, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 781/2000 => loss: 0.002324978355318308, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 782/2000 => loss: 0.0014039017260074615, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 783/2000 => loss: 0.001843198318965733, Reward Mean: -0.01899999938905239\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 784/2000 => loss: 0.001822036225348711, Reward Mean: -0.005000000819563866\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 785/2000 => loss: 0.0023688836954534054, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 786/2000 => loss: 0.0022972640581429005, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 787/2000 => loss: 0.001735103433020413, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 788/2000 => loss: 0.0021006197202950716, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 789/2000 => loss: 0.002380445133894682, Reward Mean: 7.450580430390374e-11\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 790/2000 => loss: 0.002057273406535387, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 791/2000 => loss: 0.0021431862842291594, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 792/2000 => loss: 0.0018765362910926342, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 793/2000 => loss: 0.001857185154221952, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 794/2000 => loss: 0.0020744632929563522, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 795/2000 => loss: 0.00272400863468647, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 796/2000 => loss: 0.0021415152586996555, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 797/2000 => loss: 0.002037777565419674, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 798/2000 => loss: 0.0018891104264184833, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 799/2000 => loss: 0.001821543206460774, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 800/2000 => loss: 0.0020333610009402037, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 801/2000 => loss: 0.0022709383629262447, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 802/2000 => loss: 0.0017706752987578511, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 803/2000 => loss: 0.0016871762927621603, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 804/2000 => loss: 0.002355325035750866, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 805/2000 => loss: 0.0019166180863976479, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 806/2000 => loss: 0.0020486456342041492, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 807/2000 => loss: 0.0016377544961869717, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 808/2000 => loss: 0.0022143241949379444, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 809/2000 => loss: 0.0019531080033630133, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 810/2000 => loss: 0.0019362892489880323, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 811/2000 => loss: 0.0018782862462103367, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 812/2000 => loss: 0.00251424266025424, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 813/2000 => loss: 0.0017404812388122082, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 814/2000 => loss: 0.002017992315813899, Reward Mean: 0.0029999997932463884\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 815/2000 => loss: 0.0019640768878161907, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 816/2000 => loss: 0.0016342168673872948, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 817/2000 => loss: 0.0022672659251838923, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 818/2000 => loss: 0.0025101611390709877, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 819/2000 => loss: 0.0018870519706979394, Reward Mean: -0.0029999997932463884\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 820/2000 => loss: 0.0020801129285246134, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 821/2000 => loss: 0.001859729876741767, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 822/2000 => loss: 0.0018376416992396116, Reward Mean: -0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 823/2000 => loss: 0.002089163288474083, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 824/2000 => loss: 0.0022551098372787237, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 825/2000 => loss: 0.001773470314219594, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 826/2000 => loss: 0.002085162792354822, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 827/2000 => loss: 0.0019493955187499523, Reward Mean: -0.003000000026077032\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 828/2000 => loss: 0.0021157972514629364, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 829/2000 => loss: 0.0018791110487654805, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 830/2000 => loss: 0.002438080031424761, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 831/2000 => loss: 0.001956608146429062, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 832/2000 => loss: 0.002024873625487089, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 833/2000 => loss: 0.0019715474918484688, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 834/2000 => loss: 0.0023118876852095127, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 835/2000 => loss: 0.001867788378149271, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 836/2000 => loss: 0.0018459041602909565, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 837/2000 => loss: 0.0016921714413911104, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 838/2000 => loss: 0.0017418439965695143, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 839/2000 => loss: 0.0016804386395961046, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 840/2000 => loss: 0.001791026908904314, Reward Mean: -0.005000000819563866\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 841/2000 => loss: 0.002037337515503168, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 842/2000 => loss: 0.0020378525368869305, Reward Mean: 0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 843/2000 => loss: 0.0023860782384872437, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 844/2000 => loss: 0.0018269293941557407, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 845/2000 => loss: 0.0016350166406482458, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 846/2000 => loss: 0.002084640320390463, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 847/2000 => loss: 0.001739477040246129, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 848/2000 => loss: 0.0018146137008443475, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 849/2000 => loss: 0.002722203964367509, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 850/2000 => loss: 0.0017760061891749501, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 851/2000 => loss: 0.0019313199445605278, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 852/2000 => loss: 0.0024990621022880077, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 853/2000 => loss: 0.0019687130115926266, Reward Mean: -0.008999999612569809\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 854/2000 => loss: 0.0018412144854664803, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 855/2000 => loss: 0.0018911513034254313, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 856/2000 => loss: 0.0019524111412465572, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 857/2000 => loss: 0.0021880825515836477, Reward Mean: 0.001999999862164259\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 858/2000 => loss: 0.0020551993511617184, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 859/2000 => loss: 0.0016598391812294722, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 860/2000 => loss: 0.0017027193680405617, Reward Mean: -0.02199999988079071\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 861/2000 => loss: 0.002179062459617853, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 862/2000 => loss: 0.0020576189272105694, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 863/2000 => loss: 0.0013249770272523165, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 864/2000 => loss: 0.0015453087398782372, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 865/2000 => loss: 0.0020953472703695297, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 866/2000 => loss: 0.001817663200199604, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 867/2000 => loss: 0.002328701550140977, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 868/2000 => loss: 0.001880859723314643, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 869/2000 => loss: 0.0019911513663828373, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 870/2000 => loss: 0.0020371894352138042, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 871/2000 => loss: 0.0023232311941683292, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 872/2000 => loss: 0.001597629045136273, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 873/2000 => loss: 0.0014602607116103172, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 874/2000 => loss: 0.0022710184566676617, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 875/2000 => loss: 0.0017647817730903625, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 876/2000 => loss: 0.0027240158524364233, Reward Mean: -0.00400000112131238\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 877/2000 => loss: 0.0017757101450115442, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 878/2000 => loss: 0.001867984188720584, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 879/2000 => loss: 0.0020310147665441036, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 880/2000 => loss: 0.0014242602046579123, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 881/2000 => loss: 0.0017130437772721052, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 882/2000 => loss: 0.00308110099285841, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 883/2000 => loss: 0.0019730902276933193, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 884/2000 => loss: 0.001906430465169251, Reward Mean: 0.0010000005131587386\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 885/2000 => loss: 0.001854279194958508, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 886/2000 => loss: 0.001581563614308834, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 887/2000 => loss: 0.002365950495004654, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 888/2000 => loss: 0.002393113449215889, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 889/2000 => loss: 0.0019893471617251635, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 890/2000 => loss: 0.0022558923810720444, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 891/2000 => loss: 0.0024129950907081366, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 892/2000 => loss: 0.001992179546505213, Reward Mean: 0.0029999995604157448\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 893/2000 => loss: 0.001942643546499312, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 894/2000 => loss: 0.00216197338886559, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 895/2000 => loss: 0.0019814453553408384, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 896/2000 => loss: 0.002043740591034293, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 897/2000 => loss: 0.0021549381781369448, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 898/2000 => loss: 0.0023510742466896772, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 899/2000 => loss: 0.0019822034519165754, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 900/2000 => loss: 0.0014979726402089, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 901/2000 => loss: 0.0019055558368563652, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 902/2000 => loss: 0.0021267523989081383, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 903/2000 => loss: 0.001854672096669674, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 904/2000 => loss: 0.0016165153356269002, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 905/2000 => loss: 0.0017809333512559533, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 906/2000 => loss: 0.001722302520647645, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 907/2000 => loss: 0.0023036031052470207, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 908/2000 => loss: 0.0022575489711016417, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 909/2000 => loss: 0.001755894860252738, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 910/2000 => loss: 0.002105996711179614, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 911/2000 => loss: 0.0020188582129776478, Reward Mean: -0.01600000075995922\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 912/2000 => loss: 0.0024692427832633257, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 913/2000 => loss: 0.001850716769695282, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 914/2000 => loss: 0.001662008697167039, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 915/2000 => loss: 0.0014352785656228662, Reward Mean: -0.00800000037997961\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 916/2000 => loss: 0.0020523262210190296, Reward Mean: -0.0139999995008111\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 917/2000 => loss: 0.0017207718919962645, Reward Mean: -7.450580430390374e-11\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 918/2000 => loss: 0.0015159542672336102, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 919/2000 => loss: 0.0018355275969952345, Reward Mean: -0.00699999975040555\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 920/2000 => loss: 0.002358274068683386, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 921/2000 => loss: 0.0017131163040176034, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 922/2000 => loss: 0.002040786435827613, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 923/2000 => loss: 0.0018250680295750499, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 924/2000 => loss: 0.0019809699151664972, Reward Mean: -0.009999999776482582\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 925/2000 => loss: 0.0022450750693678856, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 926/2000 => loss: 0.0015373185742646456, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 927/2000 => loss: 0.0023426362313330173, Reward Mean: -0.007000000681728125\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 928/2000 => loss: 0.0018871382344514132, Reward Mean: 0.004999999888241291\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 929/2000 => loss: 0.002076612086966634, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 930/2000 => loss: 0.001959281973540783, Reward Mean: -0.012000000104308128\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 931/2000 => loss: 0.0025343620218336582, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 932/2000 => loss: 0.001459317747503519, Reward Mean: -0.007999999448657036\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 933/2000 => loss: 0.002217840636149049, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 934/2000 => loss: 0.002082118298858404, Reward Mean: -0.018000001087784767\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 935/2000 => loss: 0.0014891871251165867, Reward Mean: 0.003999999724328518\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 936/2000 => loss: 0.0022902372293174267, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 937/2000 => loss: 0.0017432705499231815, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 938/2000 => loss: 0.00201071472838521, Reward Mean: -0.01900000125169754\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 939/2000 => loss: 0.0022318053524941206, Reward Mean: -0.017000000923871994\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 940/2000 => loss: 0.0025037883315235376, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 941/2000 => loss: 0.0018439425621181726, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 942/2000 => loss: 0.0020621628500521183, Reward Mean: -0.014999999664723873\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 943/2000 => loss: 0.002399747958406806, Reward Mean: -0.017999999225139618\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 944/2000 => loss: 0.0019877494778484106, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 945/2000 => loss: 0.0023652352392673492, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 946/2000 => loss: 0.002068884903565049, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 947/2000 => loss: 0.002256344771012664, Reward Mean: -0.004000000189989805\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 948/2000 => loss: 0.002167987637221813, Reward Mean: -0.019999999552965164\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 949/2000 => loss: 0.0016404060879722238, Reward Mean: -0.0020000000949949026\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 950/2000 => loss: 0.0016797101125121117, Reward Mean: -0.015000001527369022\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 951/2000 => loss: 0.0024006215389817953, Reward Mean: -0.0029999997932463884\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 952/2000 => loss: 0.0022363197058439255, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 953/2000 => loss: 0.0018500623991712928, Reward Mean: -0.0010000001639127731\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 954/2000 => loss: 0.002129577798768878, Reward Mean: -0.009000000543892384\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 955/2000 => loss: 0.0018531217938289046, Reward Mean: -0.010999999940395355\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 956/2000 => loss: 0.0027052874211221933, Reward Mean: -0.012999999336898327\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 957/2000 => loss: 0.001882519107311964, Reward Mean: -0.006000000052154064\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 958/2000 => loss: 0.0021328364964574575, Reward Mean: -0.013000000268220901\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 959/2000 => loss: 0.0020451548043638468, Reward Mean: -0.01400000136345625\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 960/2000 => loss: 0.0021140757016837597, Reward Mean: -0.009999999776482582\n"
     ]
    }
   ],
   "source": [
    "DQN_agent.train(env_, ITERATIONS, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_execute(agent, steps, env):\n",
    "    rewards = np.zeros(env.n_boards, dtype=float)\n",
    "    for step in trange(steps):\n",
    "        state = env.to_state()\n",
    "        # Select actions using the DQN agent\n",
    "        actions = agent.select_actions(state).reshape(-1,1)\n",
    "        # Move in the environment and get rewards\n",
    "        rewards = rewards + env_.move(actions)\n",
    "        display_boards(env, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, agent, steps=1000):\n",
    "    with tf.device('/GPU:0'):\n",
    "        # load the weights\n",
    "        # self.load_weights(WEIGHT_PATH+\"q_model.h5\", WEIGHT_PATH+\"v_model.h5\") \n",
    "        fruits = np.zeros(env.n_boards, dtype=int)\n",
    "\n",
    "        rewards = np.zeros(env.n_boards, dtype=float)[:,None]\n",
    "        for _ in trange(steps):\n",
    "            print(\"iteration: \", _)\n",
    "                # update the coordination of fruits in each board\n",
    "                # fruit_before = np.argwhere(env.boards == env.FRUIT)\n",
    "            state = env.to_state()\n",
    "            actions = agent.select_actions_exploitation(state).reshape(-1, 1)\n",
    "            reward = env.move(actions)\n",
    "                # fruit_after = np.argwhere(env.boards == env.FRUIT)\n",
    "                # diff = [np.array_equal(fruit_before[i], fruit_after[i]) for i in range(env.n_boards)]\n",
    "                # increment the fruit count in boards that have different fruit locations\n",
    "                # fruits = np.array([fruits[i] + 1 if not diff[i] else fruits[i] for i in range(env.n_boards)])\n",
    "                \n",
    "                # print(fruits)\n",
    "\n",
    "            rewards = rewards + reward\n",
    "            print(\"rewards: \", rewards)\n",
    "            display_boards(env, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:05, 16.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.07332955 0.17173319 0.19787274 0.18178153]\n",
      " [0.21605328 0.2538144  0.18006554 0.19592658]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "iteration:  1\n",
      "q_values:  [[0.1630514  0.19913374 0.23567791 0.21342033]\n",
      " [0.23470412 0.2807214  0.20228796 0.21885827]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "iteration:  2\n",
      "q_values:  [[0.18386713 0.22857797 0.27347884 0.24422164]\n",
      " [0.2758249  0.31540388 0.2364778  0.24018888]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "iteration:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:05, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.24027975 0.26001328 0.33081713 0.31324774]\n",
      " [0.31323934 0.3278263  0.24356826 0.2823091 ]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "iteration:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:00<00:05, 17.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.27615574 0.3091676  0.41132286 0.3640652 ]\n",
      " [0.37589246 0.34908944 0.29319307 0.30825335]]\n",
      "actions:  [2 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "iteration:  5\n",
      "q_values:  [[0.35676426 0.3827791  0.46181074 0.4330285 ]\n",
      " [0.39118776 0.4210962  0.3408786  0.33586633]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "iteration:  6\n",
      "q_values:  [[0.40778068 0.4104713  0.48113155 0.5067295 ]\n",
      " [0.46834102 0.43095997 0.34355104 0.39260167]]\n",
      "actions:  [3 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "iteration:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:00<00:05, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.44460338 0.4354225  0.5042933  0.5120185 ]\n",
      " [0.48909718 0.4626239  0.43465966 0.44117317]]\n",
      "actions:  [3 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "iteration:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:00<00:05, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.47605902 0.4522897  0.572172   0.4420479 ]\n",
      " [0.4118537  0.5248249  0.41884243 0.43627864]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.5]\n",
      " [0.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  9\n",
      "q_values:  [[0.12436113 0.11543419 0.02447861 0.0805418 ]\n",
      " [0.09728719 0.14578658 0.25877753 0.19043057]]\n",
      "actions:  [0 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [0.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  10\n",
      "q_values:  [[0.2120569  0.23596877 0.17275056 0.19588485]\n",
      " [0.16797952 0.2405693  0.32099187 0.3655959 ]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [0.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  11\n",
      "q_values:  [[0.23321655 0.2423575  0.19135319 0.20290533]\n",
      " [0.27345234 0.22601755 0.32954872 0.4675898 ]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [0.5]], shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:00<00:04, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:00<00:04, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.27611768 0.25755334 0.19135745 0.21745291]\n",
      " [0.36924627 0.34012923 0.4685237  0.52135986]]\n",
      "actions:  [0 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [0.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  13\n",
      "q_values:  [[0.32966205 0.31460083 0.23428956 0.23488224]\n",
      " [0.40931344 0.33960554 0.5669369  0.53242207]]\n",
      "actions:  [0 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  14\n",
      "q_values:  [[ 0.41647467  0.3947661   0.30615625  0.32080215]\n",
      " [-0.0932033   0.10155132  0.07341515  0.03199613]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:00<00:04, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[ 0.45231947  0.47963136  0.3631093   0.36348528]\n",
      " [-0.21167594  0.00385768 -0.05538547 -0.11199067]]\n",
      "actions:  [1 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  16\n",
      "q_values:  [[ 0.5174271   0.49890083  0.37188047  0.426158  ]\n",
      " [-0.15239313 -0.02153785 -0.04727669 -0.1069613 ]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:01<00:06, 12.78it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_25704\\49746459.py:3: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig,axs=plt.subplots(1,min(len(env.boards), n), figsize=(10,2))\n",
      " 20%|██        | 20/100 [00:01<00:05, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[ 0.5632037   0.5594179   0.45315948  0.4794252 ]\n",
      " [-0.08333586 -0.07312638 -0.02725757 -0.02982437]]\n",
      "actions:  [0 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.3]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  18\n",
      "q_values:  [[ 0.4663797   0.59466946  0.49402118  0.45438734]\n",
      " [-0.16048728 -0.08130766 -0.04828542  0.06674001]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  19\n",
      "q_values:  [[ 0.02167341  0.11007831  0.13198894  0.05219623]\n",
      " [-0.05832582 -0.04706255 -0.05786172  0.0848625 ]]\n",
      "actions:  [2 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  20\n",
      "q_values:  [[ 0.04076113  0.11990242  0.11012125  0.11759648]\n",
      " [-0.00954838  0.00821619 -0.00084699  0.11671641]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:01<00:04, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[ 0.02379261  0.09590451  0.06399153  0.02651482]\n",
      " [-0.00831822 -0.06183985  0.02361998  0.06370161]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  22\n",
      "q_values:  [[0.009434   0.00387396 0.08799814 0.06686518]\n",
      " [0.00226792 0.00398096 0.07616717 0.10540573]]\n",
      "actions:  [2 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  23\n",
      "q_values:  [[-0.05162835  0.0367395   0.02407544  0.12596604]\n",
      " [ 0.09648057  0.06160649  0.1471      0.1912743 ]]\n",
      "actions:  [3 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  24\n",
      "q_values:  [[0.10336389 0.01694737 0.09958827 0.1615443 ]\n",
      " [0.09508581 0.04158834 0.14850922 0.12586927]]\n",
      "actions:  [3 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:01<00:04, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.1433899  0.0494219  0.16885853 0.25031412]\n",
      " [0.10594633 0.26507798 0.37950632 0.2668875 ]]\n",
      "actions:  [3 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  26\n",
      "q_values:  [[0.12828647 0.05554318 0.26869103 0.25146472]\n",
      " [0.22721756 0.42361632 0.5171288  0.28217956]]\n",
      "actions:  [2 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  27\n",
      "q_values:  [[0.13461384 0.18327723 0.27683127 0.28948703]\n",
      " [0.3649771  0.43050092 0.57816774 0.31318322]]\n",
      "actions:  [3 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  28\n",
      "q_values:  [[0.2596569  0.11542539 0.39690974 0.44799334]\n",
      " [0.18424931 0.169329   0.07822158 0.09650885]]\n",
      "actions:  [3 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:01<00:04, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.26845646 0.23460908 0.4761469  0.44546214]\n",
      " [0.38470653 0.36618134 0.27838692 0.2853844 ]]\n",
      "actions:  [2 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  30\n",
      "q_values:  [[0.42365056 0.41753113 0.5828526  0.5343756 ]\n",
      " [0.44844693 0.45540714 0.32887045 0.35396037]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[0.8]\n",
      " [1.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  31\n",
      "q_values:  [[0.45515794 0.38248664 0.43235496 0.5903183 ]\n",
      " [0.5305304  0.4190484  0.382159   0.4328861 ]]\n",
      "actions:  [3 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[1.3]\n",
      " [1.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  32\n",
      "q_values:  [[0.30774054 0.21563344 0.10805825 0.2332319 ]\n",
      " [0.59201074 0.46443513 0.42552167 0.4599074 ]]\n",
      "actions:  [0 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[1.3]\n",
      " [1.8]], shape=(2, 1), dtype=float32)\n",
      "iteration:  33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:02<00:03, 16.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.2641733  0.21452413 0.08793425 0.15894976]\n",
      " [0.3249474  0.3242936  0.40936026 0.4743208 ]]\n",
      "actions:  [0 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[1.3]\n",
      " [1.8]], shape=(2, 1), dtype=float32)\n",
      "iteration:  34\n",
      "q_values:  [[0.28319094 0.17414424 0.1407752  0.17686155]\n",
      " [0.3405756  0.26973155 0.475119   0.46327657]]\n",
      "actions:  [0 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[1.8]\n",
      " [1.8]], shape=(2, 1), dtype=float32)\n",
      "iteration:  35\n",
      "q_values:  [[0.2060347  0.14151645 0.21318506 0.20536402]\n",
      " [0.34921962 0.40844992 0.512781   0.5857124 ]]\n",
      "actions:  [2 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[1.5999999]\n",
      " [2.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  36\n",
      "q_values:  [[ 0.31629953  0.36155283  0.4460456   0.360129  ]\n",
      " [ 0.05615139  0.10001715  0.10144552 -0.03671652]]\n",
      "actions:  [2 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[1.5999999]\n",
      " [2.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:02<00:03, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[ 0.39087236  0.39485794  0.5037114   0.4532255 ]\n",
      " [ 0.01697272  0.15551458  0.19587453 -0.01180043]]\n",
      "actions:  [2 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[1.5999999]\n",
      " [2.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  38\n",
      "q_values:  [[ 0.4602072   0.4579563   0.5370384   0.5132453 ]\n",
      " [-0.01304062  0.12773243  0.01717259 -0.13397309]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[1.5999999]\n",
      " [2.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  39\n",
      "q_values:  [[ 0.46546423  0.5136239   0.4591419   0.546348  ]\n",
      " [ 0.10693392  0.20426999  0.05581109 -0.0752242 ]]\n",
      "actions:  [3 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  40\n",
      "q_values:  [[0.20069769 0.06954445 0.03703773 0.03636779]\n",
      " [0.07517239 0.2288265  0.06469892 0.03512597]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [00:02<00:03, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[ 0.20942618  0.18126078 -0.01726807  0.06820704]\n",
      " [ 0.1468061   0.25209993  0.03104058  0.02879861]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  42\n",
      "q_values:  [[0.21444269 0.23230626 0.04366168 0.09475835]\n",
      " [0.1622111  0.4479542  0.14029562 0.11580998]]\n",
      "actions:  [1 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  43\n",
      "q_values:  [[0.22873497 0.27231824 0.11929441 0.04243846]\n",
      " [0.27236742 0.52888244 0.19084957 0.18357797]]\n",
      "actions:  [1 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  44\n",
      "q_values:  [[0.32711738 0.2632508  0.15057491 0.16485193]\n",
      " [0.28789487 0.5546547  0.1923946  0.26518646]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.8]], shape=(2, 1), dtype=float32)\n",
      "iteration:  45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [00:02<00:02, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[ 0.34578502  0.38913554  0.19715098  0.2733377 ]\n",
      " [-0.17165317 -0.0632166  -0.17063038 -0.08311526]]\n",
      "actions:  [1 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.7]], shape=(2, 1), dtype=float32)\n",
      "iteration:  46\n",
      "q_values:  [[ 0.43190074  0.42352843  0.31809974  0.28617576]\n",
      " [-0.07520506 -0.02206442 -0.0519391   0.03774539]]\n",
      "actions:  [0 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  47\n",
      "q_values:  [[0.48190507 0.54678315 0.34399736 0.38446444]\n",
      " [0.07157957 0.03585541 0.09048337 0.17244926]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.1]\n",
      " [2.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  48\n",
      "q_values:  [[0.50613266 0.49874634 0.35533944 0.3498346 ]\n",
      " [0.09815177 0.00071545 0.08517104 0.21587895]]\n",
      "actions:  [0 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.6]\n",
      " [2.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [00:03<00:03, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.0266092  0.18506476 0.11968092 0.07312053]\n",
      " [0.1474917  0.00171536 0.11472548 0.2214785 ]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.6]\n",
      " [2.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  50\n",
      "q_values:  [[-0.03807728  0.15452954  0.1433598   0.0500285 ]\n",
      " [ 0.24980727  0.08049099  0.17286491  0.29754913]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.6]\n",
      " [2.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  51\n",
      "q_values:  [[-0.06266247  0.11245935  0.12923141 -0.0116393 ]\n",
      " [ 0.30112377  0.10638103  0.17249708  0.2758992 ]]\n",
      "actions:  [2 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.6]\n",
      " [2.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  52\n",
      "q_values:  [[0.07227774 0.20170324 0.26339003 0.16322728]\n",
      " [0.36288613 0.26595455 0.14220072 0.31017202]]\n",
      "actions:  [2 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.6]\n",
      " [2.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [00:03<00:02, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.1844011  0.26533407 0.3682672  0.2775805 ]\n",
      " [0.4592636  0.35767797 0.2516187  0.4464355 ]]\n",
      "actions:  [2 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.1]\n",
      " [2.5]], shape=(2, 1), dtype=float32)\n",
      "iteration:  54\n",
      "q_values:  [[-0.04207286 -0.0122233  -0.09801233 -0.01231008]\n",
      " [ 0.37489733  0.3031276   0.32938427  0.49285144]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.1]\n",
      " [3. ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  55\n",
      "q_values:  [[-0.06021044 -0.1185714  -0.19837576 -0.04694678]\n",
      " [ 0.45208547  0.25787327  0.3219117   0.37920195]]\n",
      "actions:  [3 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.8999999]\n",
      " [3.5      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  56\n",
      "q_values:  [[ 0.25176167  0.20314479  0.17100528  0.22794254]\n",
      " [-0.01180981 -0.04362322 -0.05671149 -0.0140735 ]]\n",
      "actions:  [0 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.8999999]\n",
      " [3.5      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [00:03<00:02, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[ 0.27574596  0.22203468  0.19917     0.28456268]\n",
      " [-0.10261089 -0.10001863 -0.1680977  -0.04170261]]\n",
      "actions:  [3 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.8999999]\n",
      " [3.5      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  58\n",
      "q_values:  [[ 0.3199703   0.2604191   0.22172406  0.29231036]\n",
      " [-0.11413649 -0.09956552 -0.10446694 -0.1274985 ]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.8999999]\n",
      " [3.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  59\n",
      "q_values:  [[0.3630658  0.29896715 0.2643777  0.35981473]\n",
      " [0.19270279 0.2531781  0.20469463 0.18549106]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.8999999]\n",
      " [3.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  60\n",
      "q_values:  [[0.4273448  0.33223403 0.32025436 0.40714502]\n",
      " [0.19583388 0.2788878  0.21431643 0.19427653]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.8999999]\n",
      " [3.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  61\n",
      "q_values:  [[0.4697263  0.36858884 0.37814373 0.47630414]\n",
      " [0.24907537 0.3428568  0.2757222  0.2297107 ]]\n",
      "actions:  [3 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[2.8999999]\n",
      " [3.3      ]], shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [00:03<00:01, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  62\n",
      "q_values:  [[0.5806089  0.45846742 0.44880936 0.49508762]\n",
      " [0.3218437  0.41309407 0.3271884  0.2863866 ]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.3999999]\n",
      " [3.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  63\n",
      "q_values:  [[0.25499803 0.41401473 0.29880908 0.29492354]\n",
      " [0.4081448  0.47082105 0.39979076 0.34838465]]\n",
      "actions:  [1 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.3999999]\n",
      " [3.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  64\n",
      "q_values:  [[0.21819088 0.31788817 0.45514107 0.23548795]\n",
      " [0.48909718 0.4626239  0.43465966 0.44117317]]\n",
      "actions:  [2 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.3999999]\n",
      " [3.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  65\n",
      "q_values:  [[0.34725708 0.4896356  0.45285562 0.36400446]\n",
      " [0.4118537  0.5248249  0.41884243 0.43627864]]\n",
      "actions:  [1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [00:04<00:01, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  tf.Tensor(\n",
      "[[3.8999999]\n",
      " [3.8      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  66\n",
      "q_values:  [[-0.00312559  0.07853567  0.09700528  0.06070651]\n",
      " [ 0.12691526  0.1618164   0.29899684  0.2823069 ]]\n",
      "actions:  [2 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.8999999]\n",
      " [3.8      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  67\n",
      "q_values:  [[0.01860023 0.15621744 0.20177463 0.16670255]\n",
      " [0.15008143 0.20880659 0.31728405 0.38574108]]\n",
      "actions:  [2 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.8999999]\n",
      " [3.8      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  68\n",
      "q_values:  [[-0.02175281  0.1862745   0.17011201  0.15377001]\n",
      " [ 0.30309513  0.19594827  0.31129506  0.49832383]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.8999999]\n",
      " [3.8      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  69\n",
      "q_values:  [[0.12275667 0.13857621 0.15750504 0.21758457]\n",
      " [0.434986   0.35975948 0.3980631  0.5723875 ]]\n",
      "actions:  [3 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.6999998]\n",
      " [4.3      ]], shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [00:04<00:01, 18.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  70\n",
      "q_values:  [[0.3184173  0.3769874  0.47514397 0.4403493 ]\n",
      " [0.14770639 0.04717699 0.15722138 0.23586345]]\n",
      "actions:  [2 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.6999998]\n",
      " [4.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  71\n",
      "q_values:  [[0.39789197 0.41577065 0.54406387 0.5126654 ]\n",
      " [0.15307562 0.16785671 0.33714208 0.3131409 ]]\n",
      "actions:  [2 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[3.6999998]\n",
      " [4.3      ]], shape=(2, 1), dtype=float32)\n",
      "iteration:  72\n",
      "q_values:  [[0.5032933  0.42179206 0.45577744 0.60517734]\n",
      " [0.17750995 0.43787485 0.43018436 0.43428063]]\n",
      "actions:  [3 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.2]\n",
      " [4.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [00:04<00:01, 18.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.47043958 0.3558515  0.39912602 0.48537776]\n",
      " [0.07860938 0.31723836 0.34388697 0.30841923]]\n",
      "actions:  [3 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.2]\n",
      " [4.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  74\n",
      "q_values:  [[0.41739148 0.404618   0.39371938 0.37068808]\n",
      " [0.19163084 0.21334298 0.30559316 0.3938958 ]]\n",
      "actions:  [0 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.2]\n",
      " [4.3]], shape=(2, 1), dtype=float32)\n",
      "iteration:  75\n",
      "q_values:  [[0.3834382  0.5191325  0.30431286 0.35989094]\n",
      " [0.3703457  0.24924798 0.32145202 0.45974773]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.7]\n",
      " [4.8]], shape=(2, 1), dtype=float32)\n",
      "iteration:  76\n",
      "q_values:  [[0.04207272 0.23098817 0.2627423  0.15716666]\n",
      " [0.12085456 0.2292923  0.1566521  0.14299808]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.7      ]\n",
      " [4.6000004]], shape=(2, 1), dtype=float32)\n",
      "iteration:  77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [00:04<00:01, 18.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.03173975 0.17669444 0.28834367 0.18978743]\n",
      " [0.4525295  0.5324887  0.38421184 0.3872868 ]]\n",
      "actions:  [2 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.7      ]\n",
      " [4.6000004]], shape=(2, 1), dtype=float32)\n",
      "iteration:  78\n",
      "q_values:  [[0.06365838 0.27927813 0.24752383 0.19769217]\n",
      " [0.5397861  0.5673266  0.43058935 0.48589337]]\n",
      "actions:  [1 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.7      ]\n",
      " [4.6000004]], shape=(2, 1), dtype=float32)\n",
      "iteration:  79\n",
      "q_values:  [[0.03237379 0.18591332 0.09388985 0.17561561]\n",
      " [0.6052703  0.49502373 0.43972906 0.5363112 ]]\n",
      "actions:  [1 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.7      ]\n",
      " [5.1000004]], shape=(2, 1), dtype=float32)\n",
      "iteration:  80\n",
      "q_values:  [[0.08471679 0.12848449 0.15569879 0.27562386]\n",
      " [0.28566742 0.44420773 0.38473472 0.3028028 ]]\n",
      "actions:  [3 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.5      ]\n",
      " [5.1000004]], shape=(2, 1), dtype=float32)\n",
      "iteration:  81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [00:04<00:00, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.31564003 0.26741567 0.3139933  0.40150872]\n",
      " [0.25443387 0.4857933  0.4527796  0.2956432 ]]\n",
      "actions:  [3 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.5      ]\n",
      " [5.1000004]], shape=(2, 1), dtype=float32)\n",
      "iteration:  82\n",
      "q_values:  [[0.40724227 0.35684314 0.42654863 0.4871841 ]\n",
      " [0.28666052 0.3720023  0.5466043  0.36575487]]\n",
      "actions:  [3 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.5      ]\n",
      " [5.6000004]], shape=(2, 1), dtype=float32)\n",
      "iteration:  83\n",
      "q_values:  [[ 0.44148085  0.41708022  0.5404537   0.5729296 ]\n",
      " [-0.04687074  0.12164178  0.18189879  0.16842663]]\n",
      "actions:  [3 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.5      ]\n",
      " [5.6000004]], shape=(2, 1), dtype=float32)\n",
      "iteration:  84\n",
      "q_values:  [[ 0.4627325   0.50832     0.57721645  0.58591443]\n",
      " [-0.02896763  0.27315968  0.22752197  0.22486766]]\n",
      "actions:  [3 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[4.5      ]\n",
      " [5.5000005]], shape=(2, 1), dtype=float32)\n",
      "iteration:  85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [00:05<00:00, 18.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.51777864 0.5387674  0.5519471  0.5167261 ]\n",
      " [0.15424371 0.3307487  0.37832236 0.31445006]]\n",
      "actions:  [2 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.       ]\n",
      " [5.5000005]], shape=(2, 1), dtype=float32)\n",
      "iteration:  86\n",
      "q_values:  [[0.1412453  0.18891573 0.08792777 0.15963876]\n",
      " [0.32432774 0.4343385  0.49333432 0.51930857]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.       ]\n",
      " [5.5000005]], shape=(2, 1), dtype=float32)\n",
      "iteration:  87\n",
      "q_values:  [[0.21021168 0.15513566 0.12251611 0.15881167]\n",
      " [0.32068494 0.4276526  0.43991745 0.49088898]]\n",
      "actions:  [0 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.       ]\n",
      " [5.5000005]], shape=(2, 1), dtype=float32)\n",
      "iteration:  88\n",
      "q_values:  [[0.2600229  0.17783314 0.10637942 0.22713679]\n",
      " [0.37305018 0.45622498 0.5056252  0.45902914]]\n",
      "actions:  [0 2]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.       ]\n",
      " [5.5000005]], shape=(2, 1), dtype=float32)\n",
      "iteration:  89\n",
      "q_values:  [[0.3192988  0.28429285 0.11816648 0.2624855 ]\n",
      " [0.26403442 0.5258195  0.35011622 0.31147704]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.       ]\n",
      " [5.5000005]], shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [00:05<00:00, 18.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  90\n",
      "q_values:  [[0.4464003  0.33717105 0.23394403 0.36298645]\n",
      " [0.1634761  0.5024046  0.21831733 0.22132567]]\n",
      "actions:  [0 1]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.       ]\n",
      " [6.0000005]], shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [00:05<00:00, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  91\n",
      "q_values:  [[ 0.56809694  0.42332876  0.32578763  0.44011584]\n",
      " [-0.08350582 -0.0427687  -0.07609106  0.02113342]]\n",
      "actions:  [0 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.5      ]\n",
      " [5.8000007]], shape=(2, 1), dtype=float32)\n",
      "iteration:  92\n",
      "q_values:  [[-0.01056115  0.14014904  0.02532268  0.05271514]\n",
      " [ 0.28690615  0.24723834  0.23147891  0.29231855]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.5      ]\n",
      " [5.8000007]], shape=(2, 1), dtype=float32)\n",
      "iteration:  93\n",
      "q_values:  [[-0.02881656  0.19327402  0.0847214  -0.01044862]\n",
      " [ 0.31331834  0.2624558   0.24373175  0.29484594]]\n",
      "actions:  [1 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.5      ]\n",
      " [5.8000007]], shape=(2, 1), dtype=float32)\n",
      "iteration:  94\n",
      "q_values:  [[-0.06285942  0.11093356  0.05023247 -0.008702  ]\n",
      " [ 0.4084013   0.31569797  0.27744865  0.37572268]]\n",
      "actions:  [1 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.5      ]\n",
      " [5.8000007]], shape=(2, 1), dtype=float32)\n",
      "iteration:  95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [00:05<00:00, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[-0.02484999  0.11447197  0.09193831  0.0045889 ]\n",
      " [ 0.45332232  0.36242864  0.33719847  0.44685307]]\n",
      "actions:  [1 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.5      ]\n",
      " [5.8000007]], shape=(2, 1), dtype=float32)\n",
      "iteration:  96\n",
      "q_values:  [[0.02880315 0.12624349 0.15774642 0.07575237]\n",
      " [0.47788143 0.3652673  0.39338642 0.53568554]]\n",
      "actions:  [2 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.5      ]\n",
      " [5.8000007]], shape=(2, 1), dtype=float32)\n",
      "iteration:  97\n",
      "q_values:  [[0.01632046 0.21856013 0.27757412 0.26101494]\n",
      " [0.5694499  0.40239906 0.42602777 0.5880786 ]]\n",
      "actions:  [2 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.5      ]\n",
      " [5.8000007]], shape=(2, 1), dtype=float32)\n",
      "iteration:  98\n",
      "q_values:  [[0.07768106 0.35794377 0.25155586 0.3332189 ]\n",
      " [0.67007494 0.5127143  0.44416845 0.5224906 ]]\n",
      "actions:  [1 0]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.4      ]\n",
      " [6.3000007]], shape=(2, 1), dtype=float32)\n",
      "iteration:  99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_values:  [[0.26628053 0.40516195 0.39650664 0.39761943]\n",
      " [0.12463736 0.15547496 0.10064245 0.16820559]]\n",
      "actions:  [1 3]\n",
      "rewards:  tf.Tensor(\n",
      "[[5.3      ]\n",
      " [6.3000007]], shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEp0lEQVR4nO3dPW7baBSG0UuBaQIQ7gW7yx6mibOA6WYVLlxlMSmyCndZQJIiWYcBboDANDb0TZM/TBCZ8CuTEnxOLUK3EHAfXBtg11prBQDAo23WHgAA4NQJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUD/nQ7vdrsZxrGEYquu6p56JZ6q1VtM01Xa7rc1G6wP72U0sYe5umhVU4zjWxcXFwYaDfW5vb+v8/HztMYAjZzexpId206ygGoahqqpe19/V14vDTAb/c1939bk+/Pi9AexjN7GEubtpVlB9P6X29aL6zo+WJ/LtrZJO98AcdhOLmLmb/KMKAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhGa9HDn17z9/LfE1T+LTu/ePfvby+uqAk5yOlzdf1x4B4EGnvJueq/HN/hcU7/Pq7ZcDTvI7FyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9gDH7vL6au0RAICq2n5sa4/wRy5UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHgAATtGnd+8f/ezl9dUBJ+EYuFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF97AAA4RZfXV2uPwBFxoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVrDzDH+KZ79LPbj+2AkwAA/M6FCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1C/xJS9vvkbPv7o50CAA8E26m+BXLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+zodaa1VVdV93Ve1J5+EZu6+7qvr5ewPYx25iCXN306ygmqapqqo+14dwLHjYNE11dna29hjAkbObWNJDu6lrM84Bu92uxnGsYRiq67qDDgjftdZqmqbabre12fhrNLCf3cQS5u6mWUEFAMCfOQMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT+A38WkI580UxLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEp0lEQVR4nO3dMW7cZhCG4eGCbgwQ6hdS5zukiXyAdDmFClU5jAufQp0PYLuIzyGAFyCQRsL+aewkiOEVoY8i19jnqZfYKRaYFyMB7FprrQAAeLbd1gMAAPzsBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKif86HD4VDjONYwDNV13UvPxJlqrdU0TbXf72u30/rAcXYTa5i7m2YF1TiOdXV1tdhwcMz9/X1dXl5uPQZw4uwm1vTUbpoVVMMwVFXVr/Vb9fVqmcngfx7roT7Xh39+bwDH2E2sYe5umhVU306pfb2qvvOj5YV8fauk0z0wh93EKmbuJv+oAgAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKFZL0dO/fX7L2t8DSfi9d2XrUcAeJLd9PMZ3x5/QfExb/74c8FJvudCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6rce4NR9evf+2c9e394sOAkAnLf9x7b1CD/kQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChfusBTt317c3WIwAAJ86FCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G89AACcm0/v3kfPX9/eLDQJS3GhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9QAAcG6ub2+2HoGFuVABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6rQeYY3zbPfvZ/ce24CQAAN9zoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVrfMnruy/R82/uFhoEAL5KdxP8lwsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECon/Oh1lpVVT3WQ1V70Xk4Y4/1UFX//t4AjrGbWMPc3TQrqKZpqqqqz/UhHAueNk1TXVxcbD0GcOLsJtb01G7q2oxzwOFwqHEcaxiG6rpu0QHhm9ZaTdNU+/2+djt/jQaOs5tYw9zdNCuoAAD4MWcAAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQ39xdkJBKVWVSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEpElEQVR4nO3dMW7UeBTH8eeRaZCs9KOk4w7bkBxguz1FilR7GApOkY4DAAWcI5IvYIkm0ZgG2N1ETP6b38QexOdTjzWvGOl99RLJ3TzPcwEA8GSbtQcAAPjVCSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFDf8qHdblfjONYwDNV13XPPxG9qnueapqm2221tNlof2M9uYgmtu6kpqMZxrLOzs4MNB/vc3NzU6enp2mMAR85uYkmP7aamoBqGoaqqXtef1deLw0wG99zVbX2sdz9+bwD72E0soXU3NQXV91NqXy+q7/xoeSbf3irpdA+0sJtYRONu8o8qAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGp6OXLqy19/LPE1HImX15/XHgHgUXbTr2e82P+C4n1e/f3pgJM85EIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq1x4AAKDF9v289gg/5UIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7tAY7dhzdvn/zs+dXlAScBAI6VCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhfe4Bjd351ufYIAPAfH968ffKz9trzcKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2AADA/3N+dbn2CNzjQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHqDFeNE9+dnt+/mAkwAAPORCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6pf4kpfXn6PnX10faBAA+CbdTfBvLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKG+5UPzPFdV1V3dVs3POg+/sbu6rap/fm8A+9hNLKF1NzUF1TRNVVX1sd6FY8Hjpmmqk5OTtccAjpzdxJIe203d3HAO2O12NY5jDcNQXdcddED4bp7nmqapttttbTb+Gg3sZzexhNbd1BRUAAD8nDMAAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEDoK7ILkJA2Mg6sAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEmUlEQVR4nO3dMW4bVxRA0U+BbgwQ6gmp8x7SxF5AuqzChassJkVWoc4LcFzE6xDADQzgRoImjZ0EMUQNdClShs+pSfAVA7yLJwGzmud5HgAAPNrZqQcAAPjeCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAovWSD93d3Y3dbjc2m81YrVZPPRM/qHmexzRNY7vdjrMzrQ/sZzdxDEt306Kg2u124/Ly8mDDwT7X19fj4uLi1GMAz5zdxDE9tJsWBdVmsxljjPHz+GWsx4vDTAb/cztuxsfx/p/nDWAfu4ljWLqbFgXV11PqerwY65WHlify5a2STvfAEnYTR7FwN/lHFQCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAA0aKXI1eff/3pGD/DM/Hy6tOpRwB4kN30/dm92f+C4n1e/fbXASf5lgsVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAA0frUAwAALLH9MJ96hHu5UAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAAKL1qQd47v78/Y9Hf/f1u7cHnAQAurLXxrDb7uNCBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCI1qce4Ll7/e7tqUcAgIOx156GCxUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAETrUw+wxO7N6tHf3X6YDzgJAMC3XKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCI1sf4kZdXn9L3X10daBAA+KLuJvgvFyoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCI1ks+NM/zGGOM23Ezxvyk8/ADux03Y4x/nzeAfewmjmHpbloUVNM0jTHG+Djex7HgYdM0jfPz81OPATxzdhPH9NBuWs0LzgF3d3djt9uNzWYzVqvVQQeEr+Z5HtM0je12O87O/DUa2M9u4hiW7qZFQQUAwP2cAQAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCI/gbg+5COwjcAZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEpElEQVR4nO3dPW7baBSG0UuBaQIQ7gW7yx6mGWcB080qXLjKYlJ4Fe6ygCTFZB0GuAECaWzoS5M/xBOZ8CuTMnJOLUK3EHAfXBtg11prBQDAo23WHgAA4LkTVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7Oh3a7XY3jWMMwVNd1Tz0Tf6jWWk3TVNvttjYbrQ/sZzexhLm7aVZQjeNYZ2dnBxsO9rm5uanT09O1xwCOnN3Ekh7aTbOCahiGqqr6u/6pvl4cZjL4xV3d1sd69/33BrCP3cQS5u6mWUH17ZTa14vqOz9ansjXt0o63QNz2E0sYuZu8o8qAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEJr1cuTU53//WuJrOBIvrz+tPQLAg+ym52d8vf8Fxfu8evPfASe5z4UKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrz0AAMAc2/dt7RF+y4UKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3aAwAAz8eHt1ePfvb88uKAkxwXFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9WsPcOw+vL169LPnlxcHnAQA1me3/T8XKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw9w7M4vL9YeAQA4ci5UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHmCO8XX36Ge379sBJwEAuM+FCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1C/xJS+vP0XPv7o+0CAA8FW6m+BnLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+zodaa1VVdVe3Ve1J5+EPdle3VfXj9wawj93EEubupllBNU1TVVV9rHfhWPCwaZrq5ORk7TGAI2c3saSHdlPXZpwDdrtdjeNYwzBU13UHHRC+aa3VNE213W5rs/HXaGA/u4klzN1Ns4IKAIDfcwYAAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAh9AdHZkJD2caoHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEq0lEQVR4nO3dMWrceBTH8adBaQLC/WB3uUOadQ6w3Z7ChascJkVO4S4HSFJszmHQBQTb2Mx/m2Q3JGQs/BtLMvl86hHzioH35dmgrrXWCgCAR9utPQAAwHMnqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv2cDx0OhxrHsYZhqK7rnnomflOttZqmqfb7fe12Wh84zm5iCXN306ygGsexLi4uTjYcHHN7e1vn5+drjwFsnN3Ekh7aTbOCahiGqqr6o/6svl6cZjL4wX3d1ef68N/vDeAYu4klzN1Ns4Lq2ym1rxfVd360PJGvb5V0ugfmsJtYxMzd5B9VAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAIDTr5cipf/56vcTXsBEvb76sPQLAg+ym52d8c/wFxce8evv3CSf5mQsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3sAAIA59h/b2iP8kgsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPq1BwAAno9P794/+tnL66sTTrItLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QEAgOfj8vpq7RE2yYUKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrz3A1n169/7Rz15eX51wEgBgq1yoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/doDbN3l9dXaIwAAG+dCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QHmGN90j352/7GdcBIAgJ+5UAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPolvuTlzZfo+Vc3JxoEAL5KdxN8z4UKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUz/lQa62qqu7rrqo96Tz8xu7rrqr+/70BHGM3sYS5u2lWUE3TVFVVn+tDOBY8bJqmOjs7W3sMYOPsJpb00G7q2oxzwOFwqHEcaxiG6rrupAPCN621mqap9vt97Xb+Gg0cZzexhLm7aVZQAQDwa84AAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChfwE+n5CS4d2s9gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEpElEQVR4nO3dP27UXBTG4eORaZCs9KOkYw80hAV8HatIkYrFULCKdCwAKGAdkbwBS1+TaEzDP4GYXOWd2AN5nnqufApL56ebSO7meZ4LAIB726w9AADA305QAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+pYf7Xa7GsexhmGoruseeiYeqXmea5qm2m63tdlofWA/u4kltO6mpqAax7HOzs4ONhzsc319Xaenp2uPARw5u4kl3bWbmoJqGIaqqnpR/1VfTw4zGfzitm7qY737/r4B7GM3sYTW3dQUVN+uUvt6Un3npeWBfP2qpKt7oIXdxCIad5N/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQ08eRU/+/er7EYzgST68+rz0CwJ3spr/P+HL/B4r3efb60wEn+Z0bKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2AAAALbbv57VH+CM3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq1x4AAHgcPrx5G50/v7w40CSH54YKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrz0AAPA4nF9erD3Cg3FDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tce4Nh9ePP23mfPLy8OOAkAcKzcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3uAFuPL7t5nt+/n6NnnlxfReQDg3+eGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1C/xkKdXn6Pzz64ONAgAfJXuJviZGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFDf8qN5nquq6rZuquYHnYdH7LZuqurH+wawj93EElp3U1NQTdNUVVUf6104FtxtmqY6OTlZewzgyNlNLOmu3dTNDdcBu92uxnGsYRiq67qDDgjfzPNc0zTVdrutzcZfo4H97CaW0LqbmoIKAIA/cw0AABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABD6AsbYkJCNWIipAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAElUlEQVR4nO3dsW1bZxSA0Z8C3Rgg1BNS5x3SRB4gXaZQoSrDuPAU6ryAXcRzCOACBNJI4EtjJ0GMUA/+KFKOzqn5wFsQuB+uBLzFNE3TAADgu52degAAgB+doAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgWs750G63G5vNZqxWq7FYLJ56Jl6oaZrGdrsd6/V6nJ1pfWA/u4ljmLubZgXVZrMZl5eXBxsO9rm7uxsXFxenHgN45uwmjumx3TQrqFar1RhjjJ/HL2M5Xh1mMviXh3E/Po0Pf/3eAPaxmziGubtpVlB9PaUux6uxXPjR8kS+vFXS6R6Yw27iKGbuJv+oAgAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgmvVy5OqPX386xtfwTLy+/XzqEQAeZTf9eDZv97+geJ83v/1+wEm+5UIFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAtDz1AADAy/Dx3fv0/NXN9YEmOTwXKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAtDz1AADAy3B1c33qEZ6MCxUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEy1MP8NQ+vnufnr+6uT7QJADA/5ULFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgWp56gDk2bxff/ezVzfUBJwEA+JYLFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAANHyGF/y+vZzev7N7YEGAYAv6m6Cf3KhAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgGg550PTNI0xxngY92NMTzoPL9jDuB9j/P17A9jHbuIY5u6mWUG13W7HGGN8Gh/iWPC47XY7zs/PTz0G8MzZTRzTY7tpMc04B+x2u7HZbMZqtRqLxeKgA8JX0zSN7XY71uv1ODvz12hgP7uJY5i7m2YFFQAA/80ZAAAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIDoT9LMjNirF7YJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEj0lEQVR4nO3dMW4bVxRA0U+BbgwQ6gmpsveQJt5AuqzCBlxlMS68BFfqvAG7iNchgBsYII0ETho7CWJEGuhSpAKfU/NjXjHAu/gkwNU8z/MAAODBzk49AADA/52gAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACBaL/nQfr8fu91ubDabsVqtHnsmflDzPI9pmsZ2ux1nZ1ofuJvdxDEs3U2Lgmq3243Ly8uDDQd3ub6+HhcXF6ceA3ji7CaO6b7dtCioNpvNGGOMn8cvYz2eHWYy+JfbcTM+j49/vW8Ad7GbOIalu2lRUH27Sl2PZ2O98tLySL7+q6Sre2AJu4mjWLib/FAFACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEC06M+Rqz9+/ekYj+GJeH715dQjANzLbjq+T+/ep/MvPrx58NmXv/2enn0fN1QAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBE61MPAAD8GF69fZ3Ob8d8oEkOzw0VAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCAaH3qAZb49O79g8++evv6gJMAAHzPDRUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIFqfeoAlXnx48+Cz2zEfcBIAgO+5oQIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACBaH+Mhz6++pPMvrw40CAB8VXcT/JMbKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIjWSz40z/MYY4zbcTPG/Kjz8AO7HTdjjL/fN4C72E0cw9LdtCiopmkaY4zxeXyMY8H9pmka5+fnpx4DeOLsJo7pvt20mhdcB+z3+7Hb7cZmsxmr1eqgA8I38zyPaZrGdrsdZ2e+jQbuZjdxDEt306KgAgDgv7kGAACIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACD6E4S5jQh4aWqnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwUlEQVR4nO3dMW4UWRSG0VutIrFUcl6yiYgckZEMpEiTzWpYA6tgCc5YgCHxBojILNUGSprEVhcJzIyGcXep/3aVx5wT99O7QUv307OlbqZpmgoAgINt1h4AAOD/TlABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITaOR/abrc1DEN1XVdN0zz0TPyipmmqcRyr7/vabLQ+sJvdxBLm7qZZQTUMQ52fnx9tONjl5uamzs7O1h4DeOTsJpa0bzfNCqqu66qq6rf6vdp6dpzJ4F/u6rY+18e/vm8Au9hNLGHubpoVVD+eUtt6Vm3jS8sD+f6rkp7ugTnsJhYxczf5RxUAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAIzfpx5NSff7xa4hoeiZPL67VHANjLblrei3dfovMfnn86+Ozb/mV09z5eqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3aA3C/4U1z8Nn+ajriJACQ+/r+Ijr/ug4/f1LX0d37eKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv2ANyvv5rWHgGAJ2Z400Tn7ab/5oUKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj0AALCc/mpae4QnyQsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXXuAOV68+3Lw2a/vL444CQDAz7xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhde4A5Pjz/dPDZ13VxxEkAAH7mhQoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINQuccnJ5XV0/u3ly8PvruxuAJ6mdDfBP3mhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItXM+NE1TVVXd1W3V9KDz8Au7q9uq+vv7BrCL3cQS5u6mWUE1jmNVVX2uj+FYsN84jnV6err2GMAjZzexpH27qZlmPAdst9sahqG6rqumaY46IPwwTVON41h939dm46/RwG52E0uYu5tmBRUAAPfzDAAAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEPoGpoaXI/irN1AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEu0lEQVR4nO3dMW7cVhSG0csB3Qgg1BNSqiwgXVxEbg2kyypUaAFZSYpUWYI7L0B2ow1kAwK4AQJuJAzTxAkQRSNifoqU7XPqeeAtCNwPbwaYZpqmqQAAONpu6wEAAL50ggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINTO+dB+v69hGKrrumqa5rln4hs1TVON41h939dup/WBw+wm1jB3N80KqmEY6vz8fLHh4JDb29s6OzvbegzghbObWNNTu2lWUHVdV1VVP9XP1darZSaD/7ivu/pY7/953wAOsZtYw9zdNCuoPl+ltvWq2sZLyzP5+18lXd0Dc9hNrGLmbvJDFQCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAjN+nPk1KdfflzjMbwQJ+9uth4B4El205fn+1//PPrs8HpccJKH3FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITarQfgccOb5uiz/fW04CQAsL0/vvtw9Nm39cNyg/wPN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQarcegMf119PWIwDwlRneNNH5LXfTxdXl0WdP6mbBSR5yQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGq3HgAAWE9/PW09wlfJDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKjdeoA5Pvz2+9FnL64uF5wEAOAhN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQarceYI6Lq8utRwAAeJQbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULvGQ07e3azxGACYzW5iSW6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7ZwPTdNUVVX3dVc1Pes8fMPu666q/n3fAA6xm1jD3N00K6jGcayqqo/1PhwLnjaOY52enm49BvDC2U2s6and1EwzrgP2+30Nw1Bd11XTNIsOCJ9N01TjOFbf97Xb+TYaOMxuYg1zd9OsoAIA4HGuAQAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQn8BJGSVYiCNEUUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAErElEQVR4nO3dMW4bVxSG0TvEuBFAqB9I60gTeQHpsoRUKrQeF16FOi9AdqNtRMBsYAA3EvjS2A4QQORAPzmjSOfUHL5bDHA/PAlg11prBQDAi23WHgAA4P9OUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPo5H9rtdjWOY2232+q67tQz8U611mqaphqGoTYbrQ/sZzexhLm7aVZQjeNYl5eXRxsO9nl4eKiLi4u1xwBeObuJJR3aTbOCarvdVlXV7/VH9fXhOJPBfzzVY32rL7/eN4B97CaWMHc3zQqqn1epfX2ovvPSciI/flXS1T0wh93EImbuJv+oAgAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKFZP46c+v7nb0scwytxdnu/9ggAB9lN78upd5MbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2ADxv/Ni9+Nnhrh1xEgDIff30OXr+r7+vXvzseBsdfZAbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw/A84a7tvYIALwx48cuej7ZTVc319HZibO6P+n3u6ECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw8AACxnuGtrj/AmuaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw9wal8/fY6ev7q5PtIkAMBb5YYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3aA5za1c312iMAAG+cGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/xCFnt/dLHAMAs9lNHJMbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUD/nQ621qqp6qseqdtJ5eMee6rGq/n3fAPaxm1jC3N00K6imaaqqqm/1JRwLDpumqc7Pz9ceA3jl7CaWdGg3dW3GdcBut6txHGu73VbXdUcdEH5qrdU0TTUMQ202/hoN7Gc3sYS5u2lWUAEA8DzXAAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX8AXcaWcYrQpjAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAErUlEQVR4nO3dMWocdxTH8TfLuDEM6hfpArlAmsgHcJcjpFKhk/gALnwKdz6A7MZ3SGXBXGDAjcT+UySOIaDVoN/uzEb6fOod5hUL78uTYLvWWisAAJ5ss/YAAAD/d4IKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUz/nQbrercRxrGIbquu7YM/FCtdZqmqbabre12Wh9YD+7iSXM3U2zgmocx7q4uDjYcLDP7e1tnZ+frz0GcOLsJpb02G6aFVTDMFRV1W/1tvp6dZjJ4D/u666+1Kd/v28A+9hNLGHubpoVVD9OqX29qr7zpeVI/vlVSad7YA67iUXM3E3+UQUAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCs34cOfX991+XeA0n4vXHr2uPAPAou+llOfZucqECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw/Aw8Y33ZOf3d60A04CAH/7/P7Dk5/949tl9O4/3/0SPX9MLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tcegIdtb9raIwDwzIxvuuj5y+urA03yvLhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUHAACWs71pa4/wLLlQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUHOHWf33948rOX11cHnAQAOFUuVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq1x7g1F1eX609AgBw4lyoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/RIvef3x6xKvAYDZ7CYOyYUKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUz/lQa62qqu7rrqoddR5esPu6q6qf3zeAfewmljB3N80KqmmaqqrqS30Kx4LHTdNUZ2dna48BnDi7iSU9tpu6NuMcsNvtahzHGoahuq476IDwQ2utpmmq7XZbm42/RgP72U0sYe5umhVUAAA8zBkAACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACD0FxIMk73JCv1dAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAErElEQVR4nO3dMWocdxTH8TfLuDEM6gepSpcLpIlyAHc5QioHfJIcwIWPkMqdDyC78R1cRTAXGHAjsf80cQIhWg36rWY20udT7zCvWHhfngTbtdZaAQDwYLutBwAA+L8TVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7Jh/b7fU3TVMMwVNd1jz0Tz1RrreZ5rnEca7fT+sBhdhNrWLqbFgXVNE11cXFxtOHgkOvr6zo/P996DODE2U2s6b7dtCiohmGoqqof61X19eI4k8G/3NZNfaoPf3/fAA6xm1jD0t20KKi+nVL7elF950vLI/nrVyWd7oEl7CZWsXA3+UcVAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACC36ceTU159/WOM1nIiX7z9vPQLAveym5+Wxd5MLFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqN96AO42/dQ9+Nnxqh1xEgCeio9v30XP//LH5YOf/fLb99G7T5kLFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6rQfgbuNV23oEAJ6Y737/NXrebvpvLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+6wEAgPWMV23rEZ4kFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9QCn7uPbdw9+9vLN6yNOAgCcKhcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/UAp+7yzeutRwAATpwLFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6NV7y8v3nNV4DAIvZTRyTCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhf8qHWWlVV3dZNVXvUeXjGbuumqv75vgEcYjexhqW7aVFQzfNcVVWf6kM4Ftxvnuc6OzvbegzgxNlNrOm+3dS1BeeA/X5f0zTVMAzVdd1RB4RvWms1z3ON41i7nb9GA4fZTaxh6W5aFFQAANzNGQAAICSoAABCggoAICSoAABCggoAICSoAABCggoAIPQncW6UmHOD+VQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwUlEQVR4nO3dv23cBhTH8ccD3Rgg1BNSKldZII3lAdJlChUawDNkgBSpMoI6DyC78QKp0gngAgTSSDim8R8ggE6Efnfk+fT51EfwFQe8L54EXDNN01QAADzbZu0BAAB+dIIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUzvnQdrutYRiq67pqmubQM/FCTdNU4zhW3/e12Wh9YDe7iSXM3U2zgmoYhrq4uNjbcLDL3d1dnZ+frz0GcOTsJpb01G6aFVRd11VV1dv6tdp6tZ/J4H8e6r4+1Ydv3zeAXewmljB3N80Kqq+n1LZeVdv40nIgX35V0ukemMNuYhEzd5N/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQrB9HTv372y9LvIYj8frm89ojADzJbnpZDr2bXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt2gPwuOFd8+xn+9tpj5MAcCrevP97tXf/8/vPq7370FyoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINSuPQCP62+ntUcA4MT89dPH6PnL66s9TXJaXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt2gMAAMu5vL5ae4ST5EIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbtAY7dxz/+fPazl9dXe5wEADhWLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQatce4NhdXl+tPQIAcORcqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj0AAPyIhnfNs5/tb6c9TsIxcKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1S7zk9c3nJV4DALOlu+nNzZ4G4SS4UAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNo5H5qmqaqqHuq+ajroPLxgD3VfVd+/bwC72E0sYe5umhVU4zhWVdWn+hCOBU8bx7HOzs7WHgM4cnYTS3pqNzXTjHPAdrutYRiq67pqmmavA8JX0zTVOI7V931tNv4aDexmN7GEubtpVlABAPA4ZwAAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgNB/yAWVIUMThncAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwElEQVR4nO3dsW3baBjH4ZcC0wQg3BN2lyoLXHPOAOluChceIDNkgBSZwl0GcNJkgVTpDHABAmlsiNdcLrgDLBP6y6RiP0+tD3wLAu8PnwSomaZpKgAA9rZZewAAgN+doAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVzPrTdbmsYhuq6rpqmeeyZeKamaapxHKvv+9pstD6wm93EEubupllBNQxDnZ2dHWw42OXm5qZOT0/XHgM4cnYTS3poN80Kqq7rqqrqz3pbbb04zGTwP3d1W1/q07/vG8AudhNLmLubZgXVz6vUtl5U23hpeST//Kukq3tgDruJRczcTX6oAgAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKFZf46c+vHXH0s8hiPx8urr2iMAPMhuel4eeze5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVrD8D9hjfN3mf76+mAkwDwVLx69y06//396wNN8rS4oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu/YA3K+/ntYeAQD+4/OHj3ufPb+8OOAkx8UNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF17gGP3+cPHvc+eX14ccBIAyH1//zo6f17Z+afKDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2rUHOHbnlxdrjwAAHDk3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbtAQDgdzS8afY+219PB5yEY+CGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1C7xkJdXX5d4DADMlu6mV1cHGoQnwQ0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEConfOhaZqqququbqumR52HZ+yubqvq1/sGsIvdxBLm7qZZQTWOY1VVfalP4VjwsHEc6+TkZO0xgCNnN7Gkh3ZTM824DthutzUMQ3VdV03THHRA+GmaphrHsfq+r83Gt9HAbnYTS5i7m2YFFQAA93MNAAAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ+huxDZZ3nZEtcAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvElEQVR4nO3dsW3cZhjH4ZcHujFAqCekVK6yQJrIA6TLFCo0QGbIAClceQR1HkB24wVSpRPABQikkXBMkdgGAuhE6M8jZel56iO+tyDw/vDdAddM0zQVAACPttt6AACA752gAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItXM+tN/vaxiG6rqumqY59ky8UNM01TiO1fd97XZaHzjMbmINc3fTrKAahqHOzs4WGw4Oubm5qdPT063HAJ44u4k1PbSbZgVV13VVVfVz/VJtvVpmMvifu7qtT/Xh6/sGcIjdxBrm7qZZQfXlKrWtV9U2XlqO5L9/lXR1D8xhN7GKmbvJD1UAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgNOvPkVN///rTGsfwRLy++rz1CAAPsptelmPvJjdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdusBuN/wtnn0s/31tOAkAMAhbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G49APfrr6etRwDgmXnz25+bnf3+h4/R8+eXFwtNsjw3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbrAZ6zj3+8i54/v7xYaBIA+Ndfv/+42dnntd3Zx+aGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt1gM8Z+eXF1uPAACswA0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECo3XoAAPgeDW+bRz/bX08LTsJT4IYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrnHI66vPaxwDALOlu+nN1UKD8Cy4oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVzPjRNU1VV3dVt1XTUeXjB7uq2qr69bwCH2E2sYe5umhVU4zhWVdWn+hCOBQ8bx7FOTk62HgN44uwm1vTQbmqmGdcB+/2+hmGoruuqaZpFB4QvpmmqcRyr7/va7XwbDRxmN7GGubtpVlABAHA/1wAAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF/APTVlHcLMuFaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuUlEQVR4nO3dMW7UaBjH4dcj00Sy0o+Srai22o6G0CLRcQoKDrBn2ANssdUeIR0HAJpcgIouki9giSbRmAZYaYGJNX/HDsnz1GN9b2Hp/embkaYZx3EsAAAOtll7AACAX52gAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItVM+tNvtqu/76rqumqa57Zl4oMZxrGEYarvd1maj9YH97CaWMHU3TQqqvu/r9PR0tuFgn8vLyzo5OVl7DOCOs5tY0k27aVJQdV1XVVVP60W19WieyeB/ruuq3tebb+8bwD52E0uYupsmBdXXq9S2HlXbeGm5JV/+VdLVPTCF3cQiJu4mP1QBAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCA0KQ/R059evlkiWO4I47OL9YeAeBGdtPDctu7yQ0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXXsAfq5/1hz87PbtOOMkAMA+bqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K49wH327u9/oufPXr+aaRIAmMfjPz+sdva/v707+Nnn53/MN8gPuKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1aw9wn529frX2CAAwq49//b7a2Wd1+NlHdTHjJN9zQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdu0BAOBX1D9rDn52+3accRLuAjdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdolDjs4vljgGACZLd9Pj85kG4V5wQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGqnfGgcx6qquq6rqvFW5+EBu66rqvrvfQPYx25iCVN306SgGoahqqre15twLLjZMAx1fHy89hjAHWc3saSbdlMzTrgO2O121fd9dV1XTdPMOiB8NY5jDcNQ2+22NhvfRgP72U0sYepumhRUAAD8nGsAAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQZy86k4Qetb3BAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEv0lEQVR4nO3dMWocZxjH4XeWcSMY1A9SFVep0rmx3Qbc+RQO+AA5Qw7gwkdIpc4HsN3oAq7cCeYCA2kkdtLECSRkd9j/7owsPU+9385bDLw/Pgm2maZpKgAADrZZewAAgO+doAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVzPrTdbmsYhuq6rpqmOfVMPFLTNNU4jtX3fW02Wh/YzW5iCXN306ygGoahLi8vjzYc7HJzc1MXFxdrjwHcc3YTS9q3m2YFVdd1VVX1vF5VW0+OMxn8y13d1uf68Pf7BrCL3cQS5u6mWUH17Sq1rSfVNl5aTuSvX5V0dQ/MYTexiJm7yT+qAACEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQGjWjyOn/nj9bInHcE+cXV2vPQLAXnbT43Lq3eSGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K49wEP26d376PwPv/9y8Nn+4xQ9GwCYzw0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNq1B3jIXrx9E53vazrSJACwvqe/flnt2cPVab/fDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdewAA4HH4+tuP0flP794ffPbn+il69j5uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj0AAMAcL96+OfjsWV0fcZL/ckMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBq1x4AAL5Hw8vm4LP9x+mIk3AfuKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1Szzk7Op6iccAwGzpbnp6daRBeBDcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNo5H5qmqaqq7uq2ajrpPDxid3VbVf+8bwC72E0sYe5umhVU4zhWVdXn+hCOBfuN41jn5+drjwHcc3YTS9q3m5ppxnXAdrutYRiq67pqmuaoA8I30zTVOI7V931tNv4aDexmN7GEubtpVlABAPD/XAMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT+BOq1lZ7E5kpcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEy0lEQVR4nO3dPW4bVxSG4TPEuBFAqCekVKqygTSRF+AuS0jlwgvwGrKAFKmyBHVegO1GG3CVKgJmAwO4kcBJEyfIH3XBj5pRyOepeTmnGOC8uBLAbpqmqQAA2Ntq6QEAAP7vBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhv+dB2u61hGGq9XlfXdU89EydqmqYax7E2m02tVlof2M1uYg6tu6kpqIZhqMvLy4MNB7vc3d3VxcXF0mMAz5zdxJwe201NQbVer6uq6tt6VX29OMxk8DcPdV8f690f7xvALnYTc2jdTU1B9eUqta8X1XdeWp7I778q6eoeaGE3MYvG3eQfVQAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDU9OPIqc/ffTPHY3gmzm5ulx4B4FF202l56t3khgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINQvPcAxu3r7KTr/81cf9j57/eZ19GwAoJ0bKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1Sw9wzH754evo/HVl5wHgmFy9/bT32eHmgIP8CzdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChfukBAIDT8OHHn6Lz3/96faBJDs8NFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6pQcAAE7D9ZvXiz37rG6f9PvdUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3qAFsPLbu+zm/fTAScBAPgnN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6pceoMXm/bT0CADwF8PLbu+z9trxcUMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq53jI2c3tHI8BgGbpbrq6OdAgHAU3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAob7lQ9M0VVXVQ91XTU86Dyfsoe6r6s/3DWAXu4k5tO6mpqAax7Gqqj7Wu3AseNw4jnV+fr70GMAzZzcxp8d2Uzc1XAdst9sahqHW63V1XXfQAeGLaZpqHMfabDa1WvlrNLCb3cQcWndTU1ABAPDfXAMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIR+A/bWmMNcbZ9WAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEyklEQVR4nO3dsW0bdxTH8XfEuRFAqCekVK68QJrIA7jLCKlceADPkAFSpMoI6jyA7UYLpEoVAbfAAW4k8NzYDpxA1D/8kXey9fnUPPIVBN4XTwLYTdM0FQAAe1stPQAAwLdOUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPqWF2232xqGodbrdXVdd+yZeKSmaapxHGuz2dRqpfWB3ewm5tC6m5qCahiGOj8/P9hwsMv19XWdnZ0tPQbwwNlNzOm+3dQUVOv1uqqqfqoX1deTw0wG/3JbN/W+3nz5vgHsYjcxh9bd1BRUn0+pfT2pvvOl5Ug+/aqk0z3Qwm5iFo27yT+qAACEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKjpx5FTH37+cY6P4YE4ubxaegSAe9lNj8uxd5MLFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF96AO729PWfez/716/PDjgJALCLCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+qUH4G5//PBu72cv6tkBJwEAdnGhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9UsPwN0uXr1cegQA+Mq7337f+9lf/r444CT/z3B53Pd3oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/QAAMC34+LVy6VH2MtJXR31/V2oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINQvPUCL4Xm397Obt9MBJwEA+C8XKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1Sw/QYvN2WnoEAPjK8Lzb+1l77fvjQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrn+JCTy6s5PgYAmqW76enlgQbhu+BCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6lteNE1TVVXd1k3VdNR5eMRu66aq/vm+AexiNzGH1t3UFFTjOFZV1ft6E44F9xvHsU5PT5ceA3jg7CbmdN9u6qaGc8B2u61hGGq9XlfXdQcdED6bpqnGcazNZlOrlb9GA7vZTcyhdTc1BRUAAHdzBgAACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACH0ENC2XUnpedtoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvUlEQVR4nO3dMW4cZRjH4XdWkybSyP3KpkrFBWhwDpCOI1ClyAE4AwegoOII7nKAJE0uQEWFpbnASGls7dAQECCvP/a/O+PYz1Pvp3mLkd6fvl1pu3me5wIA4GCbtQcAAPjSCSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFDf8qHdblfjONYwDNV13aln4oma57mmaartdlubjdYH9rObWELrbmoKqnEc6+Li4mjDwT7X19d1fn6+9hjAA2c3saT7dlNTUA3DUFVV39ar6uvZcSaDf7mtm/pQb/963wD2sZtYQutuagqqz1epfT2rvvPSciJ//qukq3ughd3EIhp3kx+qAACEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKjpz5FTn777ZonH8EA8v/q49ggA97KbnpZT7yY3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq1x6Au7344deDz/7y1fvo2ZdvXkfnAeApcUMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq1x6Au/3249cHn72sw88C8Hi9/+nn6Pz3v18eaZL/L9mLp+aGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL92gMAAMu5fPN67REeJTdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHqDF+LI7+Oz23XzESQAA/ssNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6tQdosX03rz0CAPzD+LI7+Ky99vi4oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVLPOT51cclHgMAzdLd9OLqSIPwKLihAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9S0fmue5qqpu66ZqPuk8PGG3dVNVf79vAPvYTSyhdTc1BdU0TVVV9aHehmPB/aZpqrOzs7XHAB44u4kl3beburnhOmC329U4jjUMQ3Vdd9QB4bN5nmuaptput7XZ+DYa2M9uYgmtu6kpqAAAuJtrAACAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCA0B+5GZZ3bKtFjAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEw0lEQVR4nO3dMW4cZRjH4XdWk8bSyP3KpkpFRZcGp0Wi4whUFByAM3AACiqO4C4HSNL4AlRUWJoLjERja4eGgAhi/WX/uzNO/Dz1fpq3GOn96duVtpvneS4AAA62WXsAAICPnaACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1LR/a7XY1jmMNw1Bd1516Jp6oeZ5rmqbabre12Wh9YD+7iSW07qamoBrHsS4vL482HOxze3tbFxcXa48BPHJ2E0t6aDc1BdUwDFVV9WV9XX09O85k8J77uqu39erv9w1gH7uJJbTupqageneV2tez6jsvLSfy179KuroHWthNLKJxN/mhCgBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAISa/hw59cc3L5Z4DI/E2fXN2iMAPMhuelpOvZvcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3sATuP5D79G53/57M3BZ7+6/iJ6NgB8bNxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUH4DR++/Hz6PxVHX7+rG6iZwOw35uffj747Le/Xx1xkg+T7qbHzA0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPq1BwAAPszV99+tPQLvcUMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7tAVqML7uDz25fz0ecBADgv9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhfe4AW29fz2iMAwL+ML7uDz9prnx43VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX6Jh5xd3yzxGABolu6m59dHGoRPghsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQ3/KheZ6rquq+7qrmk87DE3Zfd1X1z/sGsI/dxBJad1NTUE3TVFVVb+tVOBY8bJqmOj8/X3sM4JGzm1jSQ7upmxuuA3a7XY3jWMMwVNd1Rx0Q3pnnuaZpqu12W5uNb6OB/ewmltC6m5qCCgCA/+caAAAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg9CfUd5dhqyRE3gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEx0lEQVR4nO3dMW4cZRjH4XdWk8bSyP3KpkpFRZeGpEWi4whUFByAM3AACiqO4C4HSNL4AlSpYmkuMBKNrR0aAgLE+mP/65mN/Tz1fpq3GPn96VtL283zPBcAAAfbrD0AAMCnTlABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6lg/tdrsax7GGYaiu6x56Jp6oeZ5rmqbabre12Wh9YD+7iSW07qamoBrHsS4vL482HOxzc3NTFxcXa48BnDi7iSXdt5uagmoYhqqq+rK+rr6eHWcy+Ie7uq139frP9w1gH7uJJbTupqag+niV2tez6jsvLQ/kj1+VdHUPtLCbWETjbvKPKgAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBq+nHk1G/fvFjiMZyIs6vrtUcAuJfd9LQ89G5yQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChfu0BOE3Pf/j14LPj1REHAYBPgBsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/YAnKZfPnt78Nmv6ovjDQLwCL396efo/LcfXh5pkv/v/Y+fr/bsU+aGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL92gNwml5+/93BZ8/q+oiTADw+yd9YTpMbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw/QYnzVHXx2+2Y+4iQAAP/mhgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/doDtNi+mdceAQD+ZnzVHXzWXnt83FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6JR5ydnW9xGMAoFm6m55fHWkQHgU3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAob7lQ/M8V1XVXd1WzQ86D0/YXd1W1V/vG8A+dhNLaN1NTUE1TVNVVb2r1+FYcL9pmur8/HztMYATZzexpPt2Uzc3XAfsdrsax7GGYaiu6446IHw0z3NN01Tb7bY2G99GA/vZTSyhdTc1BRUAAP/NNQAAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQOh3dUmXYEgcyS8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEr0lEQVR4nO3dMW4kVRSG0VutmsRSyXnLzojYAAkzCyBjCUQErIQFELAKZ7OAYRLvgQhLtYGSSGz1I2FAgGg/+e+u8tjnxF16Nyj1/fRsqYfWWisAAJ5st/UAAACfO0EFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABAaez50OBxqnueapqmGYTj3TLxSrbValqX2+33tdlofOM5uYg29u6krqOZ5ruvr65MNB8fc3d3V1dXV1mMAz5zdxJoe201dQTVNU1VVfV3f1FhvTjMZ/MtD3dfHev/X+wZwjN3EGnp3U1dQfbpKHetNjYOXljP581clXd0DPewmVtG5m/yjCgBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIS6fhw59fu3X61xDM/Exc3t1iMAPMpuel3OvZvcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBo3HoAzuOXn36Onv/ut7dPfna+iY4G+Cwk37PJd2zq1x+/3Ozsl8wNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITGrQfgPN7+8P1mZ1/U7WZnA6xly+9Znh83VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABAatx6gx/xuePKz+w/thJMAAPyXGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAIjVsP0GP/oW09AgD8w/xuePKz9trL44YKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACA0rnHIxc3tGscAQLd0N31xc6JBeBHcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhMaeD7XWqqrqoe6r2lnn4RV7qPuq+vt9AzjGbmINvbupK6iWZamqqo/1PhwLHrcsS11eXm49BvDM2U2s6bHdNLSO64DD4VDzPNc0TTUMw0kHhE9aa7UsS+33+9rt/DUaOM5uYg29u6krqAAA+H+uAQAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQn8AwaKXZymEuNkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvElEQVR4nO3dMW4bVxSG0TvEuDEwUE9IqVxlA2ksL8BdlpDKhReQNWQBKVJlCeq8ANuNN5AqlQXMBgZII4GTJk6QBKIe+FMztHROzcG7xYD3w5MAdvM8zwUAwME2aw8AAPC1E1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKG+5UO73a7GcaxhGKrruoeeiSdqnueapqm2221tNlof2M9uYgmtu6kpqMZxrIuLi6MNB/tcX1/X+fn52mMAJ85uYkn37aamoBqGoaqqXtbr6uvZcSaD/7itm/pY7/5+3wD2sZtYQutuagqqL1epfT2rvvPS8kD++lVJV/dAC7uJRTTuJv+oAgAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKGmH0dO/fH9d0scw4l4fvVp7REA7mU3PS0PvZvcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3sA7vbh518OfvaHz5fR2b//9G30PMBj9+LH31Y723f06XFDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QG42+XbN2uPAMAdfv3mw8HP+n5/fNxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhfewAA+Bpdvn2z9gicEDdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChfu0BWoyvuoOf3b6fjzgJAMD/uaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2AC227+e1RwCAfxlfdQc/a689Pm6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/RKHPL/6tMQxANAs3U0vro40CI+CGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFDf8qF5nquq6rZuquYHnYcn7LZuquqf9w1gH7uJJbTupqagmqapqqo+1rtwLLjfNE11dna29hjAibObWNJ9u6mbG64DdrtdjeNYwzBU13VHHRC+mOe5pmmq7XZbm42/RgP72U0soXU3NQUVAAB3cw0AABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABD6E6+elx9LuPrvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEv0lEQVR4nO3dMW4cZRjH4XdWkybSyP3KpkqVC9DEOQAdR6BKkQNwBg5AQcUR3OUASZpcgIoKS3OBkWhs7VBAQCCx/rT/9cxm/Tz1fpq3GPn96VtL283zPBcAAAfbrD0AAMCXTlABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6lg/tdrsax7GGYaiu6x57Jp6oeZ5rmqbabre12Wh9YD+7iSW07qamoBrHsa6uro42HOxze3tbl5eXa48BnDi7iSU9tJuagmoYhqqqelXfVF/PjjMZ/Md93dXHevf3+wawj93EElp3U1NQfb5K7etZ9Z2Xlkfy169KuroHWthNLKJxN/lHFQCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAg1/Thy6vdvv17iMZyI5zef1h4B4EF209Py2LvJDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUHOGcffvwpOv/db9cHn/31h5fRswHY78X3vxx81t/o8+OGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL92gOcs+u3b9YeAQBYgBsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVrDwAAX6Kfv/pw8NnrennESTgFbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL92gO0GF93B5/dvp+POAkA/On67Zu1R+CEuKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2AC227+e1RwCAfxlfdweftdfOjxsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv8RDnt98WuIxANAs3U0vbo40CGfBDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhv+dA8z1VVdV93VfOjzsMTdl93VfXP+wawj93EElp3U1NQTdNUVVUf6104Fjxsmqa6uLhYewzgxNlNLOmh3dTNDdcBu92uxnGsYRiq67qjDgifzfNc0zTVdrutzca30cB+dhNLaN1NTUEFAMD/cw0AABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABD6A7ePlnfOgtzfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwElEQVR4nO3dMW7bZhjH4ZcCswQQvBN2lnryBbrUPUC3niIFcoCcIafI3MlbDpBkyQUyZTPACxDoYkPskCZFC1Qm9KdIV36eWR/4DoTfHz4ZUDOO41gAABxss/YAAAD/d4IKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUTvnQbrervu9ru91W0zTHnoknahzHGoahuq6rzUbrA/vZTSxh6m6aFFR939fFxcVsw8E+t7e3dX5+vvYYwCNnN7Gkh3bTpKDabrdVVfVT/VJtPZtnMviX+7qrj/Xu+/sGsI/dxBKm7qZJQfXtKrWtZ9U2XlqO5K9flXR1D0xhN7GIibvJP6oAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAaNKPI6f++PXHJR7DI/H85tPaIwA8yG56Wo69m9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhde4BTdvn6c3T+y5urmSYBAI7JDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2rUHOGVvX3yIzl/X1UyTADC3y9efDz775Y2/76fGDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2rUHOGXXr16uPQIAsAA3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbtAabof24OPtu9H2ecBAC+evviw8Fnr+tqxkl4DNxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhde4Apuvfj2iMAwD/88PtvB5/tyl47NW6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7RIPeX7zaYnHAMBk6W66vJlpEE6CGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFA75UPjOFZV1X3dVY1HnYcn7L7uqurv9w1gH7uJJUzdTZOCahiGqqr6WO/CseBhwzDU2dnZ2mMAj5zdxJIe2k3NOOE6YLfbVd/3td1uq2maWQeEb8ZxrGEYquu62mx8Gw3sZzexhKm7aVJQAQDw31wDAACEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE/gQzKJSct7IxuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEv0lEQVR4nO3dMW4cZRjH4XdWkybSyv3IpqJKRUeD00ai4whUFByAM3AACiqO4C4HcNLkAlRUsTQXGInG1g4NAQFi/Wn/uzOb+Hnq/TRvMfL707eWtpvneS4AAA62WXsAAICPnaACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1LR/a7XY1jmNtt9vquu7UM/FEzfNc0zTVMAy12Wh9YD+7iSW07qamoBrHsa6uro42HOxzd3dXl5eXa48BnDm7iSU9tpuagmq73VZV1Vf1dfX17DiTwb881H29rdd/vW8A+9hNLKF1NzUF1Yer1L6eVd95aTmRP39V0tU90MJuYhGNu8k/qgAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECo6ceRU79/8+USj+FMPL95t/YIAI+ym56WU+8mN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tceAACemvFlF50fbucjTcKxuKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2AOfuzU8/H3z22/fX0bN/+/FFdB6A0/n8h18PP+zv+yfHDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUHOHfX33+39ggAwJlzQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHqDF+LI7+OxwOx9xEgCA/3JDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QFaDLfz2iMAwD/88tmbg89e14sjTsI5cEMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDql3jI85t3SzwGAJqlu+nVzReHP7vsxU+NGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFDf8qF5nquq6qHuq+aTzsMT9lD3VfX3+wawj93EElp3U1NQTdNUVVVv63U4Fjxumqa6uLhYewzgzNlNLOmx3dTNDdcBu92uxnGs7XZbXdcddUD4YJ7nmqaphmGozca30cB+dhNLaN1NTUEFAMD/cw0AABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABD6AwBMlbJvDrcfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEs0lEQVR4nO3dsW3cdhTH8ccD3Rg4qCekBbJAmsgDpMsIqVRokgzgwlO48wCyG++QygK4AIE0Eu6fInGCBMiJ0I9HXqzPpz6CrzjgffEk4LrWWisAAJ5tt/UAAAD/d4IKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUz/nQ4XCocRxrv99X13WnnokXqrVW0zTVMAy122l94Di7iTXM3U2zgmocx7q6ulpsODjm/v6+Li8vtx4DOHN2E2t6ajfNCqr9fl9VVT/Uj9XXq2Umg395rIf6VB/++r4BHGM3sYa5u2lWUH09pfb1qvrOl5YT+fNXJZ3ugTnsJlYxczf5RxUAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAIzfpx5NRvP32/xms4E6/ff956BIAn2U0vy6l3kwsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPqtBwCAl2Z800XPD3dtoUlYigsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPqtBzi1j2/fRc///OX62c/++st30bsB+DYNd23rEViYCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+q0HOLXr25utRwAAvnEuVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7rAeYY33TPfna4awtOAgB/+Pj23bOfvb69WXASzoELFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6rQeYY7hrW48AAP9wfXuz9QicERcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv8ZLXr//vMZrAGA2u4kluVABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6OR9qrVVV1WM9VLWTzsML9lgPVfX39w3gGLuJNczdTbOCapqmqqr6VB/CseBp0zTVxcXF1mMAZ85uYk1P7aauzTgHHA6HGsex9vt9dV236IDwVWutpmmqYRhqt/PXaOA4u4k1zN1Ns4IKAID/5gwAABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABD6HWo4lZhJb43dAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEs0lEQVR4nO3dPW7cZhSG0csB3RgYqCekVKm8gTSRF+Auq3DhBXgNWUCKVFmCOy9AduMNpEongBsg4EbCMIX/ggAefdDLIZXonHoI3mKA++BKwHTzPM8FAMC97bYeAADgv05QAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+pYPHQ6HGsex9vt9dV136pl4pOZ5rmmaahiG2u20PnCc3cQaWndTU1CN41gXFxeLDQfHXF9f1/n5+dZjAA+c3cSa7tpNTUG13++rqurnelF9PVlmMviX27qp9/X26/cN4Bi7iTW07qamoPpySu3rSfWdLy0n8vlXJZ3ugRZ2E6to3E3+UQUAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCTT+OnPr4y09rvIYH4umbD1uPAHAnu+lxOfVucqECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/1AADw2IzPu+j54WpeaBKW4kIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7rAU7tx9d/Rs//9euzhSYBgE+Gq3nrEViYCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+q0HOLU/fngXPX9ZzxaaBID/k3e//X7vZy9fvVxwEh4CFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9QAtxufdvZ+9fPVywUkA4BP7hX9yoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/UALYareesRAAC+y4UKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUr/GSp28+rPEaAGhmN7EkFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFDf8qF5nquq6rZuquaTzsMjdls3VfXt+wZwjN3EGlp3U1NQTdNUVVXv6204FtxtmqY6OzvbegzggbObWNNdu6mbG84Bh8OhxnGs/X5fXdctOiB8Mc9zTdNUwzDUbuev0cBxdhNraN1NTUEFAMD3OQMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT+Bt9Tk6ScQ2XyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEs0lEQVR4nO3dMW7cVhSG0csB3RgYqCekVKm8gTSRF5Auq1DhBWQNWUCKrMKdFyC58QZcpRPADRBII2FeisQJ4CAjQj+HVDDn1PPAWxC4H94MMF1rrRUAAM+223oAAID/O0EFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq53zocDjUOI613++r67pTz8SZaq3VNE01DEPtdlofOM5uYg1zd9OsoBrHsa6urhYbDo65v7+vy8vLrccAXji7iTU9tZtmBdV+v6+qqu/rh+rr1TKTwVce66E+1oe/3zeAY+wm1jB3N80Kqi9XqX29qr7z0nIif/2rpKt7YA67iVXM3E1+qAIAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChWX+OnPr9x+/WeAwvxOv3n7YeAeBJdtN5OfVuckMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7rAQDg3Ixvu+j8cNsWmoSluKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/1AABwbobbtvUILMwNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6rQc4tW9/+hyd/+3nNwtNAgB/uvvl1+j89bubhSZhKW6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/dYDzDG+7Z599u6bu+jZ1/UmOg8AX7t+d7P1CCzMDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+q0HmGO4bc8+e317s+AkAAD/5oYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUr/GQ1+8/rfEYAJjNbmJJbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL9nA+11qqq6rEeqtpJ5+GMPdZDVf3zvgEcYzexhrm7aVZQTdNUVVUf60M4Fjxtmqa6uLjYegzghbObWNNTu6lrM64DDodDjeNY+/2+uq5bdED4orVW0zTVMAy12/k2GjjObmINc3fTrKACAOC/uQYAAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj9AcT4lB8i60SnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEs0lEQVR4nO3dMWocdxTH8TfLuDEM6hepc5ULpIlygHSpUqdS4QPkDDlAIDmFOx9AceMLpLKbCOYCA2kkdlw4jiHBqz/6zc4o6POpd5hXLLwvT4Lt5nmeCwCAB9ttPQAAwP+doAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPUtHzocDjWOYw3DUF3XnXomnqh5nmuaptrv97XbaX3gOLuJNbTupqagGsexLi4uFhsOjrm5uanz8/OtxwAeObuJNd23m5qCahiGqqr6pr6rvp4tMxn8y13d1pt6/c/3DeAYu4k1tO6mpqD6dErt61n1nS8tJ/L3r0o63QMt7CZW0bib/KMKAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhJp+HDn11/dfr/EaHonnr95uPQLAveymp+XUu8mFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL91gO0GL/tHvzs/npecBIAyCV7rcpue4xcqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUbz1Ai/31vPUIALCY9z/8Gj1/eX210CQsxYUKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3WA5zai5/+iJ5/9/NXC00CAB9dvrzaegQW5kIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDqtx6gxe+//PbgZ3/883LBSQAA/suFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL91gO0uHx5tfUIAABf5EIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq13jJ81dv13gNADSzm1iSCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhv+dA8z1VVdVe3VfNJ5+EJu6vbqvr8fQM4xm5iDa27qSmopmmqqqo39TocC+43TVOdnZ1tPQbwyNlNrOm+3dTNDeeAw+FQ4zjWMAzVdd2iA8In8zzXNE213+9rt/PXaOA4u4k1tO6mpqACAODLnAEAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEIfABjAlWBb6faJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAExElEQVR4nO3dsW0cVxSG0TuLUSJgwXxAZo7YgBNTBThTCYoUqADXwAIUqAplKoBSogYcMRKBaWAAJSR2nFg2YEDLB/67MzR5TrwP7wYL3A+PBLab53kuAAAebLP2AAAA/3eCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1Ld8aLfb1TiOtd1uq+u6Y8/EMzXPc03TVMMw1Gaj9YH97CaW0LqbmoJqHMc6Ozs72HCwz83NTZ2enq49BvDI2U0s6b7d1BRU2+22qqp+q9+rrxeHmQz+465u60t9+uf7BrCP3cQSWndTU1D9eErt60X1nS8tR/L3r0p6ugda2E0sonE3+UcVAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACDX9OHLq++tfl7iGR+Llx69rjwBwL7vpeTn2bvJCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QFajK+6B58druYDTgIAuc/vP0TnL969PdAkHIoXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw/QYria1x4BgCdmfNVF55Pd9ObbRXQ3j48XKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw/Q4vP7Dw8+e/Hu7QEnAeCpGK7m1e6+vjxf7W6OwwsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3uAFm++XTz47C9//BndfX15Hp0HAJ4+L1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tceoMX15fnaIwAA/JQXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/EJS8/fl3iGgBoZjdxSF6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCfcuH5nmuqqq7uq2ajzoPz9hd3VbVv983gH3sJpbQupuagmqapqqq+lKfwrHgftM01cnJydpjAI+c3cSS7ttN3dzwHLDb7Wocx9put9V13UEHhB/mea5pmmoYhtps/DUa2M9uYgmtu6kpqAAA+DnPAAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAob8AvPGamCkQpTAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEqElEQVR4nO3dP27UahTG4eORaZCs9KNkA2yAhrAAOipqKgpWwgKuBKugYwG5NOwBGiJ5A5ZoEo0p+CddicmnvBM7N3meej75FJbOT9+MNN08z3MBAHBtm7UHAAD4vxNUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChvuVDu92uxnGsYRiq67qbnol7ap7nmqapttttbTZaH9jPbmIJrbupKajGcayTk5ODDQf7nJ+f1/Hx8dpjALec3cSSrtpNTUE1DENVVT2pZ9XXg8NMBv9xWRf1sT78ft8A9rGbWELrbmoKql9XqX09qL7z0nJDfv6rpKt7oIXdxCIad5MfqgAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECo6c+RU9+eP17iMdwSD99/WnsEgCvZTffLTe8mN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tceoMX4tLv22e3ZfMBJAOCHf/95d+2zL7+eRs/+/OZRdJ7Dc0MFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7tAVp8efH22mdPz14dcBIA7orxaRedP31tv/CHGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9WsP0OLl19O1RwDgjtmezWuPwB3ihgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/doDtPj85tHaIwAA/JUbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/EQx6+/7TEYwCgmd3EIbmhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9S0fmue5qqou66JqvtF5uMcu66Kq/rxvAPvYTSyhdTc1BdU0TVVV9bE+hGPB1aZpqqOjo7XHAG45u4klXbWburnhOmC329U4jjUMQ3Vdd9AB4Zd5nmuaptput7XZ+DYa2M9uYgmtu6kpqAAA+DvXAAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoe930JQS+pUjFQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEsklEQVR4nO3dMW4bVxSG0TvEuDEwUE9IqVxpA2kiL8Cdl5DKRapUWYMXkCKrcOcFWC7sDbhKFQGzgQHSSOCkSJwAAUI96CdnGOmcmsN3iwHuhycB7OZ5ngsAgAfbrD0AAMD/naACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1LR/a7XY1jmMNw1Bd1x17Jp6oeZ5rmqbabre12Wh9YD+7iSW07qamoBrHsS4uLg42HOxzc3NT5+fna48BnDi7iSXdt5uagmoYhqqq+q5eVV/PDjMZ/Mtd3dbHev/3+wawj93EElp3U1NQfb1K7etZ9Z2XliP561clXd0DLewmFtG4m/yjCgBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAISafhw59fvrb5c4hhPx/N3ntUcAuJfd9LQceze5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/YALa5//uXBz1798OaAkwDAn1789OXBz/769vKAk3AK3FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF97gBbf/3a19ggAPDLjyy56/vqb6wc/e1WX0dmcHjdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHgAA1rD9MEfPX314c6BJeAzcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX+KQ8WWXfcHby8MMAgBwBG6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/RKHvPjx0xLHAECz5+8+rz0Cj4gbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUN/yoXmeq6rqrm6r5qPOwxN2V7dV9c/7BrCP3cQSWndTU1BN01RVVR/rfTgW3G+apjo7O1t7DODE2U0s6b7d1M0N1wG73a7GcaxhGKrruoMOCF/N81zTNNV2u63Nxl+jgf3sJpbQupuaggoAgP/mGgAAICSoAABCggoAICSoAABCggoAICSoAABCggoAIPQH3WCRZgNkqXAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEs0lEQVR4nO3dMW7kdBTH8eeRt1nJSj9KulRcgIbsAeg4AtUWW1FxBg5AwSnS7QFgi90LUFERyRewRJNoTMOChGDyV36OPUk+n3osv2Kk99VLpOnmeZ4LAIAH2209AADAUyeoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCfcuHDodDjeNYwzBU13WPPRMv1DzPNU1T7ff72u20PnCc3cQaWndTU1CN41gXFxeLDQfH3Nzc1Pn5+dZjACfObmJN9+2mpqAahqGqqr6qr6uvV8tMBv9yV7f1od7//X0DOMZuYg2tu6kpqD6fUvt6VX3nS8sj+etXJZ3ugRZ2E6to3E3+UQUAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCTT+OnPrjmy/XeA0n4vX1p61HALiX3fSyPPZucqECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/1AADwFF1+/+uDn/3thy8WnIRT4EIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7rAVr88uNPD3726t3bBScB4LlIdktV1be/Xy00Cc+BCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+q0HaHH17u3WIwDwzNgtLMmFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G89AABAi/FN9+BnL68XHOQ/uFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF/jJeObLnp+//O80CQAwFN1yj3gQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXeMnldx/XeA0ANHt9/WnrEXhGXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEJ9y4fmea6qqru6rZofdR5esLu6rap/vm8Ax9hNrKF1NzUF1TRNVVX1od6HY8H9pmmqs7OzrccATpzdxJru203d3HAOOBwONY5jDcNQXdctOiB8Ns9zTdNU+/2+djt/jQaOs5tYQ+tuagoqAAD+nzMAAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEDoT/QklAHO0Yv4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEr0lEQVR4nO3dPW4bVxSG4TPEuDEwUE9IqVR5A25sLyBdVuHCVSqvIQtI4cpLUOcF2C7iDaRKJ2A2MEAaCZw0cRwEMXWhj5zRz/PUHNxTDHBeXBJgN8/zXAAA3Npm7QEAAO47QQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOpbPrTb7WocxxqGobquO/ZMPFLzPNc0TbXdbmuz0frAfnYTS2jdTU1BNY5jnZ2dHWw42Ofy8rJOT0/XHgO44+wmlnTTbmoKqmEYqqrqRf1YfT05zGTwH9d1VZ/rwz/vG8A+dhNLaN1NTUH19Sq1ryfVd15ajuTvf5V0dQ+0sJtYRONu8kMVAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACDX9OXLqz5+eL3EMd8TTiy9rjwBwI7vpcTn2bnJDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tceAADWcP7299XO/uOXZ6udzXG4oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/YALT79+u7Wz7588/qAkwDwULz/4VP0vP3Cv7mhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9WsP0OLlm9drjwDAA2O33D/jq+7Wz55fHHCQ/+GGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL9EoeMr7ro+e3H+UCTAAD31V3uATdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChfolDzn/+bYljAKDZ04sva4/AA+KGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1Ld8aJ7nqqq6rquq+ajz8Ihd11VVfXvfAPaxm1hC625qCqppmqqq6nN9CMeCm03TVCcnJ2uPAdxxdhNLumk3dXPDdcBut6txHGsYhuq67qADwlfzPNc0TbXdbmuz8W00sJ/dxBJad1NTUAEA8H2uAQAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQn8BgfWTHYsn5+AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAErElEQVR4nO3dMW4UZxjH4XdWQ4M0cr+yU7niAmkwB6DjFBRUVJwhB0hBxRHccYBAES6Qis7SXGAkGls7KQJEisL6k//rGWM/T72f5i1Gen/6dqXt5nmeCwCAG9usPQAAwM9OUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPqWD+12uxrHsYZhqK7rbnsmHqh5nmuaptput7XZaH1gP7uJJbTupqagGsexTk5ODjYc7HNxcVHHx8drjwHccXYTS7puNzUF1TAMVVX1tJ5XX48OMxn8x1Vd1sd6//19A9jHbmIJrbupKai+XaX29aj6zkvLLfn6r5Ku7oEWdhOLaNxNfqgCABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoaY/R059efHrEo/hjnh8/mntEQCuZTc9LLe9m9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUHAIA1nL75Kzr/+bcnB5qE+8ANFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6tQdo8eH3tzc+e/bq5QEnAeC+ePfLh+j8WT050CS0Gp91Nz57en7AQf6HGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9Us8ZHzWRefPXr080CQA8A+75eez/WNee4QfckMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDql3jI6es/l3gMADR7fP5p7RG4R9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+pYPzfNcVVVXdVk13+o8PGBXdVlV/75vAPvYTSyhdTc1BdU0TVVV9bHeh2PB9aZpqqOjo7XHAO44u4klXbeburnhOmC329U4jjUMQ3Vdd9AB4Zt5nmuaptput7XZ+DYa2M9uYgmtu6kpqAAA+DHXAAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAob8BiteQmBcOR+0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEs0lEQVR4nO3dP2oUcRjH4XeWsQkM6ZekS2VlZ2NsBTsrj2BhZeUZPICgp0jnAdRCL2ClVWAuMGCTsGPjHxDdjPvdzMbkeer9MW8x8H747cI24ziOBQDAxha7HgAA4H8nqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu2UD61Wq+r7vrquq6ZpLnsmbqhxHGsYhloul7VYaH1gPbuJOUzdTZOCqu/7Ojw83NpwsM7p6WkdHBzsegzgirObmNNFu2lSUHVdV1VV9+phtXVrO5PBb87rrN7Xm5/vG8A6dhNzmLqbJgXVj6vUtm5V23hpuSTf/1XS1T0whd3ELCbuJj9UAQAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgNCkP0dOfX10d47HcEXsnXzc9QgAF7KbbpbL3k1uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDU7noAANiFo+efovOfX9ze0iRcB26oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7a4HAID/0buXrzc+e/z0yRYnuTn6+83GZ49OtjjIH7ihAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFA7x0P6+010/svjVxufPX76JHo2ANfT5xe3o/PHlZ3n3y3fjrse4a/cUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNo5HnL07EN0/sGzOxuf3auP0bMBuJ72TuwHtscNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqJ3yoXEcq6rqvM6qxkudhxvsvM6q6tf7BrCO3cQcpu6mSUE1DENVVb2vN+FYcLFhGGp/f3/XYwBXnN3EnC7aTc044TpgtVpV3/fVdV01TbPVAeGHcRxrGIZaLpe1WPg2GljPbmIOU3fTpKACAODvXAMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIS+AUAUkx84POA0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEv0lEQVR4nO3dMW4cZRjH4XdWk8bSyv3IpkpFRUeD00ai4whUFByAM3AACiqO4C4HcNLkAlRUsTQXGInG1n40BCRE1qP978449vPUO/u9xUjvT58tbddaawUAwME2aw8AAPC5E1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+zod2u12N41jb7ba6rjv1TDxTrbWapqmGYajNRusD+9lNLGHubpoVVOM41uXl5dGGg31ub2/r4uJi7TGAR85uYkkP7aZZQbXdbquq6pv6tvp6cZzJ4D/u667e1Zt/3jeAfewmljB3N80Kqo9XqX29qL7z0nIif/+qpKt7YA67iUXM3E3+UQUAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCs34cOfXnd18vcQyPxNn1+7VHAHiQ3fS8nHo3uaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2AE/Z+KqLnh9u2pEmAQBOyQ0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3uAp2y4aWuPAAAswA0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3sAAFjDy59+X+3s3754Gz1/9eMPR5rk8zK+6g5+9uX1EQf5H26oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINQvccjbX36Nnv/+w9XBz/7x85fR2QA8TWvuh6uymw4x3LS1R/gkN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+iUNeD1+F3zAd/ORZvQ/PBuApOru2HzgeN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+zodaa1VVdV93Ve2k8/CM3dddVf37vgHsYzexhLm7aVZQTdNUVVXv6k04FjxsmqY6Pz9fewzgkbObWNJDu6lrM64DdrtdjeNY2+22uq476oDwUWutpmmqYRhqs/HXaGA/u4klzN1Ns4IKAIBPcw0AABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABD6C0Y2ljvtNpGaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEu0lEQVR4nO3dMW4cZRjH4XdWk8bSyv3IpkrFBaDAOQAdR6Ci4ACcgQNQUHEEdzmAkyYXoKLC0lxgJBpb+1FAQEJkPfJ/dsaJn6fe0fcWI70/fbvSdq21VgAAPNpu6wEAAD52ggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINTP+dDhcKhxHGu/31fXdaeeiWeqtVbTNNUwDLXbaX3gOLuJNczdTbOCahzHury8XGw4OOb29rYuLi62HgN44uwm1vTQbpoVVPv9vqqqvqqvq68Xy0wG/3Ffd/W2Xv/zvgEcYzexhrm7aVZQvb9K7etF9Z2XlhP5+18lXd0Dc9hNrGLmbvJDFQCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAjN+nPk1B/ffLHGMTwRZ9fvth4B4EF20/Ny6t3khgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/dYDfMrGV130/HDTFpoEADglN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+6wE+ZcNN23oEAGAFbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL9Goe8+enn6Pmr779baBIAWMbLH37d7OxfPnvz6Gc/5p06vuoe/ezL6wUH+R9uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUr3HIt79frXEMAKzmtx8/3+zsq9ru7C0NN23rET7IDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhf45Dxyyl6/qzeLTQJAPzl7NpuYTluqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv2cD7XWqqrqvu6q2knn4Rm7r7uq+vd9AzjGbmINc3fTrKCapqmqqt7W63AseNg0TXV+fr71GMATZzexpod2U9dmXAccDocax7H2+311XbfogPBea62maaphGGq38200cJzdxBrm7qZZQQUAwIe5BgAACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACP0JsSCWSLqSDlcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvUlEQVR4nO3dMW4cZRjH4XdWkybSyP3KpkrFBWjiHICOI1ClyAE4AwegoOII7nIAJ00uQEWFpbnASDS29qMhICGyHvKfnbHj56l39L3FSO9P3660XWutFQAAn2239QAAAI+doAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVzPnQ4HGocxxqGobquO/VMPFGttZqmqfb7fe12Wh84zm5iDXN306ygGsexLi4uFhsOjrm5uanz8/OtxwAeOLuJNd23m2YF1TAMVVX1sr6tvp4tMxn8y13d1vt6+/f7BnCM3cQa5u6mWUH18Sq1r2fVd15aTuSvf5V0dQ/MYTexipm7yQ9VAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAIDTrz5FTf3z3zRrH8EA8v/qw9QgA97KbnpZT7yY3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDqtx7gSza+6qLn99dtoUkAgFNyQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOq3HuBLtr9uW48AAKzADRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhf45B3P/0cPX/55vVCkwAALM8NFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF/jkO9/v1zjGAB4FF788OtmZ//y1bvo+cs3rxea5P8bX3Wf/eyLqwUH+Q9uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUr3HIbz9+vcYxAPAobLkXL+vx7uT9ddt6hE9yQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXOOT51Yc1jgGA2ewmluSGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1M/5UGutqqru6raqnXQenrC7uq2qf943gGPsJtYwdzfNCqppmqqq6n29DceC+03TVGdnZ1uPATxwdhNrum83dW3GdcDhcKhxHGsYhuq6btEB4aPWWk3TVPv9vnY730YDx9lNrGHubpoVVAAAfJprAACAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCA0J/yfJZ3CNhPkwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuklEQVR4nO3dMW4bVxSG0TvEuDEwUE9IrlR5A2ksLyBdVuHCC/AavAovQZ0XILvxBly5EzAbGCCNBL40cQIECDnRT84o0jk1H94tCNwPTwLYtdZaAQDwYJu1BwAA+L8TVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7Oh3a7XY3jWMMwVNd1p56JZ6q1VtM01Xa7rc1G6wP72U0sYe5umhVU4zjWxcXF0YaDfW5vb+v8/HztMYBHzm5iSYd206ygGoahqqre1K/V14vjTAb/cF939bU+//V9A9jHbmIJc3fTrKD6+ZTa14vqO19aTuTPX5X0dA/MYTexiJm7yT+qAACEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQGjWjyOnfv/tlyWu4ZF4ef1t7READrKbnpdT7yYvVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq1x7gKRvfdtH57U070iQAwCl5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVrD/CUbW/a2iMAAAvwQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOqXuOTyw/fo/KdXXx589ur9u+huAIBDvFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6JS758fF1dP6qsvMA8JRcfvi+2t2fXn158Nmr9++iu8e33YPPXl5HVx/khQoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/doDAAD/zY+Pr1e7+6rWu3t701a7+xAvVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX6JS15ef1viGgCYzW7imLxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+jkfaq1VVdV93VW1k87DM3Zfd1X19/cNYB+7iSXM3U2zgmqapqqq+lqfw7HgsGma6uzsbO0xgEfObmJJh3ZT12Y8B+x2uxrHsYZhqK7rjjog/NRaq2maarvd1mbjr9HAfnYTS5i7m2YFFQAA/84zAABASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBA6A/G+JZeKJcOEwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuklEQVR4nO3dMWocZxjH4XeWcWMY1C+Sm6jyBdJEOUC6nCKBHMBn8Clcp1LnA9hufAFX7gRzgYE0EvuliRMIZHfY/+6MIj1PvR/fWyy8Pz4JtmuttQIA4GibtQcAAPi/E1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+zod2u12N41jDMFTXdeeeiWeqtVbTNNV2u63NRusD+9lNLGHubpoVVOM41tXV1cmGg33u7u7q8vJy7TGAR85uYkmHdtOsoBqGoaqqfqifqq8Xp5kM/uWh7utTvf/7+wawj93EEubupllB9e0pta8X1Xe+tJzJX78q6ekemMNuYhEzd5N/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQrB9HTv3x8/dLXMMj8fL289ojABxkNz0v595NXqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K89wFM2/thF57cf2okmAQDOyQsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3uAp2z7oa09AgCwAC9UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChfu0B5rh+8+Xos+9efYzuvvntl+g8APD0eaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw8wx9e3r48+e1PHnwWAp+b6zZfV7n736mN0/rvffz367PVtdPVBXqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K89AACwnK9vX692901ld2+rnWiS0/NCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6pe45OXt5yWuAYDZ7CZOyQsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECon/Oh1lpVVT3UfVU76zw8Yw91X1X/fN8A9rGbWMLc3TQrqKZpqqqqT/U+HAsOm6apLi4u1h4DeOTsJpZ0aDd1bcZzwG63q3EcaxiG6rrupAPCN621mqapttttbTb+Gg3sZzexhLm7aVZQAQDw3zwDAACEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE/gTYmZSc9a3IWQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEzklEQVR4nO3dP27bBhTH8UeBWQwI3gm7U6dM3bLEWQNkyxE6degBeoYcoEOnHsFbDuBk8QU6ZaoBXoBAFhtil6YF+kcm9JNIRf58ZhF8g4D3xbMBNeM4jgUAwM5WSw8AAPC1E1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2yoc2m031fV/r9bqapjn0TDxR4zjWMAzVdV2tVlof2M5uYg5Td9OkoOr7vi4vL/c2HGxzd3dXFxcXS48BHDm7iTk9tpsmBdV6va6qqpf1ptp6tp/J4B8e6r4+1vu/vm8A29hNzGHqbpoUVF9OqW09q7bxpeVA/vxVSad7YAq7iVlM3E3+UQUAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCk34cOfX57Ys5XsOROLu+XXoEgEfZTU/LoXeTCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2qUHOGX9qyZ6vrsZ9zQJAHBILlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF26QFOWXczLj0CAAfSv2p2ftZ+OD0uVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBqlx7g0D78/Ev0/NWPP+xpEgBOSXczLj0CR8SFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt0gMc2ve/Xy09AgBw4lyoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7dIDHNqnd8+XHgEAjsa3P/229Ag7+/WbDzs/+/r6u/0N8h9cqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDULj0AADCfT++eLz3Czq5q99nP6naPk/ybCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKid4yVn17dzvAYAJrOb2CcXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUDvlQ+M4VlXVQ91XjQedhyfsoe6r6u/vG8A2dhNzmLqbJgXVMAxVVfWx3odjweOGYajz8/OlxwCOnN3EnB7bTc044Ryw2Wyq7/tar9fVNM1eB4QvxnGsYRiq67parfw1GtjObmIOU3fTpKACAOD/OQMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT+AHUBmGsjYkQNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEyUlEQVR4nO3dPW4UWRSG4VOtIrHUcl6yiYiIJiMZkyKRsQqCWQBrYBUswRkLMCTeABGZpdpASZPY6ppkAGl+2qX+uqva9vPEfXVP0NJ5dW2pm3EcxwIAYGerpQcAAHjoBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKid8qHNZlN939d6va6maQ49E0/UOI41DEN1XVerldYHtrObmMPU3TQpqPq+r/Pz870NB9vc3NzU2dnZ0mMAR85uYk737aZJQbVer6uq6vd6W209289k8A93dVtf6/PP7xvANnYTc5i6myYF1Y+n1LaeVdv40nIgf/+qpKd7YAq7iVlM3E3+UQUAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCk34cOfXnu1dzXMOROLm8XnoEgHvZTU/LoXeTFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItUsP8Jj1r5vofHc17mkSAOCQvFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITapQd4zLqrcekRADiQ/nWz81n74fHxQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdukBDu3Fh2/R+U/Pv+x89uKP99HdAByv7mpcegSOiBcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVLD3Bo3z++jM5fVHYeAHj8vFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITapQcAAB6OFx++LXb3p+dfdj775vK3/Q3yH7xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdegAA4OH4/vHlYndf1O53n9T1Hif5Ny9UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdo5LTi6v57gGACazm9gnL1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2yofGcayqqru6rRoPOg9P2F3dVtWv7xvANnYTc5i6myYF1TAMVVX1tT6HY8H9hmGo09PTpccAjpzdxJzu203NOOE5YLPZVN/3tV6vq2mavQ4IP4zjWMMwVNd1tVr5azSwnd3EHKbupklBBQDA//MMAAAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ+gu0BZhS35E2nQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuUlEQVR4nO3dsW3cBhTH4ccD3Qgg1BPSAlkgTeQB0mUEVy48SQZw4SnUeQDZjXZIZQFcgEAaCcc0cQIEyB2h/x3J5L6vPoqvOOD98CRAzTRNUwEA8Gq7tQcAAPivE1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2zof2+30Nw1Bd11XTNOeeiQs1TVON41h939dup/WBw+wmljB3N80KqmEY6vb29mTDwSFPT091c3Oz9hjAxtlNLOnYbpoVVF3XVVXVT/VztfXmNJPBP7zUc32tz3993wAOsZtYwtzdNCuovp9S23pTbeNLy5n8+V8lne6BOewmFjFzN/lDFQCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAjN+ufIqd9/+XGJ17ARV/ePa48AcJTddFnOvZtcqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj3A/9nwtome7x+mE00CAJyTCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhde4Ct+/Lx06ufvfvw/oSTALAlw9vm1c/2D9MJJ2ELXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K49wNa9+3a39ggAbFD/MK09AhviQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdu0Btu63X39YewQAYONcqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3aAwAAl+HLx0/R8+++3b362eE+evVRLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQatceAAC4DHcf3q/27qt6POvPd6ECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1S7zk6v5xidcAwGx2E6fkQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGrnfGiapqqqeqnnqums83DBXuq5qv7+vgEcYjexhLm7aVZQjeNYVVVf63M4Fhw3jmNdX1+vPQawcXYTSzq2m5ppxjlgv9/XMAzVdV01TXPSAeG7aZpqHMfq+752O7+NBg6zm1jC3N00K6gAAPh3zgAAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKE/AOMslpiwf+KjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEu0lEQVR4nO3dMW7bZhjH4ZcCswQgvBN2p065QJc4B8jWI3TK0AP0DDlAh54iWw5gZ8kFOmWqAV6AQBYbYpemBQpUJvSXSLp+nlkf+A4E3h8+CVAzTdNUAAAcbbf2AAAAT52gAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItXM+tN/vaxiG6rqumqY590w8U9M01TiO1fd97XZaHzjMbmIJc3fTrKAahqGurq5ONhwccnd3V5eXl2uPAWyc3cSSHttNs4Kq67qqqnpdb6utF6eZDP7loe7rU338+30DOMRuYglzd9OsoPp2ldrWi2obLy1n8te/Srq6B+awm1jEzN3khyoAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQmvXnyKmvP/6wxGPYiJcfPq89AsCj7Kbn5dy7yQ0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNq1B/g/G9400fn+ZjrRJADAObmhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItWsPsHXf//L70Wdvv7uNnn198y46D8D5DG+ao8/2N9MJJ2EL3FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF17gK378v7V0Wev6/izAGxbfzOtPQIb4oYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3aAwAAT8ftr78dffanP66jZ395/yo6f05uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj0AAPB0XP/8bu0RNskNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF3iIS8/fF7iMQAwm93EKbmhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItXM+NE1TVVU91H3VdNZ5eMYe6r6q/nnfAA6xm1jC3N00K6jGcayqqk/1MRwLHjeOY11cXKw9BrBxdhNLemw3NdOM64D9fl/DMFTXddU0zUkHhG+maapxHKvv+9rtfBsNHGY3sYS5u2lWUAEA8N9cAwAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhP4EWBKWH4sS6V0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEx0lEQVR4nO3dsW3cdhTH8ccD3Rg4qCekLpUXSBN5gHQZwZULD5AZPIALT+HOA8huvIArVxbABQikkXD/NHECBIhE6HdHMtLnUx/BVxzwvngScF1rrRUAAA+2W3sAAID/O0EFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq53zocDjUOI613++r67pTz8QT1VqraZpqGIba7bQ+cDe7iSXM3U2zgmocx7q4uDjacHCX6+vrOj8/X3sMYOPsJpZ0326aFVT7/b6qqn6pX6uvZ8eZDP7ltm7qc338+/sGcBe7iSXM3U2zgurHKbWvZ9V3vrScyF+/Kul0D8xhN7GImbvJP6oAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAaNaPI6f++O3nJV7DRjz/8GXtEQDuZTc9LafeTS5UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHuAx+/TuffT85ZvXR5oEADglFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9gBb99PvXx/87Kvvl0ecBIAtGV92D352uGpHnIQtcKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2AFv37e2LtUcAYIOGq7b2CGyICxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUH4DTGl130/HDVjjQJADx+LlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QE4jeGqrT0CABv06d376PlX3y8f/Oy3ty+id2+ZCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUHAACWc/nm9dojPEouVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX6Jlzz/8GWJ1wDAbHYTx+RCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6ud8qLVWVVW3dVPVTjoPT9ht3VTVP983gLvYTSxh7m6aFVTTNFVV1ef6GI4F95umqc7OztYeA9g4u4kl3bebujbjHHA4HGocx9rv99V13VEHhB9aazVNUw3DULudv0YDd7ObWMLc3TQrqAAA+G/OAAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoT8B1KuZC0N4dxYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEyElEQVR4nO3dsW3cdhTH8ccD3Rg4qCekVKm8QJrIA7jLCKlUaIDM4AFSpMoI7jyA7MYLpHIVAVyAgBsJ908TJ4ABnRj97khF+nzqI/iKA94XTwKua621AgDgwTZrDwAA8H8nqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv2cD+12uxrHsbbbbXVdd+yZeKZaazVNUw3DUJuN1gf2s5tYwtzdNCuoxnGss7Ozgw0H+1xfX9fp6enaYwCPnN3Eku7bTbOCarvdVlXVj/Wm+npxmMngG7d1Ux/r/T/fN4B97CaWMHc3zQqqr6fUvl5U3/nSciR//6qk0z0wh93EImbuJv+oAgAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKFZP46c+vLTD0u8hkfi5btPa48AcC+76Xk59m5yoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/YAT9n3v/wRPf/7dx8e/Oz55UX0bgBgPhcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/YA3O388mLtEQC4w/i6e/Czw1U74CQ8Bi5UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHuAp+/z21dojAHAkw1VbewQeERcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVrD8BxjK+76Pnhqh1oEgB4+lyoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/doDcBzDVVt7BACO5MOvvz342Z//PI/e/fntq+j5p8qFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL92gMAAP/N+eXF2iPwDRcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv8RLXr77tMRrAGA2u4lDcqECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1cz7UWquqqtu6qWpHnYdn7LZuqurf7xvAPnYTS5i7m2YF1TRNVVX1sd6HY8H9pmmqk5OTtccAHjm7iSXdt5u6NuMcsNvtahzH2m631XXdQQeEr1prNU1TDcNQm42/RgP72U0sYe5umhVUAADczRkAACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACD0F+EgmClmqg9rAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEx0lEQVR4nO3dMW4bVxSG0TvEuDFAqB9IqVJ5A2kiLyBdlpDKhReQNXgBKVJlCe68ANmNN5DKVQTMBgZII4EvTZwAQUwN9JMztHhOzcG7xQD3wyMBdq21VgAAPNpm7QEAAL52ggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINTP+dBut6txHGu73VbXdceeiTPVWqtpmmoYhtpstD6wn93EEubupllBNY5jXV1dHWw42Of29rYuLy/XHgM4cXYTS3poN80Kqu12W1VV39cP1dezw0wG/3Ffd/Wh3v3zvgHsYzexhLm7aVZQfb5K7etZ9Z2XliP5+18lXd0Dc9hNLGLmbvJDFQCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAjN+nPk1J8/frfEMZyI528/rj0CwIPspvNy7N3khgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/doDPGXf/vz7amf/9s376Pnr168ONAkAPH1uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3aAzxln968WO3s61rvbIBzML7sHv3scNMOOAmnwA0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPq1BwCAr9Fw09YegRPihgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/doDcBzjyy56frhpB5oEAJ4+N1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QE4juGmrT0CAF/w/pdfo+d/+uP60c9+evMiOpv/54YKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3aAwDAubl+/WrtETgwN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+iUOev/24xDEAMJvdxCG5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVzPtRaq6qq+7qrakedhzN2X3dV9e/7BrCP3cQS5u6mWUE1TVNVVX2od+FY8LBpmuri4mLtMYATZzexpId2U9dmXAfsdrsax7G22211XXfQAeGz1lpN01TDMNRm49toYD+7iSXM3U2zggoAgC9zDQAAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEPoL0f6XgRCHzWEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEzUlEQVR4nO3dMW7bZhjH4ZcCswQQvBP21skX6FLnAN1yhE4ZcoCewQfIkFNkywGcLLlAJk81wAsQyGJD7NK0QADLhP8UqVTPM4v43oHA+8MnAWrGcRwLAIBn26w9AADAz05QAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2ikf2u121fd9bbfbaprm0DNxosZxrGEYquu62my0PrCf3cQSpu6mSUHV931dXFzMNhzsc3d3V+fn52uPARw5u4klPbWbJgXVdrutqqrf6vdq68U8k8EPHuq+PtfHf983gH3sJpYwdTdNCqrvV6ltvai28dJyIP/8q6Sre2AKu4lFTNxNfqgCABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoUl/jpz69vrXJY7hSLz88GXtEQCeZDedlkPvJjdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGrXHoDH/fLn19XOvr2+XO1sAPjZuKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1aw/A426vL5/97Kd376Ozr+r5ZwOcgv5V8+xnu5txxkk4Bm6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINSuPQCHcfX2zdojAPyvdTfj2iNwRNxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdewAOo3/VRM93N+NMkwDwo0/v3kfPX719M9MkzMUNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF17AA6juxnXHgGAR/zx19XaIzAzN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQatceAABOze315dojMDM3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXaJQ15++LLEMQAwmd3EnNxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2ikfGsexqqoe6r5qPOg8nLCHuq+q/943gH3sJpYwdTdNCqphGKqq6nN9DMeCpw3DUGdnZ2uPARw5u4klPbWbmnHCdcBut6u+72u73VbTNLMOCN+N41jDMFTXdbXZ+DYa2M9uYglTd9OkoAIA4HGuAQAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQn8DU/eZgWWZHZYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwElEQVR4nO3dMW4cZRjH4XdWkybSyv3IpoHKF6DBHICOI1CBxAE4Qw5AQUVNlS4HcNLkAlSpsDQXGInG1n40BKRIWY/8n51x4uep99O8xUjvT9+utF1rrRUAAA+223oAAIBPnaACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1cz50OBxqHMfa7/fVdd2pZ+KJaq3VNE01DEPtdlofOM5uYg1zd9OsoBrHsS4uLhYbDo65ubmp8/PzrccAHjm7iTXdt5tmBdV+v6+qqm/qu+rr2TKTwQfu6rbe1Kv/3jeAY+wm1jB3N80KqvdXqX09q77z0nIi//6rpKt7YA67iVXM3E1+qAIAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChWX+OnPr7+6/XeAyPxPOXb7ceAeBedtPTcurd5IYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3WA3AaX/3yZ3T+3YvLhSYBgM+fGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9QAA8Ckav+0efHa4bgtOwmPghgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/dYDcBq/f/E6On9VlwtNAvB5Gq7bg8++/vW36NlXP/8YnWd5bqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G89AKfx5R8/ReeHagtNAsCHfvjrausRWJgbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/1AJzGcN22HgGAj3j34nLrEViYGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9Ws85PnLt2s8BgBms5tYkhsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQP+dDrbWqqrqr26p20nl4wu7qtqr+f98AjrGbWMPc3TQrqKZpqqqqN/UqHAvuN01TnZ2dbT0G8MjZTazpvt3UtRnXAYfDocZxrP1+X13XLTogvNdaq2maahiG2u18Gw0cZzexhrm7aVZQAQDwca4BAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/wBiNpW9I1TooAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwUlEQVR4nO3dMWocBxTH4TfLuDEM6gcpVSpfIAQiH8BdqtSpXPgAOYNvkC5HcOcDyG58gVROJZgLDLiR2EkTJ2DIatB/dkbSfl+tYV6x6P14EmwzTdNUAADc227rAQAAHjtBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQauf80H6/r2EYquu6aprm2DNxoqZpqnEcq+/72u20PnCY3cQa5u6mWUE1DENdXFwsNhwccn19Xefn51uPATxwdhNrums3zQqqruuqquqnelVtPVtmMvjGbd3Ux3r/7+cN4BC7iTXM3U2zgurrKbWtZ9U2PrQcyT/fKul0D8xhN7GKmbvJP6oAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAaNaXI6e+/PzDGq95cIaX2Zf89lfTQpOs6/m7T1uPAHCnU91Np+rYu8mFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G49wFPWX01bjwAArMCFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt1gNwHN//9mf0/Oe3LxaaBACePhcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu/UAAPAYDS+bez/71y+/R+++fPM6ep7luVABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqN16AAB4jPqr6d7P/vrj5YKT8BC4UAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECo3XoAjuOP7z5Ez1/Wi4UmAeBbn9/6HfvUuFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITarQfgOC7fvN56BAA4GS5UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGrXeMnzd5/WeA0AzGY3sSQXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUDvnh6Zpqqqq27qpmo46Dyfstm6q6r/PG8AhdhNrmLubZgXVOI5VVfWx3odjwd3Gcayzs7OtxwAeOLuJNd21m5ppxjlgv9/XMAzVdV01TbPogPDVNE01jmP1fV+7nb9GA4fZTaxh7m6aFVQAAPw/ZwAAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgNDfsOCU2DGCvL4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE2ElEQVR4nO3dMWojZxjH4XfEbGMQ7oXdbeUqXViItw2kS5U6VYocYM/gAwSSU7jbAzjb+AJbOZVhLjCQxkaTJptAIPKg/2hGtp+n1se8xeD3xyeDmmEYhgIAYG+rpQcAAHjuBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKgd86Htdltd19V6va6maQ49E6/UMAzV931tNptarbQ+sJvdxBzG7qZRQdV1XZ2fn082HOxyf39fZ2dnS48BHDm7iTk9tZtGBdV6va6qqm/qu2rrzTSTwX881kN9qo//vG8Au9hNzGHsbhoVVF+uUtt6U23jpeVA/v5VSVf3wBh2E7MYuZv8owoAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCERv04curP77+e4zFHp3uf/cjv5maYaJJ5nVzfLj0CwJNe6256rQ69m9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2qUHeMk2N8PSIwAAM3BDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF26QEA4Dnq3jd7n93cDBNOwjFwQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGqXHoDDePvhc3T+7upiokkAXqY/fvh177M/vruMnu1v9PFxQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdukBAOA5uvz5p73Pvv3wecJJOAZuqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDULj0Ax+n3X37b++y3119NNwjAC3R3dbH0CEzMDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdegAO4+7qIjp/WfufP6nb6NkA8Ny4oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQO8dDTq5v53gMAIxmNzElN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2zIeGYaiqqsd6qBoOOg+v2GM9VNW/7xvALnYTcxi7m0YFVd/3VVX1qT6GY8HT+r6v09PTpccAjpzdxJye2k3NMOI6YLvdVtd1tV6vq2maSQeEL4ZhqL7va7PZ1Grl22hgN7uJOYzdTaOCCgCA/+caAAAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg9Bf6LZrCa+QomwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEzklEQVR4nO3dMW7bBhTH4UeBWQII3gV78+QLdKl7gG45QicPnjrlDD5AhpwiWw6QZGgukMlTDfACBLLYELs0LZCiMuE/RUrx980i+AYB74dnA2qGYRgKAIAnWy09AADAsRNUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdsyHttttdV1X6/W6mqbZ90w8U8MwVN/3tdlsarXS+sBudhNzGLubRgVV13V1dnY22XCwy93dXZ2eni49BnDg7Cbm9NhuGhVU6/W6qqp+rl+rrRfTTAbfeaj7+lTv//m+AexiNzGHsbtpVFB9O6W29aLaxpeWPfn7VyWd7oEx7CZmMXI3+UcVAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACI36ceTU11c/zfGag9P9kv3I7+bDMNEk83r57vPSIwA86rnupmOW7NXz3/+YcJL/cqECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1Sw/wI9t8GJYeAQB+GIe8V12oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINQuPQAAHKOPb94++dnL66sJJ+EQuFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITapQcAgGP025+XT372/PWX6N23NxfR80zPhQoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7dIDAMAxur25ePKz56+/TDgJh8CFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt0gOwHx/fvI2ev7y+mmgSAL53e3Ox9AhMzIUKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDULj0A+3F5fbX0CADwbLhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKid4yUv332e4zUAMJrdxJRcqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu2YDw3DUFVVD3VfNex1Hp6xh7qvqn+/bwC72E3MYexuGhVUfd9XVdWneh+OBY/r+75OTk6WHgM4cHYTc3psNzXDiHPAdrutrutqvV5X0zSTDgjfDMNQfd/XZrOp1cpfo4Hd7CbmMHY3jQoqAAD+nzMAAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEDoLzVUmZpEm9bFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwElEQVR4nO3dMW4UBxTH4TeroUEauV/ZHRUXSBPnAOk4QioXrqg4Aweg4BR0HAAo4AKpqGJpLjASja2dNECkRFmP+M/OrNnvq3e0rxjp/fRsaZtxHMcCAOCHbdYeAADgoRNUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdsqHdrtd9X1fXddV0zSHnokTNY5jDcNQ2+22NhutD+xnN7GEqbtpUlD1fV8XFxezDQf73Nzc1Pn5+dpjAEfObmJJ9+2mSUHVdV1VVf1av1dbj+aZDP7lrm7rQ739/r4B7GM3sYSpu2lSUH07pbb1qNrGS8uBfP1VSad7YAq7iUVM3E3+UQUAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCk34cOfXl2S9LfM3R6X/LfuR3+26caZJlPX7zae0RAO51qrvpIUv26pPnH2ec5L9cqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3aA/zMtu/GtUcA4EDev3r9w89eXl/NOMnpOOa96kIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbtAQDgIfrjr8u1R+CIuFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITatQcAgFPz5MWf0fOfXz6daRLm4kIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbtATiM969eR89fXl/NNAnAz+nzy6drj8ARcaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv2ABzG5fXV2iMAwMlwoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu8SXPH7zaYmvAYDJ7Cbm5EIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBqp3xoHMeqqrqr26rxoPNwwu7qtqr+ed8A9rGbWMLU3TQpqIZhqKqqD/U2HAvuNwxDnZ2drT0GcOTsJpZ0325qxgnngN1uV33fV9d11TTNrAPCN+M41jAMtd1ua7Px12hgP7uJJUzdTZOCCgCA/+cMAAAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ+ht6VZaY1IRH1AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvElEQVR4nO3dMW7cVhSG0csB3Rgg1A+kzpU3kCbKAtJ5CalUqEqVNXgBLrwKd16A7cLeQCpXEcANEHAjYV6aOAEcaEToH5Fj65yaBG9B4H54MwC71lorAADubbP2AAAA3ztBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6udctNvtahzHGoahuq576Jl4pFprNU1Tbbfb2my0PrCf3cQS5u6mWUE1jmOdnZ0dbDjY5+rqqk5PT9ceAzhydhNLums3zQqqYRiqqurn+rX6enKYyeAbN3VdH+rtv+8bwD52E0uYu5tmBdXXo9S+nlTfeWl5IP98VdLRPTCH3cQiZu4mf1QBAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCA0KyPI6e+vPhpicccnfGX7CO/23ftQJMs6+mbT2uPAHCnx7qbvmfJXn32+8cDTvJ/TqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL92gP8yLbv2tojAHCL969eR/f/9tf5ve/9/PJ59OzH6pj3qhMqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVrDwAAazi/vIjuf/bHnweahB+BEyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9WsPwO3ev3p973vPLy8OOAkA3/r88vnaI3BEnFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF97AG53fnmx9ggAwAxOqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUL/GQp28+LfEYAJjNbuKQnFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6ORe11qqq6qauq9qDzsMjdlPXVfXf+wawj93EEubupllBNU1TVVV9qLfhWHC3aZrq5ORk7TGAI2c3saS7dlPXZhwH7Ha7GsexhmGorusOOiB81VqraZpqu93WZuPXaGA/u4klzN1Ns4IKAIDbOQYAAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj9DZeXlpaL8I9nAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEoElEQVR4nO3dMU7ceBTH8eeRaSJZ9CPocodtlhxguz0FBVUOQ5FTpMsBkhSbcyD5ApbSgOafJuxKiRgsfoM9LJ9PPSO/YqT31QPJXWutFQAAT7ZZewAAgJdOUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPo5H9rtdjWOYw3DUF3XPfdMvFKttZqmqbbbbW02Wh/Yz25iCXN306ygGsexzs/PDzYc7HNzc1NnZ2drjwEcObuJJT22m2YF1TAMVVX1Z/1VfZ0cZjL4xV3d1tf69O/vDWAfu4klzN1Ns4Lq/pTa10n1nR8tz+TnWyWd7oE57CYWMXM3+UcVAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACM16OXLq+99/LPGYozO+y17yu/3cDjTJst58/Lb2CACPeq276SVL9urb9/8ccJLfuVABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6tQf4P9t+bmuPAMAz+XL94cnfvbi6POAkr8cx71UXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw8AAC/RxdXl2iNwRFyoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC/doD8LAv1x+e/N2Lq8sDTgIA7ONCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QF42MXV5dojAAAzuFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6JR7y5uO3JR4DALPZTRySCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKif86HWWlVV3dVtVXvWeXjF7uq2qv77vQHsYzexhLm7aVZQTdNUVVVf61M4FjxumqY6PT1dewzgyNlNLOmx3dS1GeeA3W5X4zjWMAzVdd1BB4R7rbWapqm2221tNv4aDexnN7GEubtpVlABAPAwZwAAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgNAPe7eRlttw0EYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEmUlEQVR4nO3dMW4bVxRA0U+BbgwQ6gmpyx7SRF5AuqxChaosxoVX4c4LsF3E6zDADQyQRoImTZwACSQNfClSss6ph5hXDPguPgnMap7neQAA8N1Ojj0AAMBzJ6gAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiNZLLrq9vR273W5sNpuxWq0eeyZeqHmexzRNY7vdjpMTrQ/cz27iEJbupkVBtdvtxvn5+d6Gg/t8/fp1nJ2dHXsM4Imzmzikh3bToqDabDZjjDF+Gb+O9Xi1n8ngP27G9fg8PvzzvAHcx27iEJbupkVB9e0odT1ejfXKQ8sj+futko7ugSXsJg5i4W7yRxUAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAANGilyNXf/728yFu8+Ts3rSX/G4/znua5LBev/9y7BEAHvRSd9NzVvbqT7//scdJ/s8JFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAANH62AP8yLYf52OPAMAT9Ontu/T5i6vLPU3yvDzlveqECgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQrY89AHf79Pbdd3/24upyj5MAsE++o388TqgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCI1scegLtdXF0eewQAYAEnVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAAKL1IW7y+v2XQ9wGABazm9gnJ1QAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQrZdcNM/zGGOMm3E9xvyo8/CC3YzrMca/zxvAfewmDmHpbloUVNM0jTHG+Dw+xLHgYdM0jdPT02OPATxxdhOH9NBuWs0LjgNub2/Hbrcbm81mrFarvQ4I38zzPKZpGtvtdpyc+DUauJ/dxCEs3U2LggoAgLs5BgAAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAg+gtwjpGUZhefkQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEiUlEQVR4nO3dMYobZxiA4V+L3BjE9mK3yx3SxD5AupzChascJkVO4c4HcFzE51jQBQbS7KJJEyeQYO3gVyvJ2eepZ5ivGPhefglmNc/zPAAA+GpX5x4AAOBbJ6gAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiNZLLtrv92O3243NZjNWq9VTz8QzNc/zmKZpbLfbcXWl9YHD7CZOYeluWhRUu91u3N7eHm04OOTu7m7c3NycewzgwtlNnNJju2lRUG02mzHGGD+MH8d6vDjOZPAvD+N+fBzv/37fAA6xmziFpbtpUVB9PkpdjxdjvfLS8kT++qqko3tgCbuJk1i4m/xRBQAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAtOjjyNUfP31/isdcnN3r9pHf7Yf5SJOc1st3n849AsCjnutu+paVvfrdz78fcZL/ckIFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAtD73AP9n2w9zuv+3X3796ntfvX2Tng3A5Xqu+6Hu1afkhAoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEK3PPQBf9urtm3OPAMAFsh8ujxMqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAANH6FA95+e7TKR4DAIvZTRyTEyoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCI1ksumud5jDHGw7gfY37SeXjGHsb9GOOf9w3gELuJU1i6mxYF1TRNY4wxPo73cSx43DRN4/r6+txjABfObuKUHttNq3nBccB+vx+73W5sNpuxWq2OOiB8Ns/zmKZpbLfbcXXl12jgMLuJU1i6mxYFFQAAX+YYAAAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIDoTy7FkZLvrFG7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEkklEQVR4nO3dMW4cZRiA4X+tTRNp5X5ld9yBBnMAOiqOkCIVh0GCU6TLAUwKcohUlvYCI9HY2qGAgABhj3jXu078PPWM5itG+l79u9Ks5nmeBwAA/9vZqQcAAPjUCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAovWSi/b7/djtdmOz2YzVavXYM/FMzfM8pmka2+12nJ1pfeB+dhPHsHQ3LQqq3W43Li8vDzYc3Ofm5mZcXFycegzgibObOKaHdtOioNpsNmOMMb4a34z1eHGYyeAf7sbteDfe/vm+AdzHbuIYlu6mRUH18Sh1PV6M9cpLyyP546uSju6BJewmjmLhbvJHFQCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAA0aKPI1e/fvvlMR7z5Oy+bh/53V7PB5rkuF6+eX/qEQAe9Fx306es7NUvvv/lgJP8mxMqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAovWpB/icffjux3T/1fWrA00CAL/7+Yef0v1Xr0+3m7bX88me/RAnVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCAaH3qAT5nV69fnXoEAPgbu+lxOKECAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEK2P8ZCXb94f4zEAsJjdxCE5oQIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBoveSieZ7HGGPcjdsx5kedh2fsbtyOMf563wDuYzdxDEt306KgmqZpjDHGu/E2jgUPm6ZpnJ+fn3oM4Imzmzimh3bTal5wHLDf78dutxubzWasVquDDggfzfM8pmka2+12nJ35NRq4n93EMSzdTYuCCgCA/+YYAAAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIDoN9yCj+nVkDXrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEp0lEQVR4nO3dMW4bVxRA0U+BbgwQ6gmpS5UNpIm8gHRZQioVqrKMLMCFV+HOC7BdxHtIFQHcAIE0EjRp4gRIEGrgS5GydE7NwX/FAO/iS8AspmmaBgAAX+zk2AMAAHztBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAA0XLOj+7u7sZmsxmr1WosFouHnolnapqmsd1ux3q9HicnWh/YzW7iEObupllBtdlsxvn5+d6Gg12ur6/H2dnZsccAHjm7iUO6bzfNCqrVajXGGOP78cNYjhf7mQz+5XbcjI/j3d/vG8AudhOHMHc3zQqqz1epy/FiLBdeWh7IX1+VdHUPzGE3cRAzd5N/VAEAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEM36OHL1x4/fHeKYR+fD6zfp+Yuryz1Nclgv33469ggA93quu+lrtnm1+wPFu3zz8697nOS/3FABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQLY89wFP20+8XRzt782qRnl+/n/Y0CQBPyYfXb7742Yury3T2Y95NbqgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAANHy2AM8Zb/98u3Rzl6/n452NgBP18XV5bFHeJTcUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIloc45OXbT4c4BgBms5vYJzdUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEC3n/GiapjHGGLfjZozpQefhGbsdN2OMf943gF3sJg5h7m6aFVTb7XaMMcbH8S6OBffbbrfj9PT02GMAj5zdxCHdt5sW04zrgLu7u7HZbMZqtRqLxWKvA8Jn0zSN7XY71uv1ODnx12hgN7uJQ5i7m2YFFQAA/881AABAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAADRn56dk5K+pPYAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEqUlEQVR4nO3dMW5cVRSA4TvWpIk0cj+yqVKxARqcBdCxCheuqFgDC6CgYgnpsoAkBdkAFZ2l2cBINLb8aAiIIMZP+cczDv6+ep7uKZ50fl1beotpmqYBAMAnOzn2AAAAnztBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEC0nPOju7u7sdlsxmq1GovF4qFn4omapmlst9uxXq/HyYnWB3azmziEubtpVlBtNptxfn6+t+Fgl+vr63F2dnbsMYBHzm7ikO7bTbOCarVajTHG+Hp8M5bj2X4mg4/cjpvxbrz+630D2MVu4hDm7qZZQfXhKnU5no3lwkvLA/nzq5Ku7oE57CYOYuZu8o8qAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAACiWR9Hrn7/9qtDHPPovPj+1/T8z1+8/eRnL64u09nF81fvj3Y2wFxPdTd9zjYvd3+geJcX3/2yx0n+zQ0VAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAA0fLYA/yf/fbDl+n5i/Hpz29eLtLZ6zdTeh4APvb2x5/S8xdXl3uaZP/cUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAouWxB+BhrN9Mxx4BAP7h4ury2CM8GDdUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAAKLlIQ55/ur9IY4BgNnsJvbJDRUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEyzk/mqZpjDHG7bgZY3rQeXjCbsfNGOPv9w1gF7uJQ5i7m2YF1Xa7HWOM8W68jmPB/bbb7Tg9PT32GMAjZzdxSPftpsU04zrg7u5ubDabsVqtxmKx2OuA8ME0TWO73Y71ej1OTvw1GtjNbuIQ5u6mWUEFAMB/cw0AABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQPQHi4GRnq5ZJgMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEoElEQVR4nO3dMY7UZRjA4Xc2Q0MyoZ+ADVR6ABvxAHaeAhMqK8/gASysrK3oOIBQyAWs7EjmApPYQPZvI5qQsPt3f8ssyvPU8+V7i0neX77dZDbLsiwDAMCVnd30AAAA/3WCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBou+ZD5+fnczgcZrfbzWazed8z8ZFalmWOx+Ps9/s5O9P6wMXsJk5h7W5aFVSHw2Hu3bt3bcPBRV6+fDl379696TGAD5zdxCldtptWBdVut5uZmS/mq9nOreuZDN7yel7N83n69/cN4CJ2E6ewdjetCqo3T6nbuTXbjS8t78lfvyrp6R5Yw27iJFbuJv+oAgAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgWvXjyNUfX39+imv+dx5899uVz/7+/afXOMm/c/vJixu7G2Atu+n0nv3wYzp//+dvrnz2wbe/prsv44UKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCAaHvTA/BuP33y7Mpn73/5Wbp7/8uSzgPA2x4+fpTO7+fD3U1eqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAA0famB+DdHj5+dOWz+1mucRIA4CJeqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIBJUAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEAkqAIBIUAEARIIKACASVAAAkaACAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBE21NccvvJi1NcAwCr2U1cJy9UAACRoAIAiAQVAEAkqAAAIkEFABAJKgCASFABAESCCgAgElQAAJGgAgCIBBUAQCSoAAAiQQUAEG3XfGhZlpmZeT2vZpb3Og8fsdfzamb++b4BXMRu4hTW7qZVQXU8Hmdm5vk8jWPB5Y7H49y5c+emxwA+cHYTp3TZbtosK54Dzs/P53A4zG63m81mc60DwhvLsszxeJz9fj9nZ/4aDVzMbuIU1u6mVUEFAMC7eQYAAIgEFQBAJKgAACJBBQAQCSoAgEhQAQBEggoAIPoTdUCP9cmI88kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEyElEQVR4nO3dMWokVxSG0VuiJhE0ygvJkSNFzpxYkxqceRUOvACvQQtw4MhLmGwWoJlEG3CkTFAbKHAi0c+JxwaDusv9t6o0mnPifrwbNNyPJ0F3rbVWAAAc7GTtAQAAPneCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1M/50Ha7rXEca7PZVNd1zz0TX6jWWk3TVMMw1MmJ1gd2s5tYwtzdNCuoxnGsi4uLow0Hu9zf39f5+fnaYwAvnN3EkvbtpllBtdlsqqrqu/qh+npznMngPx7roT7W+3++bwC72E0sYe5umhVUn55S+3pTfedLyzP5+1clPd0Dc9hNLGLmbvKPKgAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABCa9ePIqT9//HaJa16dr3/54+Czd9eXR5zk/zl9d7va3QBz2U3LS/ZaVdXvX304+Oz3wzfR3ft4oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVrD8Dz+PDrb9H5q59/OtIkALwk49suOj/ctIPP3l1fRndf1eHnT+s2unsfL1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tcegKfdXV8efPaqDj8LwOs13LS1R3iVvFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6tQfgaePb7uCzw0074iQAwC5eqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3aA/C04aatPQIAMIMXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1S1xy+u52iWsAYDa7iWPyQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrnfKi1VlVVj/VQ1Z51Hr5gj/VQVf9+3wB2sZtYwtzdNCuopmmqqqqP9T4cC/abpqnOzs7WHgN44ewmlrRvN3VtxnPAdrutcRxrs9lU13VHHRA+aa3VNE01DEOdnPhrNLCb3cQS5u6mWUEFAMDTPAMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT+As9ImDe/eSs5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE00lEQVR4nO3dMW4UZxjH4XdWQ2Np5X5kp6KiSkeKmBaJLqeg4ACcgQNQpMoR6DiAofEFqOgszQVGorG1QxMSKbDryf53Z4z8PPV++t5ipfenz5a2GcdxLAAA9rZaegAAgJ+doAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVTPrTZbKrv+1qv19U0zbFn4oEax7GGYaiu62q10vrAbnYTc5i6myYFVd/3dX5+frDhYJfr6+s6OztbegzgnrObmNNdu2lSUK3X66qq+r1eVFuPDjMZ/Mdt3dTHev/P9w1gF7uJOUzdTZOC6ttTaluPqm18aTmSv39V0tM9MIXdxCwm7ib/qAIAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChST+OnPryx9M5ruGeOHl3tfQIAHeym34+j19/2vts/9twwEm+54UKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDULj0A2z1+/Wmxuz+/ebLY3QAcT/+sic53l+OBJvn//vrlw95nn9evhxvkB7xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdegC2+/zmyd5nP7z9M7r7ova/G4D7q7sclx5hbxevXu599qSuDjjJ97xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2qUH4DguXr1cegQAeDC8UAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNqlB2C7/lmz99nucjzgJADALl6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7dIDsF13OS49AgAwgRcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVzXHLy7mqOawBgMruJQ/JCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQaqd8aBzHqqq6rZuq8ajz8IDd1k1V/ft9A9jFbmIOU3fTpKAahqGqqj7W+3AsuNswDHV6err0GMA9Zzcxp7t2UzNOeA7YbDbV932t1+tqmuagA8I34zjWMAzVdV2tVv4aDexmNzGHqbtpUlABALCdZwAAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgNBXuxyZSaLAgGUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEx0lEQVR4nO3dMW4bVxSG0TvEuBFAqB9IqVJ5A2kiL8BdlpDKhReQNWQBKVJlCeq8ANmNNpAqVQTMBgZwI4EvTZwAAUQO9JMzinVOzeG7xQD3w5MAdq21VgAAPNlm7QEAAP7vBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKif86HdblfjONZ2u62u6049Ey9Ua62maaphGGqz0frAfnYTS5i7m2YF1TiOdXl5ebThYJ+7u7u6uLhYewzgmbObWNKh3TQrqLbbbVVVfV9vq69Xx5kM/uOh7utTffjnfQPYx25iCXN306yg+nKV2ter6jsvLSfy969KuroH5rCbWMTM3eQfVQAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACA068eRU59/+G6JY3gmzq5v1x4B4CC76WU59W5yQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHoDT+Pan36Pn//j59ZEmAeA5Gd900fPDTXvysx9/+TU6+8c/r5787HgdHX2QGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAI9WsPAAAsZ7hpq5199f7damef1e1Jv98NFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF97AE7jt28+Rs9f1esjTQIAXz83VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq1x6A07h6/27tEQDgxXBDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QF43Pime/Kzw0074iQAwD5uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3aA/C44aatPQIAMIMbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1Sxxydn27xDEAMJvdxDG5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVzPtRaq6qqh7qvaiedhxfsoe6r6t/3DWAfu4klzN1Ns4JqmqaqqvpUH8Kx4LBpmur8/HztMYBnzm5iSYd2U9dmXAfsdrsax7G22211XXfUAeGL1lpN01TDMNRm46/RwH52E0uYu5tmBRUAAI9zDQAAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEPoLeieYWkUjGgoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEyElEQVR4nO3dMWojZxjH4XfEbGMY3Au7S+UqXZr1toF0W22dKkfIGXyAQHIKd3sA7za+QCqniWEuMJDGRpMmm0DA8qC/NCOvn6fWx7zFwPvjk0DNOI5jAQCws9XSAwAAvHSCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1E750Gazqb7vq+u6aprm0DPxSo3jWMMw1Hq9rtVK6wPb2U3MYepumhRUfd/X+fn53oaDbe7v7+vs7GzpMYAjZzcxp+d206Sg6rquqqre1g/V1pv9TAb/81gP9bk+/vu+AWxjNzGHqbtpUlB9uUpt6021jZeWA/nnXyVd3QNT2E3MYuJu8kMVAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACE36c+TUX++/m+MxHImT69ulRwB4lt30uhx6N7mhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItUsPAADMp3/XROf/+PDrzmd//PMyevbd1UV0/pDcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXXoADuObn3+Pzt9dXexpEgCOyfpmjM5f3vy0p0m+Lm6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7dIDcJw+/fLbzme/v/52f4MAwAvghgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7dIDcBh3VxfR+cva/fxJ3UbPBoCXxg0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNqlB+Bp/btm57Prm3GPkwAA27ihAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItUsPwNPWN+PSIwAAE7ihAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFA7x0NOrm/neAwATGY3sU9uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu2UD43jWFVVj/VQNR50Hl6xx3qoqv/eN4Bt7CbmMHU3TQqqYRiqqupzfQzHgucNw1Cnp6dLjwEcObuJOT23m5pxwnXAZrOpvu+r67pqmmavA8IX4zjWMAy1Xq9rtfJtNLCd3cQcpu6mSUEFAMDTXAMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT+BhB3mMKLK+OmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEtUlEQVR4nO3dsW3cdhTH8ccD3Rg4qCekBbJAmsgDpMsIqVRokgzgwlO48wCyG++QygK4AIE0Eu6fJk4AA7pj/OORSvT51EfwFQe8L54EXNdaawUAwHfbbT0AAMB/naACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1cz50OBxqHMfa7/fVdd25Z+KFaq3VNE01DEPtdlofOM5uYg1zd9OsoBrHsa6urhYbDo65v7+vy8vLrccAnjm7iTWd2k2zgmq/31dV1U/1c/X1apnJ4BuP9VCf6sPf3zeAY+wm1jB3N80Kqq+n1L5eVd/50nImf/2qpNM9MIfdxCpm7ib/qAIAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChWT+OnPrjlx/XeA3PxOv3n7ceAeAku+llOfducqECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1Ww8AAKzn49t30fO/frleaJJ/7/ffftjs3ae4UAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECo33oAAGA917c3W4/wv+RCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6rcegPP4+PZd9Pz17c1CkwDwrfFNFz0/3LWFJmEpLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6rcegPO4vr3ZegQAnjDcta1HYGEuVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDqtx6Ap41vuu9+drhrC04CABzjQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOq3HoCnDXdt6xEAgBlcqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUr/GS1+8/r/EaAJjNbmJJLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+zodaa1VV9VgPVe2s8/CCPdZDVf3zfQM4xm5iDXN306ygmqapqqo+1YdwLDhtmqa6uLjYegzgmbObWNOp3dS1GeeAw+FQ4zjWfr+vrusWHRC+aq3VNE01DEPtdv4aDRxnN7GGubtpVlABAPA0ZwAAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgNCf9ImVmnA4SCYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEr0lEQVR4nO3dMWrcCBTH4adBaQLCvbAvsBfYZp0DpMsRUrnwSfYAKXKKdDmAkyZ32CoGXUCQxma0zSYBg8ey/xrJi7+vHqFXDLwfz4ZppmmaCgCAJ9ttPQAAwP+doAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVzPrTf72sYhuq6rpqmOfZMvFDTNNU4jtX3fe12Wh84zG5iDXN306ygGoahzs7OFhsODrm+vq7T09OtxwCeObuJNT20m2YFVdd1VVX1V72ttl4tMxnccVs39bU+//q+ARxiN7GGubtpVlD9PKW29araxpeWI/nvVyWd7oE57CZWMXM3+UcVAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACM36ceTUj3d/rvEanonXn75tPQLAg+yml+XYu8mFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G49AADwOF8+fHzys++/ny84yeP88/cfm7372FyoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINRuPQAA8Djnlxdbj8AdLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF26wEA4KUZ3jTR8/3VtNAkLMWFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt1gNwHF8+fIyeP7+8WGgSAO7qr6atR2BhLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQarcegPsNb5onP3t+ebHgJADAIS5UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdusBuF9/NW09AgAwgwsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNo1XvL607c1XgMAs9lNLMmFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1M750DRNVVV1WzdV01Hn4QW7rZuq+v19AzjEbmINc3fTrKAax7Gqqr7W53AseNg4jnVycrL1GMAzZzexpod2UzPNOAfs9/sahqG6rqumaRYdEH6apqnGcay+72u389do4DC7iTXM3U2zggoAgPs5AwAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhP4FqYKTv2TRRmwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEsklEQVR4nO3dMW7kdBTH8eeRt1nJSj9KqKi4AM1mD0BHxRFS5ACcgRvQcYTt9gBhm70AFVSRfAFLNInmT0NAQsrEm59jB83nU4/lV4z0vnqJNF1rrRUAAM+223oAAID/O0EFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDq53zocDjUOI41DEN1XffSM3GiWms1TVPt9/va7bQ+cJzdxBrm7qZZQTWOY11cXCw2HBxze3tb5+fnW48BvHJ2E2t6ajfNCqphGKqq6l19V329WWYy+I/7uqtP9fGf7xvAMXYTa5i7m2YF1cMpta831Xe+tLyQv39V0ukemMNuYhUzd5N/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQrB9HTv35/bdrvIZX4u2Hz1uPAPAku+m0vPRucqECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1Ww8AAHyZr3/8bbN3//7TN5u9+zVzoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv/UAAMCX+eWrX5/97OX11YKT8MCFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G89AACcmvF9Fz1/eX210CQsxYUKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3WAwDAqdnftK1HYGEuVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDqtx6Ax43vu2c/+8cPP0fvvry+ip4HgFPiQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOq3HoDH7W/as5+9vLlacBIA4BgXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1a7zk7YfPa7wGAGazm1iSCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKif86HWWlVV3dddVXvReThh93VXVf9+3wCOsZtYw9zdNCuopmmqqqpP9TEcC542TVOdnZ1tPQbwytlNrOmp3dS1GeeAw+FQ4zjWMAzVdd2iA8KD1lpN01T7/b52O3+NBo6zm1jD3N00K6gAAHicMwAAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQOgvPnmSpR8+JX8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvElEQVR4nO3dMWocZxjH4XeWcWMY1C9Sl0oXCIHIB3CXyrUrFz5AzqADBOxTuPMBbDe+QCq7EswFBtJI7LixEjDsarL/1YysfZ56P81bDHp/fBJsM47jWAAA7G219AAAAD87QQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGqnfGiz2VTf99V1XTVNc98zcaTGcaxhGGq9XtdqpfWB3ewm5jB1N00Kqr7v6+zs7GDDwS5XV1d1enq69BjAA2c3Mae7dtOkoOq6rqqqfq/n1daTw0wGP7ip6/pU7/993wB2sZuYw9TdNCmobq9S23pSbeOl5Z58/1ZJV/fAFHYTs5i4m/yjCgBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQmfTly6p8/fp3jMTwQT999XnoEgDvZTcflvneTGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC79AAAwP/zy59/7332y+X5ASfhlhsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVLDwAAzOfjX2+j8xevXx1oksfFDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdegAAODb9syb7AZfnex+9qP3Psp0bKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1Sw/Adv2zZu+z6w/jAScB4JD8jn583FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF16ALb7+uLN3mdf/nYRPfvL5Xl0HgCOiRsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu/QAbHfx+tXSIwAAE7ihAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFA7x0Oevvs8x2MAYDK7iUNyQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGqnfGgcx6qquqnrqvFe5+GI3dR1Vf33vgHsYjcxh6m7aVJQDcNQVVWf6n04FtxtGIY6OTlZegzggbObmNNdu6kZJ1wHbDab6vu+uq6rpmkOOiDcGsexhmGo9Xpdq5W/RgO72U3MYepumhRUAABs5xoAACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACD0DR7YlCE8hbPKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEt0lEQVR4nO3dMW4UWRSG0VutIkEqOW/ZGZE3QDJmAZOxBCICFjBrYAEErIKMBQAJGyAiGku1gZJIbHWRDDMSEu1H/+0qj31O3OV3g5Lvp2dL3c3zPBcAAAfbrD0AAMD/naACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1LR/a7XY1jmMNw1Bd1932TDxQ8zzXNE213W5rs9H6wH52E0to3U1NQTWOY52dnR1tONjn8vKyTk9P1x4DuOPsJpZ0025qCqphGKqq6o/6s/p6dJzJ4CfXdVWf6v2/7xvAPnYTS2jdTU1B9eMqta9H1XdeWm7JP98q6eoeaGE3sYjG3eQfVQAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDU9OXIqW/Pny5xDHfE43ef1x4B4EZ208Ny27vJDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE+rUHAAB+z5O/vqx29tfX56udfZe5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACPVrDwAAD834rMt+wOvzgx/9+OZtdPRFHX72feaGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL92gPwa+Oz7uBntx/mI04CwDGt+Tv64tXL1c6+z9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhfe4D77OObt9HzL/6+OPjZrx/Oo7MBgHZuqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3aA9xnF69erj0CALAAN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6pc45PG7z0scAwDN7CaOyQ0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECob/nQPM9VVXVdV1Xzrc7DA3ZdV1X13/sGsI/dxBJad1NTUE3TVFVVn+p9OBbcbJqmOjk5WXsM4I6zm1jSTbupmxuuA3a7XY3jWMMwVNd1Rx0QfpjnuaZpqu12W5uNv0YD+9lNLKF1NzUFFQAAv+YaAAAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg9B2F4JUm2SbZwQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEt0lEQVR4nO3dMWocZxjH4XeWcWMY1C9SFVe+QJooB0jnyrWr5AY5gw9gsI+Qyp0PoLjxBVI5jQVzgYE0EvuliRMI9mrQf3dGlp6n3o95i0Hvj28F27XWWgEAcGubtQcAAPjWCSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFA/50O73a7GcaxhGKrrumPPxAPVWqtpmmq73dZmo/WB/ewmljB3N80KqnEc6+zs7GDDwT6Xl5d1enq69hjAHWc3saSbdtOsoBqGoaqqfqifqq9Hh5kM/ue6rup9vfv3fQPYx25iCXN306yg+nyV2tej6jsvLUfyz69KuroH5rCbWMTM3eQfVQAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACA068eRU389+36Jx3BHPH77Ye0RAG5kNz0sx95NbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K89AACwnCe//hGd//jy6YEmuV/cUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhPq1BwCAh2b8sYvO//n89a3Pvvh0Hj2bL3NDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QHus99fvYnOf/fbL7c+u71o0bMBOJ70b/T5xc8HmoRDcUMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7tAe6zF5/Oo/Pbi3agSQCAY3JDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tce4D77+PLp2iMAAAtwQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChfomHPH77YYnHAMBsdhOH5IYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUz/lQa62qqq7rqqoddR4esOu6qqr/3jeAfewmljB3N80Kqmmaqqrqfb0Lx4KbTdNUJycna48B3HF2E0u6aTd1bcZ1wG63q3EcaxiG6rruoAPCZ621mqapttttbTa+jQb2s5tYwtzdNCuoAAD4OtcAAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChvwF07pZguPFaHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEyElEQVR4nO3dMW7bZhjH4ZcCswQgvBN2J0/tAbrUOUC3HqFThhwgZ+gBOnTqEbzlAE6AIhfI1CkGeAECXWyIXZoWKBqZ9V8iFfl5ZhHfOxB+f/hkQM00TVMBAPBom7UHAAD40gkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQO+dD2+22hmGoruuqaZpDz8QTNU1TjeNYfd/XZqP1gd3sJpYwdzfNCqphGOri4mJvw8Eut7e3dX5+vvYYwJGzm1jSQ7tpVlB1XVdVVd/V99XWs/1MBv9yX3f1rt78/b4B7GI3sYS5u2lWUH26Sm3rWbWNl5YD+etXJV3dA3PYTSxi5m7yjyoAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQmvXjyKk/fvh2iWM4Es+v3689AsCD7Kan5dC7yQ0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNq1BwAAlnP5+kP0/M1v3zz62f5mis4+Zm6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7doDAMBT8/bnX6Lnf/x4tadJ/r/+Zlrt7GPmhgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7doDnLLL1x+i53/96u2jn7169TI6G4DD8Tf69LihAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC79gB83tWrl2uPAADM4IYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj3AKfv9p6/XHgEAWIAbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1aw9waMOLJnq+v5n2NAkAcKrcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhNolDnl+/X6JY/7T5fVqRwNwxNbcTZweN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2zoemaaqqqvu6q5oOOg9P2H3dVdU/7xvALnYTS5i7m2YF1TiOVVX1rt6EY8HDxnGss7OztccAjpzdxJIe2k3NNOM6YLvd1jAM1XVdNU2z1wHhk2maahzH6vu+NhvfRgO72U0sYe5umhVUAAB8nmsAAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQn4BOl5Lq3c7qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEw0lEQVR4nO3dMW4bVxSG0TvEuDEwUD+QOlfeQJrIC0iXVajQArIGL8CFV6HOC5DdeAOu3AmYDQyQRgInTZwARkxN9JMzNHVOzYd3CwL3w5MANtM0TQUAwJNt1h4AAOBnJ6gAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELtnA9tt9sahqG6rqumaQ49E8/UNE01jmP1fV+bjdYHdrObWMLc3TQrqIZhqIuLi70NB7vc3d3V+fn52mMAR85uYkmP7aZZQdV1XVVV/Vq/VVsv9jMZfOeh7utTffjn+wawi93EEubupllB9e0pta0X1Ta+tBzI378q6ekemMNuYhEzd5N/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQrB9HTv35+y9LXMOReHnzee0RAB5lNz0vh95NXqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K49AADw8xjeNE8+299Oe5zkuHihAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItWsPAAD8Px/fvX/y2cvrq+ju/naKzp8qL1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQatce4JS9+uPLand/fft6tbsBOKzL66u1R+A7XqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K49wCn7+vZ1dP7ju/dPPntZ2d0AwHxeqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3aA/Bjl9dXa48AAMzghQoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7doDHNrwponO97fTniYBAE6VFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC7xCUvbz4vcc1/enWz2tUAHLE1dxOnxwsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEConfOhaZqqquqh7qumg87DM/ZQ91X17/cNYBe7iSXM3U2zgmocx6qq+lQfwrHgceM41tnZ2dpjAEfObmJJj+2mZprxHLDdbmsYhuq6rpqm2euA8M00TTWOY/V9X5uNv0YDu9lNLGHubpoVVAAA/JhnAACAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCA0F9AQ5Z5Vl4SdQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuklEQVR4nO3dsW0bdxTH8XfEuTFwUE9IqVx5gTSRB0iXKVRogMyQAVKkygjqPIDtxgukSifgFjggjQT+08QJEETURT/yjpY+n5qHewWB98WTAHattVYAADzZZu0BAAC+doIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUz/nQbrercRxrGIbquu7YM/FCtdZqmqbabre12Wh9YD+7iSXM3U2zgmocx7q4uDjYcLDP7e1tnZ+frz0GcOLsJpb02G6aFVTDMFRV1Xf1ffX16jCTwb/c1119qvd/f98A9rGbWMLc3TQrqL6cUvt6VX3nS8uR/PWrkk73wBx2E4uYuZv8owoAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEZv04cuqPH75d4jWciNc3n9ceAeBRdtPLcuzd5EIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX7tAQCAr8f4rnvys9sP7YCTnBYXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/2AADAcj7+/Ev0/OX11YEmeV5cqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrz0AD3vz429Pfvb3n94ecBIAnovL66u1R3iWXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K89AA/79ZuPT372st4ecBIAYB8XKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj1aw9wbOO7Lnp++6EdaJL/7/L6arV3AwDzuVABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6JV7y+ubzEq/5T29uVns1ACdszd3E8+NCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6ud8qLVWVVX3dVfVjjoPL9h93VXVP983gH3sJpYwdzfNCqppmqqq6lO9D8eCx03TVGdnZ2uPAZw4u4klPbabujbjHLDb7WocxxqGobquO+iA8EVrraZpqu12W5uNv0YD+9lNLGHubpoVVAAAPMwZAAAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg9Ce3WZKctkJoYwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwklEQVR4nO3dMW4TaRjH4XesoUEapbeSjooLbEM4wHZUHCEFB+AMHGCl3VOk4wCBhgtQsVWkucBINIk8NLArIXAG/+0ZhzxP7U/zFiO9P3225GYcx7EAANjZaukBAADuO0EFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBqp3xos9lU3/fVdV01TXPomXigxnGsYRhqvV7XaqX1ge3sJuYwdTdNCqq+7+vs7Gxvw8E219fXdXp6uvQYwJGzm5jTXbtpUlB1XVdVVc/qz2rr0X4mg+/c1k29r7f/vW8A29hNzGHqbpoUVN+uUtt6VG3jpeVAvv6rpKt7YAq7iVlM3E1+qAIAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChSX+OnPr84o85HsOReHz5YekRAO5kNz0sh95NbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1C49AABwf/TPm53Prq/GPU5yXNxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2qUHAADuj39f/r3z2fOriz1OclzcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXXoAAOD+OH91sfQIR8kNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITapQfg5568/rjz2U9vnu5xEgBgGzdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdukBOIx3f/0TnT9/dbGnSQDg9+eGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt0gMcWv+8ic6vr8Y9TfLrPr15uvPZ89r9LADwa9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2jke8vjywxyP+aEnl4s9GoAjtuRu4vfjhgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINRO+dA4jlVVdVs3VeNB5+EBu62bqvr/fQPYxm5iDlN306SgGoahqqre19twLLjbMAx1cnKy9BjAkbObmNNdu6kZJ1wHbDab6vu+uq6rpmn2OiB8M45jDcNQ6/W6VivfRgPb2U3MYepumhRUAAD8nGsAAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQF+5RlNAH4zPIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEzElEQVR4nO3dMW7bZhjH4ZcCsxgQvAt2J0+ZunWpsxboliNk6tAD9Aw5QIdOPYK2HCDJ4gt0ylQDvACBLjbELk0DBInE6i+RUv08s4jvHQi8P3wSoGYYhqEAANjbYu4BAADOnaACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1Yz602Wyq67paLpfVNM2xZ+KJGoah+r6v1WpVi4XWB7azm5jC2N00Kqi6rqvr6+uDDQfb3N/f19XV1dxjACfObmJKu3bTqKBaLpdVVfV9/VhtPTvMZPCZx3qo9/Xm3/cNYBu7iSmM3U2jgurjVWpbz6ptvLQcyT//KunqHhjDbmISI3eTH6oAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAaNSfI6f+evndFMdwIi7Wd3OPALCT3fS0HHs3uaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUDv3AADA+Xj36297P3v7808HnOS0uKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1cw8AAJyPV3/eznZ296LZ+9mb9QEH+QI3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBq5x4AADgfH14/n+3s1dthtrN3cUMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbuAfi6m1/+mO3s3795t/ezP6y/PdwgAHAG3FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqJ17gGPrXjTR86u3w4Em+e8+vH4+29m3tf/ZF3V3wEkA4PS5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVTHHKxvpvimC+6Wc92NAAnbM7dxP+PGyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFA75kPDMFRV1WM9VA1HnYcn7LEequrT+wawjd3EFMbuplFB1fd9VVW9rzfhWLBb3/d1eXk59xjAibObmNKu3dQMI64DNptNdV1Xy+WymqY56IDw0TAM1fd9rVarWix8Gw1sZzcxhbG7aVRQAQDwda4BAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCfwOyQZZZH9RzJgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvElEQVR4nO3dPW4UWRSG4VOtIkEqOW/ZRI5mA5OMWQAZq3DgBbCGWQABEUtwxgKAhA1MRGapNlASia0uEn4kNHSX+uuusvHzxH11T9DSeXVtqZtxHMcCAGBvq6UHAAB46AQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEConfKhzWZTfd9X13XVNM2xZ+KRGsexhmGo9Xpdq5XWB7azm5jD1N00Kaj6vq+zs7ODDQfb3Nzc1Onp6dJjAPec3cScdu2mSUHVdV1VVf1TL6qtJ4eZDH5xV7f1sd79+L4BbGM3MYepu2lSUH1/Sm3rSbWNLy1H8u1XJT3dA1PYTcxi4m7yjyoAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQmvTjyKkvL/+e4xruiafXn5YeAWAnu+lxOfZu8kIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbpAQCAh+P81X97n3377EN098XVZXT+mLxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2qUHAAAejs///rX32Yva/2xVVf+82fvs+XV09U5eqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDULj0AAMAU6/fj0iP8lhcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVLD8BxfHj9Jjp/cXV5oEkA4M/nhQoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7dIDHFv/vInOr9+PB5pkXhdXl0uPAACPhhcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQO8clT68/zXHN/zq/XuxqAO6xJXcTfx4vVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbKh8ZxrKqqu7qtGo86D4/YXd1W1c/vG8A2dhNzmLqbJgXVMAxVVfWx3oVjwW7DMNTJycnSYwD3nN3EnHbtpmac8Byw2Wyq7/vquq6apjnogPDdOI41DEOt1+tarfw1GtjObmIOU3fTpKACAOD3PAMAAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIS+Ajn4k2/DhmrmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuklEQVR4nO3dMW4cZRjH4XdWkybSyP3KpsEVNHQ0JC0SHadIkQNwBg5AQcUR3OUASQpyASo6S3OBkWhs7dAQkBDe/fB/d8awz1Pvp+8tVnp/+mxpu3me5wIA4NE2aw8AAPBfJ6gAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEJ9y4d2u12N41jDMFTXdaeeiTM1z3NN01Tb7bY2G60P7Gc3sYTW3dQUVOM41tXV1dGGg31ub2/r8vJy7TGAJ85uYkmHdlNTUA3DUFVVX9U31dez40wGf3Nfd/W+3vz5fQPYx25iCa27qSmoPj6l9vWs+s6XlhP541clPd0DLewmFtG4m/yjCgBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAISafhw59du3Xy5xDU/E85sPa48AcJDddF5OvZu8UAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoX3sAAOA8XH/3S3T+p0/ePfrs1zdfRHcf4oUKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrz0AAHAefv3+s+j8py8/f/TZ6/o5uvsQL1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tceAACgxfbtvPYID/JCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+7QF42Lsffnz02RevXx1xEgBgHy9UAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEOrXHuDUxpdddH77dj7SJP/ei9evVrsbAGjnhQoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINQvccnzmw9LXPOPrm9WuxqAJ2zN3cT/jxcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQ3/KheZ6rquq+7qrmk87DGbuvu6r66/sGsI/dxBJad1NTUE3TVFVV7+tNOBYcNk1TXVxcrD0G8MTZTSzp0G7q5obngN1uV+M41jAM1XXdUQeEj+Z5rmmaarvd1mbjr9HAfnYTS2jdTU1BBQDAwzwDAACEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEfgfq/pKfN4UXEwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwklEQVR4nO3dMW4bVxSG0TvEuBEwUE9InapU6dJYbgOkyypUaAFZQxbgwqtg5wXEbrSBVOkEzAYGSCOBkyaOgcQhB/zJGdk8p+bTuwWB++FJgJpxHMcCAOBgq6UHAAD42gkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQO+VD2+22+r6vruuqaZpTz8SZGsexhmGo9Xpdq5XWB3azm5jD1N00Kaj6vq/r6+ujDQe7PD4+1tXV1dJjAC+c3cSc9u2mSUHVdV1VVb2un6qtV8eZDP7luZ7qY73/5/sGsIvdxBym7qZJQfXpKbWtV9U2vrScyN//VdLTPTCF3cQsJu4mf6gCABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoUn/HDn1588/zHENL8TF5mHpEQD2spvOy6l3kxcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVLDwAAnIebX35f7O5+c9qf74UKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDULj0AAHAe/vj1u+j8h7fvDj77Y30f3b2PFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItUsPAAAwxe393cFnL+rhiJP8lxcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVLD/At+/D2XXT+9v7uSJMAwNevf9McfPZmc8RBvsALFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITapQc4tf5NE51f/zYefPb2/i66GwD4LNnJp+aFCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1M5xycXmYY5rvuhms9jVALxgS+4mvj1eqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu2UD43jWFVVz/VUNZ50Hs7Ycz1V1efvG8AudhNzmLqbJgXVMAxVVfWx3odjwX7DMNTl5eXSYwAvnN3EnPbtpmac8Byw3W6r7/vquq6apjnqgPDJOI41DEOt1+tarfw2GtjNbmIOU3fTpKACAOD/eQYAAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAj9BQYUlljDyI1NAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuUlEQVR4nO3dMW4jZRjH4Xes2SbSKL2VUOUAdDRkWyQ6TpEiB+AkFFQcwd0egN0mF+ACkeYCI9Ek8tCwIEHWGfk/njHkeWp/mrcY6f3psyU34ziOBQDA0TZrDwAA8F8nqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu2UD+33++r7vrquq6ZpTj0Tb9Q4jjUMQ22329pstD5wmN3EEqbupklB1fd9XV9fzzYcHPL4+FhXV1drjwGcObuJJb22myYFVdd1VVX1bX1fbb2bZzL4h+d6qk/14a/3DeAQu4klTN1Nk4Lq81VqW++qbby0nMif/yrp6h6Ywm5iERN3kx+qAACEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQGjSnyOnfv/hmyUew5m42D2sPQLAq+ymt+XUu8kNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITatQcAAJji5sffjj7b72Yc5AVuqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj0AAMAUv3z18eiz39XX8w3yAjdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGrXHgAAYIrb+7ujz17Uw4yT/JsbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv2AOfu408/H3329v5uxkkA4G3r3zdHn73ZzTjIC9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhde4BT69830fnb+7uZJgEAEttfx7VH+CI3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXaJh1zsHpZ4zItudqs9GoAztuZu4v/HDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKid8qFxHKuq6rmeqsaTzsMb9lxPVfX3+wZwiN3EEqbupklBNQxDVVV9qg/hWPC6YRjq8vJy7TGAM2c3saTXdlMzTrgO2O/31fd9dV1XTdPMOiB8No5jDcNQ2+22NhvfRgOH2U0sYepumhRUAAB8mWsAAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQH+J0kn1ECG/EAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuUlEQVR4nO3dMW7bZhjH4ZcCsxggvAt2l/oA3bI0XQt0yylSIAfoSTp06txJWw6QZPEFegEDvACBLjbELE0LtK5M6E+RSv08sz7wHQi8P3wSoGYcx7EAADjaZu0BAAC+dIIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUTvnQfr+vvu+r67pqmubUM/FMjeNYwzDUdrutzUbrA4fZTSxh6m6aFFR939f19fVsw8Ehd3d3dXV1tfYYwJmzm1jSU7tpUlB1XVdVVd/WD9XWi3kmg394qPv6WO/+et8ADrGbWMLU3TQpqD5fpbb1otrGS8uJ/Pmvkq7ugSnsJhYxcTf5oQoAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEJv05cuqP1y+XeAxn4mJ3u/YIAE+ym56XU+8mN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQatceAABgipuffj/6bL+bcZBHuKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv2AAAAU/z61Yejz35f38w3yCPcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXXsAAIApXr19c/TZi7qdcZJ/c0MFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBq1x7g1D78/Et0/tXbNzNNAgAk+u+ao8/e7GYc5BFuqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj3AqX3924/R+W2NM00CACS27893J7uhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItUs85GJ3u8RjHnWzW+3RAJyxNXcT/z9uqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu2UD43jWFVVD3VfNZ50Hp6xh7qvqr/fN4BD7CaWMHU3TQqqYRiqqupjvQvHgqcNw1CXl5drjwGcObuJJT21m5pxwnXAfr+vvu+r67pqmmbWAeGzcRxrGIbabre12fg2GjjMbmIJU3fTpKACAOC/uQYAAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAh9AuBQkpYenSjVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEyUlEQVR4nO3dMW7bZhjH4ZcCsxggvBN2lnrKlK1L0jVAt96iN8gZeorMnbzlAE6G5gKZuhngBQh0sSF2aVqgdWRCf4lU6ueZ9YHvQOD94ZMANdM0TQUAwN42aw8AAPCtE1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2zoe2220Nw1Bd11XTNMeeiSdqmqYax7H6vq/NRusDu9lNLGHubpoVVMMw1OXl5cGGg11ub2/r4uJi7TGAE2c3saTHdtOsoOq6rqqqXtWP1dazw0wG/3Jfd/Wx3v/9vgHsYjexhLm7aVZQfblKbetZtY2XliP5618lXd0Dc9hNLGLmbvJDFQCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAjN+nPk1B8/fb/EYzgRZ9ef1h4B4FF209Ny7N3khgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7doDnLrhh2bvs/3NdMBJAIBT5YYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj3AqetvprVHAABOnBsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVrDwAAMMfV2897nx2uDzjIA9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdewAAgDnePf+w99k39fJwgzzADRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhde4Bju3r7OTr/+y8vDjQJAJD47tef9z57Vb8dcJL/ckMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbtAY7t3fMP0fnX9eJAkwAAif5mWnuEr3JDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQapd4yNn1pyUe86A31y+j82e13uwAHM+au4n/HzdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChds6Hpmmqqqr7uquajjoPT9h93VXVP+8bwC52E0uYu5tmBdU4jlVV9bHeh2PB48ZxrPPz87XHAE6c3cSSHttNzTTjOmC73dYwDNV1XTVNc9AB4Ytpmmocx+r7vjYb30YDu9lNLGHubpoVVAAAfJ1rAACAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCA0J+lAJZ5SlFBUgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEzklEQVR4nO3dP27bdhjH4ZcCsxgQvBN2Jx+gW5c6a4FuPUKnDDlATtKhU4/gLQdwMiQXyAFigBcg0MWG2CV/gCKRCH0lUq2eZ9YPfA0QeD/4yYCacRzHAgBgb6ulBwAA+K8TVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbKhzabTfV9X+v1upqmOfZMnKlxHGsYhuq6rlYrrQ9sZzcxh6m7aVJQ9X1f19fXBxsOtnl4eKirq6ulxwBOnN3EnHbtpklBtV6vq6rq5/q12np2mMngX57qsd7W6y/vG8A2dhNzmLqbJgXV56vUtp5V23hpOZJPvyrp6h6Ywm5iFhN3k39UAQAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgNCkH0dO/f3bT3M8hhNxcfd+6REAdrKbzsuxd5MbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1Sw9w6vrnzd5nu/vxgJMAAKfKDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdeoBT192PS48AAJw4N1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQapceAABgiptXH/Y+298dcJBvcEMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbpAQCA8/Dmjz+j879/vD3QJIfnhgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINQuPQAAcB5uX76IzvfPm73P3tS76Nm7uKECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv0AMd28+pDdP6vH97sffb25Yvo2QDAV939uPQI3+WGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1M7xkIu793M85pv6u+z8L/Xj3mcvarm/G4DtltxN/P+4oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVTPjSOY1VVPdVj1XjUeThjT/VYVV/fN4Bt7CbmMHU3TQqqYRiqquptvQ7Hgt2GYajLy8ulxwBOnN3EnHbtpmaccB2w2Wyq7/tar9fVNM1BB4TPxnGsYRiq67parXwbDWxnNzGHqbtpUlABAPB9rgEAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL/APYzmPIFSIGJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuklEQVR4nO3dMW7cVhSG0csB3Qgg1BNSlz2kibyAdFmCqxRZjwuvQp0XILuIt2EB3AABNxKGbuwESOARM/8MSUXn1PPEK4DA/fAkYJppmqYCAOBou7UHAAB47gQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEConfOh/X5fwzBU13XVNM25Z+KFmqapxnGsvu9rt9P6wGF2E0uYu5tmBdUwDHV9fX2y4eCQ+/v7urq6WnsMYOPsJpb01G6aFVRd11VV1S/1a7X16jSTwT881kN9rPd/vW8Ah9hNLGHubpoVVN+vUtt6VW3jpeVMvn2rpKt7YA67iUXM3E3+UQUAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCs74cOfXlt5+XeAwbcXH7ae0RAJ5kN70s595NbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K49wNYNr5ujz/Z30wknAQC2yg0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXXuArevvprVHAAA2zg0VAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXXsAAOD5+PD23dFn33y+OeEk/81we96f74YKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUrj3A1n14++7oszd//H7CSQBgfWvutuF1c/TZn+rPE07yb26oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINSuPcDWvfl8s/YIAEBV9XfT2iP8kBsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu8RDLm4/LfGYsxhujz97Uc/39wb4v3vOu4ntcUMFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBq53xomqaqqnqsh6rprPPwgj3WQ1X9/b4BHGI3sYS5u2lWUI3jWFVVH+t9OBY8bRzHury8XHsMYOPsJpb01G5qphnXAfv9voZhqK7rqmmakw4I303TVOM4Vt/3tdv5azRwmN3EEubupllBBQDAj7kGAAAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAIfQXZWJeItT4dDAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAExElEQVR4nO3dMW7bZhjH4ZcCswQgvBN2p0y5QJc6B+jWI3Ty4AP0DDlAh049grccwMmSC3TKVAO8AIEuNsQuTQsUqEToL5Ms/DyziO8dCLw/fBKgZpqmqQAAONlu7QEAAP7vBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKid86H9fl/DMFTXddU0zXPPxAs1TVON41h939dup/WBw+wmljB3N80KqmEY6urq6mzDwSEPDw91eXm59hjAxtlNLOnYbpoVVF3XVVXVd/V9tfXqPJPBvzzVY32qD3+/bwCH2E0sYe5umhVUX69S23pVbeOl5Zn89a+Sru6BOewmFjFzN/mhCgBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIRm/Tly6o8fvl3iGDbi9d3ntUcAOMpuelmeeze5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu/YAWze8a05+tr+fzjgJALBVbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt2gNsXX8/rT0CALBxbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt2gNs3ceffzn52evbmzNOAgDre/PTb6ud/eX929XOPsYNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF17gK378ffrtUcAgM349ZuPJz97fXsTnT28a05+9s1ddPRRbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K49wNZ9ef927REAYDOub29WO7u/n1Y7+xg3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXaJQ17ffV7iGACYzW7inNxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2jkfmqapqqqe6rFqetZ5eMGe6rGq/nnfAA6xm1jC3N00K6jGcayqqk/1IRwLjhvHsS4uLtYeA9g4u4klHdtNzTTjOmC/39cwDNV1XTVNc9YB4atpmmocx+r7vnY730YDh9lNLGHubpoVVAAA/DfXAAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoT8BeLCXH6D8H8UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEyElEQVR4nO3dMW7bZhjH4ZcCswQQvBP21Ey+QJe6B8jWI3RqgR6gZ/ABMuQInbzlAEmWXKCTpxjgBQh0sSF2aVqgQCVCf4lk6ueZ9YHvQOD94ZMANeM4jgUAwNE2Sw8AAPC1E1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2yod2u131fV/b7baapjn3TDxT4zjWMAzVdV1tNlof2M9uYg5Td9OkoOr7vq6urk42HOzz8PBQl5eXS48BrJzdxJwO7aZJQbXdbquq6rt6XW29OM1k8C9P9Vgf693f7xvAPnYTc5i6myYF1Zer1LZeVNt4aTmTv/5V0tU9MIXdxCwm7iY/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQpD9HTv3xw7dzPIaVeHn3aekRAA6ym56Xc+8mN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQapceYO3675ujz3bvxxNOAgCslRsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu/QAa9e9H5ceAQBYOTdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGqXHmDtPrx5e/TZm19+OuEkAMBauaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv0AGv34+ebpUcAgNV49evvR5+9v70+4STr4oYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDULj3A2t3fXi89AgD8L3x48zY6/81vPx999tVd9OiD3FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF16AADg63F/e3302Zs6/mxVVVdjdP6c3FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAITaOR7y8u7THI8BgMnsJk7JDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKid8qFxHKuq6qkeq8azzsMz9lSPVfXP+wawj93EHKbupklBNQxDVVV9rHfhWHDYMAx1cXGx9BjAytlNzOnQbmrGCdcBu92u+r6v7XZbTdOcdED4YhzHGoahuq6rzca30cB+dhNzmLqbJgUVAAD/zTUAAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEDoTzNylre88jZfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEx0lEQVR4nO3dMW7bBhTH4UeBWQwQ3gW7U6ZM3brUXQt069S5U4+QM+QG3XoEbzmAm8UXyJQsMcALEOhiQ+yQpgVSVCL0l0mm/r5ZBN8g4P3wbEDNOI5jAQBwtM3SAwAAfOkEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqJ3yod1uV33fV9d11TTNY8/EEzWOYw3DUNvttjYbrQ/sZzcxh6m7aVJQ9X1fl5eXJxsO9rm7u6uLi4ulxwBWzm5iTod206Sg6rquqqq+rR+qrWenmQw+81D39aZe//19A9jHbmIOU3fTpKD6dEpt61m1jS8tj+SvX5V0ugemsJuYxcTd5B9VAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAIDTpx5FTf/z4zRyvYSXOrm+XHgHgILvpaXns3eRCBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF26QHWrv+uOfrZ7c14wkkA4CO7aX1cqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3SA6zd+59+PfrZq5tfTjgJAHy0vRmXHoHPuFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF16gLX7+cPV0iMAACvnQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdukB1u7dqxdLjwAAq/H85dujn/0/71QXKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv0AADA0/D85dvo+d+++v3oZ7+//jp69yEuVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABBqlx4AAPhyvHv1YrF3X9Xx7z6r2xNO8m8uVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXaOl5xd387xGgCYzG7ilFyoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7ZQPjeNYVVUPdV81Puo8PGEPdV9V/3zfAPaxm5jD1N00KaiGYaiqqjf1OhwLDhuGoc7Pz5ceA1g5u4k5HdpNzTjhHLDb7arv++q6rpqmOemA8Mk4jjUMQ22329ps/DUa2M9uYg5Td9OkoAIA4L85AwAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhP4ETp6ZwgjO8QEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEtUlEQVR4nO3dsW3cBhTH4ccD3Rgg1BNSlyoLpIk8gDuPkEqFJskALjyFOg8gu/EOriKACxBII+GYIlGCGMiJ0J9HnqPvq4/gKw54PzwJuGaapqkAAHi23dYDAAB87wQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEConfOh/X5fwzBU13XVNM2xZ+KFmqapxnGsvu9rt9P6wGF2E2uYu5tmBdUwDHVxcbHYcHDI3d1dnZ+fbz0GcOLsJtb01G6aFVRd11VV1c/1ttp6tcxk8I2Huq/P9fHv7xvAIXYTa5i7m2YF1eMpta1X1Ta+tBzJX78q6XQPzGE3sYqZu8k/qgAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBo1o8jp35/99Mar+FEvL75svUIAE+ym16WY+8mFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItVsPcOo+vf/w7Gcvr68WnAQA/jS8aZ79bH87LTgJj1yoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7dYDnLpffrvcegQA+Jf+dtp6BL7hQgUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGq3HuDUff31x61H2MTwpnn2sz/cLDgIAHwHXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt1gNwmvrbaesRAPif+fT+Q/T85fXVQpMsz4UKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3WAwAAL8Pl9dXWIxyNCxUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhd4yWvb76s8RoAmM1uYkkuVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbOh6Zpqqqqh7qvmo46Dy/YQ91X1T/fN4BD7CbWMHc3zQqqcRyrqupzfQzHgqeN41hnZ2dbjwGcOLuJNT21m5ppxjlgv9/XMAzVdV01TbPogPBomqYax7H6vq/dzl+jgcPsJtYwdzfNCioAAP6bMwAAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQOgPGPqUkLMwG/EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwUlEQVR4nO3dsW3cBhTH4ccD3Rg4qCekVK6yQBrLA7jLFCo0QGbIAClSZQR1HkB24wVcuRPABQi4kXBMYzmAgZyI+59ISvq++gi+4oD3w5OAa8ZxHAsAgINtlh4AAOCpE1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2yod2u131fV/b7baapnnsmXihxnGsYRiq67rabLQ+sJ/dxBym7qZJQdX3fZ2dnR1tONjn5uamTk9Plx4DWDm7iTk9tJsmBdV2u62qqrf1vtp6dZzJ4Cd3dVuf6sOP7xvAPnYTc5i6myYF1f0pta1X1Ta+tDyS778q6XQPTGE3MYuJu8k/qgAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBo0o8jp779/tscr2ElXl99XnoEgAfZTS/LY+8mFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItUsPsHZv/vhy8LP//PIxevf55UX0PADPU/+uOfjZ7no84iTcc6ECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1Sw/wnJ1fXiw9AgDPUHc9Lj0CP3GhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC79ABr9/XPX5ceAQBYORcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVLD8A69e+ag599c3XEQQDgCXChAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItUsPwDp11+PSIwCwQh//+vvgZ88vL444ybq4UAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXXoAAODpOL+8WHqEVXKhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItXO85PXV5zleAwCT2U0ckwsVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEConfKhcRyrququbqvGR52HF+yubqvqv+8bwD52E3OYupsmBdUwDFVV9ak+hGPBw4ZhqJOTk6XHAFbObmJOD+2mZpxwDtjtdtX3fW2322qa5qgDwr1xHGsYhuq6rjYbf40G9rObmMPU3TQpqAAA+H/OAAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoX8ByeyVIds3F4wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEuUlEQVR4nO3dsW3cZhjH4ZcHujFAqCekVK6yQJrIA7jzFCo0gGfwAClSZQR1HkB24wVSpRPABQikkXBME9mAgZyI+59IBnqe+ojvLQi8P3x3wDXTNE0FAMDRdmsPAADwfyeoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABC7ZwP7ff7Goahuq6rpmmeeyZeqGmaahzH6vu+djutDxxmN7GEubtpVlANw1AXFxcnGw4Oubu7q/Pz87XHADbObmJJT+2mWUHVdV1VVf1a76qtV6eZDH7wUPf1pT59e98ADrGbWMLc3TQrqB6vUtt6VW3jpeWZ/Puvkq7ugTnsJhYxczf5oQoAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEZv05curv978scQwb8frm69ojADzJbnpZnns3uaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv2AFv35sOfq539x0+fj3728vrqhJMAsCXD2+boZ/vb6YST8MgNFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF17gK376+PPq519WeudDcB29bfT2iPwAzdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdu0B2KbhbXP0s29uTjgIAJvy+bffj3728vrqhJNsixsqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu/YAbFN/O609AgAbdHl9tfYIm+SGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELtEoe8vvm6xDEAMJvdxCm5oQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVzPjRNU1VVPdR91fSs8/CCPdR9VX1/3wAOsZtYwtzdNCuoxnGsqqov9SkcC542jmOdnZ2tPQawcXYTS3pqNzXTjOuA/X5fwzBU13XVNM1JB4RH0zTVOI7V933tdr6NBg6zm1jC3N00K6gAAPhvrgEAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL/AAAilHWwzMrIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEvElEQVR4nO3dsW3cZhjH4ZcHujFAqCekVK6yQBrLA6TLFCo0QGbIAClSZQR1HkB24wVSpRPABQikkXBMEyWAgZwI/XnkyXqe+ojvLQi8P3x3wDXTNE0FAMCz7bYeAADgpRNUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChds6H9vt9DcNQXddV0zTHnolXapqmGsex+r6v3U7rA4fZTaxh7m6aFVTDMNTFxcViw8Ehd3d3dX5+vvUYwImzm1jTU7tpVlB1XVdVVe/rx2rrzTKTwVce6r4+18d/3zeAQ+wm1jB3N80Kqser1LbeVNt4aTmSf/5V0tU9MIfdxCpm7iY/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQrD9HTv310w9rHMOJeHvzZesRAJ5kN70ux95NbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G49wLfs3c9/bHb27999ip6/vL5aaBIAljZ8aJ79bH87LTgJj9xQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2q0H+Jb9+cv3m519WdudDcBx9bfT1iPwFTdUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEGq3HgAAeDk+/frbs5+9vL5acJLT4oYKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3WA3Cahg/Ns599d7PgIACclMvrq61HOEluqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQu3WA3Ca+ttp6xEA4MVwQwUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChdo1D3t58WeMYAJjNbmJJbqgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELtnA9N01RVVQ91XzUddR5esYe6r6r/3jeAQ+wm1jB3N80KqnEcq6rqc30Mx4KnjeNYZ2dnW48BnDi7iTU9tZuaacZ1wH6/r2EYquu6appm0QHh0TRNNY5j9X1fu51vo4HD7CbWMHc3zQoqAAD+n2sAAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQ3xZWlHczrlDQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwklEQVR4nO3dMWocZxjH4XeWcSNY1A9SKlep0rmJ3AbS+RQufICcIQdIkSpHUOcDyG50gVTpBHOBgTQSO24sBxy0GvY/mlmh56l3+N5i4P3x7cI24ziOBQDAwTZrDwAA8NwJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUDvlQ7vdrvq+r+12W03TPPVMvFDjONYwDNV1XW02Wh/Yz25iCVN306Sg6vu+zs/PZxsO9rm5uamzs7O1xwCOnN3Ekh7bTZOCarvdVlXVz/VrtfVqnsngO3d1W5/r47f3DWAfu4klTN1Nk4Lq/iq1rVfVNl5ansjXf5V0dQ9MYTexiIm7yQ9VAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAIDTpz5FT/757s8QxHImTy+u1RwB4lN30sjz1bnJDBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF27QF42Ovf/l7t7L9++HTws79c/jTfIAD8T/+2OfjZ7mqccRLuuaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1aw/Aw/75/cfVzr6ow88+qesZJwHge93VuNrZn/748+BnLz68n3GS4+KGCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt2gMAAM/HxYf3a49wlNxQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKhdewCOU/+2OfjZ15czDgIAz4AbKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv2AByn7mpcewQAeDbcUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAECoXeKQk8vrJY4BgMnsJubkhgoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINRO+dA4jlVVdVe3VeOTzsMLdle3VfXf+wawj93EEqbupklBNQxDVVV9ro/hWPC4YRjq9PR07TGAI2c3saTHdlMzTrgO2O121fd9bbfbappm1gHh3jiONQxDdV1Xm41vo4H97CaWMHU3TQoqAAAe5hoAACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACD0BftAlWEQFG31AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEwklEQVR4nO3dMWojZxjH4XfEbGMQ7ge72ypVujS72wbS5RRb7AFyhhwgRU7hbg/gbOMLpEpnmAsMpLHRlyZOILDyoL80I8fPU+tj3mLQ++OzQV1rrRUAAAfbrD0AAMBLJ6gAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEL9nA/tdrsax7G22211XXfqmXilWms1TVMNw1CbjdYH9rObWMLc3TQrqMZxrOvr66MNB/vc39/X1dXV2mMAZ85uYknP7aZZQbXdbquq6l39UH29Oc5k8B+P9VBf6vM/7xvAPnYTS5i7m2YF1dNVal9vqu+8tJzI378q6eoemMNuYhEzd5N/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQrB9HTv3543dLPIYzcXFzt/YIAM+ym16XU+8mN1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6tcegNN4+9Pvqz17vFnt0QCvwvihO/jscNuOOAlP3FABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIT6tQfgNP74+Zvo/G+//Hrw2e/r2+jZAOw33LaDzybf71VV7z99jM7/X7mhAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9gCcp/efPh589qLujjgJAMeUfL/zdW6oAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAICSoAABCggoAINSvPQDnafzQHXz27c0RBwGAF8ANFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqF97AM7TcNvWHgEAXgw3VAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDql3jIxc3dEo8BgNnsJo7JDRUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQKif86HWWlVVPdZDVTvpPLxij/VQVf++bwD72E0sYe5umhVU0zRVVdWX+hyOBc+bpqkuLy/XHgM4c3YTS3puN3VtxnXAbrercRxru91W13VHHRCetNZqmqYahqE2G3+NBvazm1jC3N00K6gAAPg61wAAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKG/APgql2Ab1p/eAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEsUlEQVR4nO3dMW4UBxTH4TeroUEauV/ZacIB6GgCLRIdFUcgUg6Qq6RLTeWOAzgUcAE6KktzgZFobO3QYCKBsp7sfzyzyN9X72hesdL76dnSNuM4jgUAwME2aw8AAPCzE1QAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF2yod2u131fV9d11XTNHc9E/fUOI41DENtt9vabLQ+sJ/dxBKm7qZJQdX3fZ2dnc02HOxzeXlZp6ena48BHDm7iSXdtpsmBVXXdVVV9Vu9qLYezDMZfOe6rupdvf32fQPYx25iCVN306SgujmltvWg2saXljvy9Vclne6BKewmFjFxN/lHFQCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAhN+nHk1OeXT5Z4DUfi4fmHtUcAuJXddL/c9W5yoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQu/YAHKdHf348+Nn+fMZBAPhB/6w5+NntxTjjJNxwoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVrDwAA/D+fXv118LNPL17POAk3XKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1K49AMfp71/+OfjZ5/V4vkEA+MHTP16vPQLfcaECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAULv2ABynX9/8fvCzj+r9jJMAwPFzoQIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVrD8Bx2l6Ma48AAD8NFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAItUu85OH5hyVeAwCT2U3MyYUKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACDUTvnQOI5VVXVdV1Xjnc7DPXZdV1X17/cNYB+7iSVM3U2TgmoYhqqqeldvw7HgdsMw1MnJydpjAEfObmJJt+2mZpxwDtjtdtX3fXVdV03TzDog3BjHsYZhqO12W5uNv0YD+9lNLGHqbpoUVAAA/DdnAACAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCA0BfJ/JH9wQTTtwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAExElEQVR4nO3dMW7kBBTH4eeRt1nJSm8lNGxFRQcFWyPRcQQqkDgAZ6CioqCipkq3B8huwV6Aaisi+QKWaBKNaQhIWTEx83fsWfb76rH8ipHeTy+RppmmaSoAAI6223oAAIB3naACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAi1cz603+9rGIbquq6apnnsmXhPTdNU4zhW3/e122l94DC7iTXM3U2zgmoYhrq4uFhsODjk+vq6zs/Ptx4DOHF2E2t6aDfNCqqu66qq6rP6otp6ssxkcM9t3dSrevH39w3gELuJNczdTbOC6u6U2taTahtfWh7JX78q6XQPzGE3sYqZu8k/qgAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBo1o8jp/748pM1XsOJeHr5eusRAB705odPo+f7q2mhSVjDY+8mFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC79QAAsIX+atp6BP5HXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G49AADw37z88aejn33+7dcLTsIdFyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC79QCcpmff/Xb0s8PlgoMA8Javfn++9Qjc40IFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXbrAThNP3/w8uhnP6+PlxsEgLe8+f6jrUfgHhcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACLVbD8Bp+vCXb45+9ln9uuAkAHD6XKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAELt1gNwmvqraesRAOCd4UIFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABASVAAAoXaNlzy9fL3GawBgNruJJblQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCEBBUAQEhQAQCE2jkfmqapqqpu66ZqetR5eI/d1k1V/fN9AzjEbmINc3fTrKAax7Gqql7Vi3AseNg4jnV2drb1GMCJs5tY00O7qZlmnAP2+30Nw1Bd11XTNIsOCHemaapxHKvv+9rt/DUaOMxuYg1zd9OsoAIA4N85AwAAhAQVAEBIUAEAhAQVAEBIUAEAhAQVAEBIUAEAhP4EeNuUqFXlBCQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEtElEQVR4nO3dMW4cdRTH8TerSRNp5H5kV1BR0UGR1Eh0HIEKJE5CRZUiR6BylwM4KcgdUsXSXGAkGlv7pyEgIViP/FvPrPHnU+9oXrHS++rZ0nattVYAANzbbusBAAAeO0EFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDql3xov9/XNE01DEN1XffQM/FEtdZqnucax7F2O60PHGY3sYalu2lRUE3TVBcXF0cbDg65vr6u8/PzrccATpzdxJru2k2LgmoYhqqqelHfVl/PjjMZ/MNt3dS7evPX9w3gELuJNSzdTYuC6tMpta9n1Xe+tDyQP39V0ukeWMJuYhULd5N/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQoh9HTv3+3VdrvIYT8fzy/dYjANzpwy9fR8+PV+1Ik7CGh95NLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+6wEAYAvjVdt6BP5HXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G89AAA8NW9fvY6e//7jy3s/++HnL6J38+9cqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3WAwDAU/Pypx+2HoEjc6ECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/1AJymt69e3/vZby6/PN4gAPAIuFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqN96AE7TZ7/+eO9nP6/fjjgJAJw+FyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9QCcpvGqbT0CADwaLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6td4yfPL92u8BgAWs5s4JhcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv+RDrbWqqrqtm6r2oPPwhN3WTVX9/X0DOMRuYg1Ld9OioJrnuaqq3tWbcCy42zzPdXZ2tvUYwImzm1jTXbupawvOAfv9vqZpqmEYquu6ow4In7TWap7nGsexdjt/jQYOs5tYw9LdtCioAAD4b84AAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChPwCot5LCyhXfBgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAACuCAYAAADwDpN/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEtElEQVR4nO3dMW4cdRTH8TerSRNp5H5kV1BR0UGR1Eh0HIEKJE5CRZUiR6BylwM4KcgdUsXSXGAkGlv7pyEgIViP/FvPrPHnU+9oXrHS++rZ0nattVYAANzbbusBAAAeO0EFABASVAAAIUEFABASVAAAIUEFABASVAAAIUEFABDql3xov9/XNE01DEN1XffQM/FEtdZqnucax7F2O60PHGY3sYalu2lRUE3TVBcXF0cbDg65vr6u8/PzrccATpzdxJru2k2LgmoYhqqqelHfVl/PjjMZ/MNt3dS7evPX9w3gELuJNSzdTYuC6tMpta9n1Xe+tDyQP39V0ukeWMJuYhULd5N/VAEACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIDQoh9HTv3+3VdrvIYT8fzy/dYjANzpwy9fR8+PV+1Ik7CGh95NLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAAKF+6wEAYAvjVdt6BP5HXKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAgJKgAAEKCCgAg1G89AAA8NW9fvY6e//7jy3s/++HnL6J38+9cqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQoIKACAkqAAAQv3WAwDAU/Pypx+2HoEjc6ECAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAkKACAAgJKgCAUL/1AJymt69e3/vZby6/PN4gAPAIuFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBASFABAIQEFQBAqN96AE7TZ7/+eO9nP6/fjjgJAJw+FyoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgJCgAgAICSoAgFC/9QCcpvGqbT0CADwaLlQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQElQAACFBBQAQ6td4yfPL92u8BgAWs5s4JhcqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAICQoAIACAkqAIBQv+RDrbWqqrqtm6r2oPPwhN3WTVX9/X0DOMRuYg1Ld9OioJrnuaqq3tWbcCy42zzPdXZ2tvUYwImzm1jTXbupawvOAfv9vqZpqmEYquu6ow4In7TWap7nGsexdjt/jQYOs5tYw9LdtCioAAD4b84AAAAhQQUAEBJUAAAhQQUAEBJUAAAhQQUAEBJUAAChPwCot5LCyhXfBgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_ = get_env(2, size=10)\n",
    "input_shape = env_.to_state().shape[1:]\n",
    "\n",
    "GAMMA = .9\n",
    "ITERATIONS = 100\n",
    "\n",
    "display_boards(env_, 2)\n",
    "play(env_,DQN_agent, 100)\n",
    "# DQN_agent.play(env_, 100)\n",
    "display_boards(env_, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:  [[7.5 7.5]\n",
      " [7.3 7.3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import AStar_Heuristic\n",
    "\n",
    "agent = AStar_Heuristic.Heuristic_Agent(env_)\n",
    "agent.execute(ITERATIONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DQNAgent' object has no attribute 'select_action'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    tensor of actions, consider that\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m        UP = 0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m        LEFT = 3\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mDQN_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menv_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_boards\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m env_\u001b[38;5;241m.\u001b[39mmove(actions)\n\u001b[0;32m     15\u001b[0m     new_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(env_\u001b[38;5;241m.\u001b[39mto_state())\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    tensor of actions, consider that\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m        UP = 0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m        LEFT = 3\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     actions \u001b[38;5;241m=\u001b[39m [\u001b[43mDQN_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m(state[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(env_\u001b[38;5;241m.\u001b[39mn_boards)]\n\u001b[0;32m     14\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m env_\u001b[38;5;241m.\u001b[39mmove(actions)\n\u001b[0;32m     15\u001b[0m     new_state \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(env_\u001b[38;5;241m.\u001b[39mto_state())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DQNAgent' object has no attribute 'select_action'"
     ]
    }
   ],
   "source": [
    "for iteration in trange(ITERATIONS):\n",
    "    # get current state of the boards\n",
    "    state = env_.to_state()\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \"\"\" \n",
    "        tensor of actions, consider that\n",
    "            UP = 0\n",
    "            RIGHT = 1\n",
    "            DOWN = 2\n",
    "            LEFT = 3\n",
    "        \"\"\"\n",
    "        actions = [DQN_agent.select_action(state[i]) for i in range(env_.n_boards)]\n",
    "        rewards = env_.move(actions)\n",
    "        new_state = tf.constant(env_.to_state())\n",
    "\n",
    "        # calculate the loss of whichever algorithm you have picked\n",
    "        loss = ...\n",
    "\n",
    "    gradient = tape.gradient(..., ...)\n",
    "    optimizer.apply_gradients(zip(gradient, ...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " ### Random policy reward\n",
    " \n",
    "Just a baseline (not the one you are supposed to develop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_env = get_env(100)\n",
    "random_rewards = []\n",
    "\n",
    "for _ in trange(1000):\n",
    "    probs = tf.convert_to_tensor([[.25]*4]*random_env.n_boards)\n",
    "    #sample actions\n",
    "    actions =  tf.random.categorical(tf.math.log(probs), 1, dtype=tf.int32)\n",
    "    # MDP update\n",
    "    rewards = random_env.move(actions)\n",
    "    random_rewards.append(np.mean(rewards))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
