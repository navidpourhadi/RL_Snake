<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T21:49:54.740569Z",
     "start_time": "2024-01-05T21:49:54.724713Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import environments_fully_observable \n",
    "import environments_partially_observable\n",
    "import numpy as np\n",
    "from  tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T21:51:24.586654Z",
     "start_time": "2024-01-05T21:51:24.492663Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# function to standardize getting an env for the whole notebook\n",
    "def get_env(n=1000):\n",
    "    # n is the number of boards that you want to simulate parallely\n",
    "    # size is the size of each board, also considering the borders\n",
    "    # mask for the partially observable, is the size of the local neighborhood\n",
    "    size = 7\n",
    "    e = environments_fully_observable.OriginalSnakeEnvironment(n, size)\n",
    "    # or environments_partially_observable.OriginalSnakeEnvironment(n, size, 2)\n",
    "    return e\n",
    "env_ = get_env()\n",
    "GAMMA = .9\n",
    "ITERATIONS = 5000\n",
    "\n",
    "fig,axs=plt.subplots(1,min(len(env_.boards), 5), figsize=(10,3))\n",
    "for ax, board in zip(axs, env_.boards):\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.imshow(board, origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the models that you need ()\n",
    "agent = ...\n",
    "value = ...\n",
    "q = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for iteration in trange(ITERATIONS):\n",
    "    # get current state of the boards\n",
    "    state = env_.to_state()\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \"\"\" \n",
    "        tensor of actions, consider that\n",
    "            UP = 0\n",
    "            RIGHT = 1\n",
    "            DOWN = 2\n",
    "            LEFT = 3\n",
    "        \"\"\"\n",
    "        actions = ... \n",
    "        rewards = env_.move(actions)\n",
    "        new_state = tf.constant(env_.to_state())\n",
    "\n",
    "        # calculate the loss of whichever algorithm you have picked\n",
    "        loss = ...\n",
    "\n",
    "    gradient = tape.gradient(..., ...)\n",
    "    optimizer.apply_gradients(zip(gradient, ...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " ### Random policy reward\n",
    " \n",
    "Just a baseline (not the one you are supposed to develop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_env = get_env(100)\n",
    "random_rewards = []\n",
    "\n",
    "for _ in trange(1000):\n",
    "    probs = tf.convert_to_tensor([[.25]*4]*random_env.n_boards)\n",
    "    #sample actions\n",
    "    actions =  tf.random.categorical(tf.math.log(probs), 1, dtype=tf.int32)\n",
    "    # MDP update\n",
    "    rewards = random_env.move(actions)\n",
    "    random_rewards.append(np.mean(rewards))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T21:49:54.740569Z",
     "start_time": "2024-01-05T21:49:54.724713Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import environments_fully_observable \n",
    "import environments_partially_observable\n",
    "import numpy as np\n",
    "from  tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T21:51:24.586654Z",
     "start_time": "2024-01-05T21:51:24.492663Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# function to standardize getting an env for the whole notebook\n",
    "def get_env(n=1000):\n",
    "    # n is the number of boards that you want to simulate parallely\n",
    "    # size is the size of each board, also considering the borders\n",
    "    # mask for the partially observable, is the size of the local neighborhood\n",
    "    size = 7\n",
    "    e = environments_fully_observable.OriginalSnakeEnvironment(n, size)\n",
    "    # or environments_partially_observable.OriginalSnakeEnvironment(n, size, 2)\n",
    "    return e\n",
    "env_ = get_env()\n",
    "GAMMA = .9\n",
    "ITERATIONS = 5000\n",
    "\n",
    "fig,axs=plt.subplots(1,min(len(env_.boards), 5), figsize=(10,3))\n",
    "for ax, board in zip(axs, env_.boards):\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.imshow(board, origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the models that you need ()\n",
    "agent = ...\n",
    "value = ...\n",
    "q = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for iteration in trange(ITERATIONS):\n",
    "    # get current state of the boards\n",
    "    state = env_.to_state()\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        \"\"\" \n",
    "        tensor of actions, consider that\n",
    "            UP = 0\n",
    "            RIGHT = 1\n",
    "            DOWN = 2\n",
    "            LEFT = 3\n",
    "        \"\"\"\n",
    "        actions = ... \n",
    "        rewards = env_.move(actions)\n",
    "        new_state = tf.constant(env_.to_state())\n",
    "\n",
    "        # calculate the loss of whichever algorithm you have picked\n",
    "        loss = ...\n",
    "\n",
    "    gradient = tape.gradient(..., ...)\n",
    "    optimizer.apply_gradients(zip(gradient, ...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " ### Random policy reward\n",
    " \n",
    "Just a baseline (not the one you are supposed to develop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_env = get_env(100)\n",
    "random_rewards = []\n",
    "\n",
    "for _ in trange(1000):\n",
    "    probs = tf.convert_to_tensor([[.25]*4]*random_env.n_boards)\n",
    "    #sample actions\n",
    "    actions =  tf.random.categorical(tf.math.log(probs), 1, dtype=tf.int32)\n",
    "    # MDP update\n",
    "    rewards = random_env.move(actions)\n",
    "    random_rewards.append(np.mean(rewards))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
>>>>>>> 548c32bf898c87650869edae2c58afdd9b2ca9fc
